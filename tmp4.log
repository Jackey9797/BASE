2023-09-03 23:52:50,474 - logger name:exp/ECL-PatchTST2023-09-03-23:52:50.474324/ECL-PatchTST.log
2023-09-03 23:52:50,475 - params : {'loss': 'huber', 'conf': 'ECL-PatchTST', 'data_name': 'ETTm1', 'iteration': 1, 'train': 1, 'mainrs': 0, 'abl': 1, 'load': True, 'build_graph': False, 'same_init': True, 'grad_norm': False, 'refiner_residual': 0, 'root_path': '', 'exp_path': 'exp/', 'val_test_mix': False, 'lr': 0.0001, 'lradj': 'TST', 'dropout': 0.2, 'fc_dropout': 0.2, 'head_dropout': 0.0, 'patch_len': 16, 'stride': 8, 'd_ff': 256, 'd_model': 128, 'n_heads': 16, 'seq_len': 336, 'pred_len': 96, 'noise_rate': 0.5, 'device': device(type='cuda', index=1), 'test_model_path': '/Disk/fhyega/code/BASE/exp/ECL-PatchTST2023-08-26-13:08:31.837686/0/best_model.pkl', 'idx': -1, 'aligner': 1, 'always_align': 1, 'refiner': 1, 'rec_block_num': 1, 'enhance': 1, 'enhance_type': 5, 'seed': 34, 'batch_size': 128, 'share_head': 0, 'add_noise': 1, 'add_norm': 0, 'jitter_sigma': 0.4, 'slope_rate': 0.01, 'slope_range': 0.2, 'alpha': 10.0, 'beta': 1.0, 'gamma': 0.15, 'feature_jittering': 1, 'rec_intra_feature': 0, 'rec_ori': 1, 'mid_dim': 128, 'test_en': 0, 'debugger': 0, 'summary': 0, 'omega': 1.0, 'theta': 1.5, 'mask_border': 1, 'sup_weight': 10.0, 'rec_length_ratio': 0.8, 'ref_dropout': 0.0, 'ref_block_num': 1, 'add_FFN': 1, 'add_residual': 0, 'rec_all': 0, 'e_layers': 3, 'early_break': 0, 'early_stop': 10, '/* model related args*/': '//', 'model_name': 'PatchTST', 'label_len': 48, 'features': 'M', 'target': 'OT', 'graph_input': False, 'individual': False, 'd_layers': 1, 'factor': 1, 'des': 'Exp', 'padding_patch': 'end', 'revin': 1, 'affine': 0, 'subtract_last': 0, 'decomposition': 0, 'kernel_size': 25, 'output_attention': 0, 'embed_type': 0, 'activation': 'gelu', 'distil': 1, 'linear_output': 1, 'pct_start': 0.2, '/*train related args*/': '//', 'epoch': 30, '/*dataset related args*/': '//', 'save_data_path': 'data/ECL/', 'data_process': True, 'embed': 'timeF', 'freq': 'h', 'begin_phase': 0, 'end_phase': 1, 'phase_len': -1, 'val_ratio': 0.33, 'graph_size': 321, '/*strategy related args*/': '//', 'strategy': 'incremental', 'increase': False, 'detect': False, 'detect_strategy': 'feature', 'replay': False, 'replay_strategy': 'random', 'repaly_num_samples': 100, 'ewc': False, 'ewc_strategy': 'ewc', 'ewc_lambda': 0.0001, 'subgraph_train': False, 'num_hops': 2, 'logname': 'ECL-PatchTST', 'time': '2023-09-03-23:52:50.474324', 'path': 'exp/ECL-PatchTST2023-09-03-23:52:50.474324', 'num_workers': 4, 'start_train': 0, 'train_mode': 'pretrain', 'get_score': False, 'use_cm': True, 'logger': <Logger __main__ (INFO)>}
2023-09-03 23:52:50,475 - [*] phase 0 start training
0 69680
train 34129
val 11425
test 11425
2023-09-03 23:52:51,362 - [*] phase 0 Dataset load!
2023-09-03 23:52:52,572 - [*] phase 0 Training start
train 34129
2023-09-03 23:53:56,640 - epoch:0, training loss:0.1882 validation loss:0.1820
train 34129
vs, vt 0.18196401625043815 0.18696492351591587
Updating learning rate to 1.0438661460315324e-05
Updating learning rate to 1.0438661460315324e-05
train 34129
vs, vt 0.16608803276386525 0.16712793711986806
need align? ->  False 0.16712793711986806
2023-09-03 23:56:04,123 - epoch:1, training loss:9.8929 validation loss:0.1661
Updating learning rate to 2.8027297449571736e-05
Updating learning rate to 2.8027297449571736e-05
train 34129
vs, vt 0.1662613485008478 0.165406786195106
need align? ->  True 0.165406786195106
2023-09-03 23:57:45,346 - epoch:2, training loss:3.4884 validation loss:0.1663
Updating learning rate to 5.204727160595503e-05
Updating learning rate to 5.204727160595503e-05
train 34129
vs, vt 0.1701712349222766 0.17121955028010738
need align? ->  True 0.165406786195106
2023-09-04 00:00:37,181 - epoch:3, training loss:2.2653 validation loss:0.1702
Updating learning rate to 7.605456385119542e-05
Updating learning rate to 7.605456385119542e-05
train 34129
vs, vt 0.164445963419146 0.16693150214850902
need align? ->  False 0.165406786195106
2023-09-04 00:02:22,198 - epoch:4, training loss:1.8719 validation loss:0.1644
Updating learning rate to 9.360855637921138e-05
Updating learning rate to 9.360855637921138e-05
train 34129
vs, vt 0.16700357906520366 0.165050612265865
need align? ->  True 0.165050612265865
2023-09-04 00:04:04,587 - epoch:5, training loss:1.6408 validation loss:0.1670
Updating learning rate to 9.99999939458629e-05
Updating learning rate to 9.99999939458629e-05
train 34129
vs, vt 0.16567683066758845 0.16234524941278827
need align? ->  True 0.16234524941278827
2023-09-04 00:05:46,671 - epoch:6, training loss:1.3446 validation loss:0.1657
Updating learning rate to 9.956902716655286e-05
Updating learning rate to 9.956902716655286e-05
train 34129
vs, vt 0.16105426773428916 0.15940715724395382
need align? ->  True 0.15940715724395382
2023-09-04 00:07:29,491 - epoch:7, training loss:1.2176 validation loss:0.1611
Updating learning rate to 9.828992401134782e-05
Updating learning rate to 9.828992401134782e-05
train 34129
vs, vt 0.1596701795442237 0.16067067037026087
need align? ->  True 0.15940715724395382
2023-09-04 00:10:02,481 - epoch:8, training loss:1.1455 validation loss:0.1597
Updating learning rate to 9.618457028986775e-05
Updating learning rate to 9.618457028986775e-05
train 34129
vs, vt 0.1588421703626712 0.15934137908948792
need align? ->  False 0.15934137908948792
2023-09-04 00:12:16,324 - epoch:9, training loss:1.0737 validation loss:0.1588
Updating learning rate to 9.32889891880015e-05
Updating learning rate to 9.32889891880015e-05
train 34129
vs, vt 0.15935017379621666 0.15790639908777343
need align? ->  True 0.15790639908777343
2023-09-04 00:14:56,597 - epoch:10, training loss:1.0716 validation loss:0.1594
Updating learning rate to 8.965272490120875e-05
Updating learning rate to 8.965272490120875e-05
train 34129
vs, vt 0.15708475667569372 0.157110619586375
need align? ->  False 0.157110619586375
2023-09-04 00:16:39,942 - epoch:11, training loss:1.0241 validation loss:0.1571
Updating learning rate to 8.533799491959945e-05
Updating learning rate to 8.533799491959945e-05
train 34129
vs, vt 0.15674948965509733 0.1568464609897799
need align? ->  False 0.1568464609897799
2023-09-04 00:18:22,582 - epoch:12, training loss:1.0077 validation loss:0.1567
Updating learning rate to 8.041862546942808e-05
Updating learning rate to 8.041862546942808e-05
train 34129
vs, vt 0.15601154714822768 0.1552327627523078
need align? ->  True 0.1552327627523078
2023-09-04 00:20:05,361 - epoch:13, training loss:1.0078 validation loss:0.1560
Updating learning rate to 7.497878832589398e-05
Updating learning rate to 7.497878832589398e-05
train 34129
vs, vt 0.15575337260961533 0.1542884157763587
need align? ->  True 0.1542884157763587
2023-09-04 00:21:48,543 - epoch:14, training loss:0.9928 validation loss:0.1558
Updating learning rate to 6.911156061073078e-05
Updating learning rate to 6.911156061073078e-05
train 34129
vs, vt 0.1548712899701463 0.1546762566599581
need align? ->  True 0.1542884157763587
2023-09-04 00:23:30,204 - epoch:15, training loss:0.9790 validation loss:0.1549
Updating learning rate to 6.291733221684778e-05
Updating learning rate to 6.291733221684778e-05
train 34129
vs, vt 0.15373340613312192 0.1532086583475272
need align? ->  True 0.1532086583475272
2023-09-04 00:25:12,198 - epoch:16, training loss:0.9632 validation loss:0.1537
Updating learning rate to 5.650208810942889e-05
Updating learning rate to 5.650208810942889e-05
train 34129
vs, vt 0.15526418938404984 0.15401232060458925
need align? ->  True 0.1532086583475272
2023-09-04 00:26:55,175 - epoch:17, training loss:0.9837 validation loss:0.1553
Updating learning rate to 4.9975594893793686e-05
Updating learning rate to 4.9975594893793686e-05
train 34129
vs, vt 0.15385946498976813 0.15498599981268246
need align? ->  True 0.1532086583475272
2023-09-04 00:28:37,539 - epoch:18, training loss:0.9698 validation loss:0.1539
Updating learning rate to 4.3449522678347527e-05
Updating learning rate to 4.3449522678347527e-05
train 34129

vs, vt 0.15443026833236217 0.1523015744570229
need align? ->  True 0.1523015744570229
2023-09-04 00:30:20,446 - epoch:19, training loss:0.9607 validation loss:0.1544
Updating learning rate to 3.7035534368065714e-05
Updating learning rate to 3.7035534368065714e-05
train 34129

vs, vt 0.15397211242881087 0.15229158409767682
need align? ->  True 0.15229158409767682
2023-09-04 00:32:04,094 - epoch:20, training loss:0.9924 validation loss:0.1540
Updating learning rate to 3.084337508123067e-05
Updating learning rate to 3.084337508123067e-05
train 34129

vs, vt 0.15419491885436906 0.1529453700201379
need align? ->  True 0.15229158409767682
2023-09-04 00:33:45,611 - epoch:21, training loss:0.9990 validation loss:0.1542
Updating learning rate to 2.497899438003108e-05
Updating learning rate to 2.497899438003108e-05
train 34129

vs, vt 0.15365432711939017 0.15229616910219193
need align? ->  True 0.15229158409767682
2023-09-04 00:35:28,105 - epoch:22, training loss:0.9941 validation loss:0.1537
Updating learning rate to 1.9542733444177923e-05
Updating learning rate to 1.9542733444177923e-05
train 34129

vs, vt 0.15376797566811243 0.15268235202464792
need align? ->  True 0.15229158409767682
2023-09-04 00:37:09,919 - epoch:23, training loss:0.9890 validation loss:0.1538
Updating learning rate to 1.4627608205499963e-05
Updating learning rate to 1.4627608205499963e-05
train 34129

vs, vt 0.1530300016204516 0.15264199388523897
need align? ->  True 0.15229158409767682
2023-09-04 00:38:52,545 - epoch:24, training loss:0.9849 validation loss:0.1530
Updating learning rate to 1.0317717819561129e-05
Updating learning rate to 1.0317717819561129e-05
train 34129

vs, vt 0.15365962750381892 0.15204861126840113
need align? ->  True 0.15204861126840113
2023-09-04 00:40:35,113 - epoch:25, training loss:0.9832 validation loss:0.1537
Updating learning rate to 6.686805705792195e-06
Updating learning rate to 6.686805705792195e-06
train 34129

vs, vt 0.1537810011870331 0.15253394614491197
need align? ->  True 0.15204861126840113
2023-09-04 00:42:18,317 - epoch:26, training loss:1.0056 validation loss:0.1538
Updating learning rate to 3.79699777713878e-06
Updating learning rate to 3.79699777713878e-06
train 34129

vs, vt 0.1536280766957336 0.15246953628957272
need align? ->  True 0.15204861126840113
2023-09-04 00:44:00,035 - epoch:27, training loss:1.0040 validation loss:0.1536
Updating learning rate to 1.6977394484662593e-06
Updating learning rate to 1.6977394484662593e-06
train 34129

vs, vt 0.15368708843986192 0.1523353236830897
need align? ->  True 0.15204861126840113
2023-09-04 00:45:42,738 - epoch:28, training loss:1.0036 validation loss:0.1537
Updating learning rate to 4.2494961180259127e-07
Updating learning rate to 4.2494961180259127e-07
train 34129

vs, vt 0.1537144230057796 0.15237265701095262
need align? ->  True 0.15204861126840113
2023-09-04 00:47:26,489 - epoch:29, training loss:1.0033 validation loss:0.1537
Updating learning rate to 4.0605413710007e-10
Updating learning rate to 4.0605413710007e-10
check exp/ECL-PatchTST2023-09-03-23:52:50.474324/0/0.153_epoch_24.pkl  &  0.15204861126840113
2023-09-04 00:47:32,798 - [*] loss:0.2865
2023-09-04 00:47:32,809 - [*] phase 0, testing
2023-09-04 00:47:32,987 - T:96	MAE	0.335340	RMSE	0.287938	MAPE	214.729548
2023-09-04 00:47:32,988 - 96	mae	0.3353	
2023-09-04 00:47:32,988 - 96	rmse	0.2879	
2023-09-04 00:47:32,988 - 96	mape	214.7295	
----*-----
2023-09-04 00:47:39,040 - [*] loss:0.2865
2023-09-04 00:47:39,049 - [*] phase 0, testing
2023-09-04 00:47:39,221 - T:96	MAE	0.335340	RMSE	0.287938	MAPE	214.729548
2023-09-04 00:47:45,696 - [*] loss:0.3042
2023-09-04 00:47:45,706 - [*] phase 0, testing
2023-09-04 00:47:45,877 - T:96	MAE	0.359384	RMSE	0.305692	MAPE	231.560516
2023-09-04 00:47:51,985 - [*] loss:0.3929
2023-09-04 00:47:51,995 - [*] phase 0, testing
2023-09-04 00:47:52,170 - T:96	MAE	0.412592	RMSE	0.395043	MAPE	270.145321
2023-09-04 00:47:58,681 - [*] loss:0.2934
2023-09-04 00:47:58,691 - [*] phase 0, testing
2023-09-04 00:47:58,866 - T:96	MAE	0.345509	RMSE	0.295075	MAPE	233.460999
2023-09-04 00:48:08,268 - [*] loss:0.3570
2023-09-04 00:48:08,278 - [*] phase 0, testing
2023-09-04 00:48:08,454 - T:96	MAE	0.398801	RMSE	0.358678	MAPE	233.081675
2023-09-04 00:48:15,310 - [*] loss:0.3289
2023-09-04 00:48:15,320 - [*] phase 0, testing
2023-09-04 00:48:15,513 - T:96	MAE	0.374594	RMSE	0.330437	MAPE	202.432704
2023-09-04 00:48:22,280 - [*] loss:0.2921
2023-09-04 00:48:22,289 - [*] phase 0, testing
2023-09-04 00:48:22,463 - T:96	MAE	0.343178	RMSE	0.293522	MAPE	220.288038
2023-09-04 00:48:29,052 - [*] loss:0.2984
2023-09-04 00:48:29,062 - [*] phase 0, testing
2023-09-04 00:48:29,235 - T:96	MAE	0.352606	RMSE	0.299791	MAPE	202.072978
----*-----
2023-09-04 00:48:33,451 - [*] loss:0.2970
2023-09-04 00:48:33,460 - [*] phase 0, testing
2023-09-04 00:48:33,632 - T:96	MAE	0.350919	RMSE	0.297476	MAPE	203.137708
2023-09-04 00:48:39,998 - [*] loss:0.3015
2023-09-04 00:48:40,007 - [*] phase 0, testing
2023-09-04 00:48:40,196 - T:96	MAE	0.349180	RMSE	0.303142	MAPE	193.733358
2023-09-04 00:48:44,402 - [*] loss:0.2992
2023-09-04 00:48:44,412 - [*] phase 0, testing
2023-09-04 00:48:44,587 - T:96	MAE	0.345847	RMSE	0.299999	MAPE	200.294828
2023-09-04 00:48:44,590 - 96	mae	0.3458	
2023-09-04 00:48:44,590 - 96	rmse	0.3000	
2023-09-04 00:48:44,590 - 96	mape	200.2948	
