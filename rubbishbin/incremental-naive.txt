2023-04-18 22:41:35,407 - logger name:exp/district3F11T17/incremental-naive2023-04-18-22:41:35.345044/incremental-naive.log
2023-04-18 22:41:35,459 - params : {'load_config': 'configs/incremental-naive.json', 'data_process': False, 'auto_test': 1, 'load': True, 'device': device(type='cuda', index=0), 'data_name': 'PEMS3-Stream', 'raw_data_path': 'data/district3F11T17/finaldata/', 'graph_path': 'data/district3F11T17/graph/', 'save_data_path': 'data/district3F11T17/FastData/', 'model_path': 'exp/district3F11T17/', 'year': 2012, 'days': 31, 'logname': 'incremental-naive', '/* model related args*/': '//', 'y_len': 12, 'dropout': 0.0, 'gcn': {'in_channel': 12, 'out_channel': 12, 'hidden_channel': 64}, 'tcn': {'in_channel': 1, 'out_channel': 1, 'kernel_size': 3, 'dilation': 1}, '/*train related args*/': '//', 'train': True, 'begin_year': 2011, 'end_year': 2017, 'epoch': 100, 'batch_size': 128, 'lr': 0.01, 'loss': 'mse', '/*strategy related args*/': '//', 'strategy': 'incremental', 'increase': False, 'detect': False, 'replay': False, 'ewc': False, 'ewc_strategy': 'ewc', 'ewc_lambda': 1.0, 'subgraph_train': False, 'time': '2023-04-18-22:41:35.345044', 'path': 'exp/district3F11T17/incremental-naive2023-04-18-22:41:35.345044', 'logger': <Logger __main__ (INFO)>}
2023-04-18 22:41:35,459 - [*] Year 2011 load from data/district3F11T17/FastData/2011_30day.npz
2023-04-18 22:41:53,684 - [*] Year 2011 Dataset load!
2023-04-18 22:42:11,630 - [*] Year 2011 Training start
2023-04-18 22:42:13,891 - node number torch.Size([83840, 12])
2023-04-18 22:42:42,747 - epoch:0, training loss:93.8839 validation loss:53.6565
2023-04-18 22:42:44,375 - epoch:1, training loss:44.9367 validation loss:37.4060
2023-04-18 22:42:45,967 - epoch:2, training loss:34.8963 validation loss:31.2212
2023-04-18 22:42:47,566 - epoch:3, training loss:27.8402 validation loss:24.2145
2023-04-18 22:42:49,174 - epoch:4, training loss:22.5487 validation loss:20.5038
2023-04-18 22:42:50,755 - epoch:5, training loss:20.2232 validation loss:19.4817
2023-04-18 22:42:52,371 - epoch:6, training loss:19.2733 validation loss:18.6869
2023-04-18 22:42:53,970 - epoch:7, training loss:18.6435 validation loss:17.9542
2023-04-18 22:42:55,619 - epoch:8, training loss:18.2797 validation loss:17.7765
2023-04-18 22:42:57,226 - epoch:9, training loss:18.0797 validation loss:17.4700
2023-04-18 22:42:58,888 - epoch:10, training loss:17.9556 validation loss:17.7326
2023-04-18 22:43:00,475 - epoch:11, training loss:17.9412 validation loss:17.5001
2023-04-18 22:43:02,062 - epoch:12, training loss:17.7959 validation loss:17.4830
2023-04-18 22:43:03,645 - epoch:13, training loss:17.8440 validation loss:17.5423
2023-04-18 22:43:05,280 - epoch:14, training loss:17.8767 validation loss:17.4262
2023-04-18 22:43:06,853 - epoch:15, training loss:17.6970 validation loss:17.4330
2023-04-18 22:43:08,504 - epoch:16, training loss:17.7424 validation loss:17.5325
2023-04-18 22:43:10,116 - epoch:17, training loss:17.6518 validation loss:17.3332
2023-04-18 22:43:11,706 - epoch:18, training loss:17.5967 validation loss:17.4511
2023-04-18 22:43:13,319 - epoch:19, training loss:17.5746 validation loss:17.3366
2023-04-18 22:43:14,921 - epoch:20, training loss:17.4792 validation loss:17.3212
2023-04-18 22:43:16,518 - epoch:21, training loss:17.5240 validation loss:17.4318
2023-04-18 22:43:18,211 - epoch:22, training loss:17.3346 validation loss:17.2924
2023-04-18 22:43:19,813 - epoch:23, training loss:17.3134 validation loss:17.1487
2023-04-18 22:43:21,406 - epoch:24, training loss:17.1544 validation loss:16.8161
2023-04-18 22:43:23,053 - epoch:25, training loss:17.0258 validation loss:16.8921
2023-04-18 22:43:24,673 - epoch:26, training loss:16.9861 validation loss:16.7866
2023-04-18 22:43:26,282 - epoch:27, training loss:16.9887 validation loss:16.9484
2023-04-18 22:43:27,917 - epoch:28, training loss:17.0691 validation loss:16.7719
2023-04-18 22:43:29,600 - epoch:29, training loss:16.9137 validation loss:16.7342
2023-04-18 22:43:31,302 - epoch:30, training loss:17.0142 validation loss:16.9193
2023-04-18 22:43:32,989 - epoch:31, training loss:16.9176 validation loss:16.7306
2023-04-18 22:43:34,595 - epoch:32, training loss:17.0125 validation loss:16.8449
2023-04-18 22:43:36,208 - epoch:33, training loss:16.8701 validation loss:16.7614
2023-04-18 22:43:37,835 - epoch:34, training loss:16.8450 validation loss:16.6195
2023-04-18 22:43:39,475 - epoch:35, training loss:16.8459 validation loss:16.6951
2023-04-18 22:43:41,100 - epoch:36, training loss:16.8365 validation loss:16.7780
2023-04-18 22:43:42,699 - epoch:37, training loss:16.9534 validation loss:16.5595
2023-04-18 22:43:44,383 - epoch:38, training loss:16.8773 validation loss:17.0651
2023-04-18 22:43:46,001 - epoch:39, training loss:16.8414 validation loss:16.6582
2023-04-18 22:43:47,603 - epoch:40, training loss:16.8010 validation loss:16.5616
2023-04-18 22:43:49,270 - epoch:41, training loss:16.7755 validation loss:16.7250
2023-04-18 22:43:50,890 - epoch:42, training loss:16.8369 validation loss:16.9599
2023-04-18 22:43:52,516 - epoch:43, training loss:16.8812 validation loss:16.5326
2023-04-18 22:43:54,112 - epoch:44, training loss:16.8776 validation loss:16.4614
2023-04-18 22:43:55,717 - epoch:45, training loss:16.7397 validation loss:16.6753
2023-04-18 22:43:57,377 - epoch:46, training loss:16.8832 validation loss:16.4794
2023-04-18 22:43:59,073 - epoch:47, training loss:16.8731 validation loss:16.7573
2023-04-18 22:44:00,718 - epoch:48, training loss:16.6929 validation loss:16.6800
2023-04-18 22:44:02,410 - epoch:49, training loss:16.9716 validation loss:16.8821
2023-04-18 22:44:04,172 - epoch:50, training loss:17.0427 validation loss:16.6409
2023-04-18 22:44:04,459 - Finished optimization, total time:90.78 s, best model:exp/district3F11T17/incremental-naive2023-04-18-22:41:35.345044/2011/16.4614_epoch_44.pkl
2023-04-18 22:44:05,643 - [*] loss:638.0565
2023-04-18 22:44:05,768 - [*] year 2011, testing
2023-04-18 22:44:05,921 - T:3	MAE	13.0518	RMSE	19.8972	MAPE	17.2383
2023-04-18 22:44:06,660 - T:6	MAE	14.0621	RMSE	21.6954	MAPE	18.9995
2023-04-18 22:44:07,379 - T:12	MAE	16.3058	RMSE	25.4703	MAPE	23.7451
2023-04-18 22:44:07,383 - [*] Year 2012 load from data/district3F11T17/FastData/2012_30day.npz
2023-04-18 22:44:07,979 - [*] Year 2012 Dataset load!
2023-04-18 22:44:08,156 - [*] load from exp/district3F11T17/incremental-naive2023-04-18-22:41:35.345044/2011/best_model.pkl
2023-04-18 22:45:02,598 - [*] Year 2012 Training start
2023-04-18 22:45:05,912 - node number torch.Size([91520, 12])
2023-04-18 22:45:13,690 - epoch:0, training loss:17.3046 validation loss:15.9862
2023-04-18 22:45:15,500 - epoch:1, training loss:16.3591 validation loss:16.1079
2023-04-18 22:45:17,312 - epoch:2, training loss:16.4732 validation loss:15.9438
2023-04-18 22:45:19,171 - epoch:3, training loss:16.3497 validation loss:16.0931
2023-04-18 22:45:20,959 - epoch:4, training loss:16.5716 validation loss:16.1476
2023-04-18 22:45:22,741 - epoch:5, training loss:16.3283 validation loss:15.9270
2023-04-18 22:45:24,615 - epoch:6, training loss:16.4774 validation loss:16.0217
2023-04-18 22:45:26,453 - epoch:7, training loss:16.3840 validation loss:16.0450
2023-04-18 22:45:28,341 - epoch:8, training loss:16.3734 validation loss:15.9382
2023-04-18 22:45:30,177 - epoch:9, training loss:16.3271 validation loss:15.9074
2023-04-18 22:45:31,996 - epoch:10, training loss:16.3427 validation loss:15.8638
2023-04-18 22:45:33,752 - epoch:11, training loss:16.3012 validation loss:16.0703
2023-04-18 22:45:35,515 - epoch:12, training loss:16.3232 validation loss:15.9567
2023-04-18 22:45:37,243 - epoch:13, training loss:16.4830 validation loss:15.9029
2023-04-18 22:45:39,009 - epoch:14, training loss:16.2542 validation loss:15.8514
2023-04-18 22:45:41,147 - epoch:15, training loss:16.3561 validation loss:15.8860
2023-04-18 22:45:42,910 - epoch:16, training loss:16.2677 validation loss:15.9756
2023-04-18 22:45:44,666 - epoch:17, training loss:16.2581 validation loss:15.8700
2023-04-18 22:45:46,438 - epoch:18, training loss:16.3558 validation loss:15.8353
2023-04-18 22:45:48,200 - epoch:19, training loss:16.2731 validation loss:15.8389
2023-04-18 22:45:49,962 - epoch:20, training loss:16.3256 validation loss:15.7588
2023-04-18 22:45:51,744 - epoch:21, training loss:16.4477 validation loss:15.8152
2023-04-18 22:45:53,520 - epoch:22, training loss:16.2501 validation loss:15.7688
2023-04-18 22:45:55,294 - epoch:23, training loss:16.3863 validation loss:15.9564
2023-04-18 22:45:57,365 - epoch:24, training loss:16.3865 validation loss:15.9030
2023-04-18 22:45:59,416 - epoch:25, training loss:16.3522 validation loss:15.8723
2023-04-18 22:46:01,358 - epoch:26, training loss:16.1954 validation loss:15.7880
2023-04-18 22:46:01,362 - Finished optimization, total time:45.28 s, best model:exp/district3F11T17/incremental-naive2023-04-18-22:41:35.345044/2012/15.7588_epoch_20.pkl
2023-04-18 22:46:01,878 - [*] loss:626.5018
2023-04-18 22:46:02,001 - [*] year 2012, testing
2023-04-18 22:46:02,162 - T:3	MAE	12.4787	RMSE	19.4705	MAPE	17.0424
2023-04-18 22:46:02,634 - T:6	MAE	13.6058	RMSE	21.4672	MAPE	18.6470
2023-04-18 22:46:03,199 - T:12	MAE	15.7489	RMSE	25.2363	MAPE	22.3245
2023-04-18 22:46:03,204 - [*] Year 2013 load from data/district3F11T17/FastData/2013_30day.npz
2023-04-18 22:46:03,559 - [*] Year 2013 Dataset load!
2023-04-18 22:46:03,559 - [*] load from exp/district3F11T17/incremental-naive2023-04-18-22:41:35.345044/2012/best_model.pkl
2023-04-18 22:47:29,740 - [*] Year 2013 Training start
2023-04-18 22:47:30,778 - node number torch.Size([100608, 12])
2023-04-18 22:47:35,085 - epoch:0, training loss:16.7441 validation loss:16.2555
2023-04-18 22:47:37,366 - epoch:1, training loss:15.6532 validation loss:16.2768
2023-04-18 22:47:39,524 - epoch:2, training loss:15.7195 validation loss:16.5364
2023-04-18 22:47:41,555 - epoch:3, training loss:15.8636 validation loss:16.1874
2023-04-18 22:47:43,665 - epoch:4, training loss:15.6861 validation loss:16.3159
2023-04-18 22:47:45,695 - epoch:5, training loss:15.6455 validation loss:16.6479
2023-04-18 22:47:47,659 - epoch:6, training loss:15.6254 validation loss:16.2794
2023-04-18 22:47:49,584 - epoch:7, training loss:15.7260 validation loss:16.0962
2023-04-18 22:47:51,603 - epoch:8, training loss:15.8146 validation loss:16.3605
2023-04-18 22:47:53,599 - epoch:9, training loss:15.7551 validation loss:17.7217
2023-04-18 22:47:55,587 - epoch:10, training loss:15.7251 validation loss:16.4461
2023-04-18 22:47:57,580 - epoch:11, training loss:15.8185 validation loss:16.1063
2023-04-18 22:47:59,781 - epoch:12, training loss:15.7240 validation loss:16.2749
2023-04-18 22:48:02,018 - epoch:13, training loss:15.6072 validation loss:16.4658
2023-04-18 22:48:02,022 - Finished optimization, total time:24.45 s, best model:exp/district3F11T17/incremental-naive2023-04-18-22:41:35.345044/2013/16.0962_epoch_7.pkl
2023-04-18 22:48:02,709 - [*] loss:683.2017
2023-04-18 22:48:03,029 - [*] year 2013, testing
2023-04-18 22:48:03,250 - T:3	MAE	12.3386	RMSE	19.7303	MAPE	18.8954
2023-04-18 22:48:03,768 - T:6	MAE	13.6115	RMSE	21.9880	MAPE	22.1720
2023-04-18 22:48:05,048 - T:12	MAE	16.2200	RMSE	26.3330	MAPE	29.0752
2023-04-18 22:48:05,054 - [*] Year 2014 load from data/district3F11T17/FastData/2014_30day.npz
2023-04-18 22:48:05,373 - [*] Year 2014 Dataset load!
2023-04-18 22:48:05,492 - [*] load from exp/district3F11T17/incremental-naive2023-04-18-22:41:35.345044/2013/best_model.pkl
2023-04-18 22:48:19,150 - [*] Year 2014 Training start
2023-04-18 22:48:21,378 - node number torch.Size([105216, 12])
2023-04-18 22:48:24,856 - epoch:0, training loss:17.4189 validation loss:17.2391
2023-04-18 22:48:27,156 - epoch:1, training loss:16.9825 validation loss:17.1505
2023-04-18 22:48:29,396 - epoch:2, training loss:16.9812 validation loss:17.1401
2023-04-18 22:48:31,609 - epoch:3, training loss:16.9724 validation loss:17.0969
2023-04-18 22:48:33,756 - epoch:4, training loss:17.0020 validation loss:17.4638
2023-04-18 22:48:36,019 - epoch:5, training loss:17.2248 validation loss:17.4774
2023-04-18 22:48:38,178 - epoch:6, training loss:17.0138 validation loss:17.1152
2023-04-18 22:48:40,354 - epoch:7, training loss:16.9221 validation loss:17.3034
2023-04-18 22:48:42,663 - epoch:8, training loss:16.9469 validation loss:17.1414
2023-04-18 22:48:44,862 - epoch:9, training loss:16.9008 validation loss:17.1194
2023-04-18 22:48:44,945 - Finished optimization, total time:19.68 s, best model:exp/district3F11T17/incremental-naive2023-04-18-22:41:35.345044/2014/17.0969_epoch_3.pkl
2023-04-18 22:48:45,517 - [*] loss:739.3006
2023-04-18 22:48:45,726 - [*] year 2014, testing
2023-04-18 22:48:45,886 - T:3	MAE	13.2138	RMSE	21.1016	MAPE	17.8782
2023-04-18 22:48:46,373 - T:6	MAE	14.3921	RMSE	23.2802	MAPE	19.0479
2023-04-18 22:48:47,038 - T:12	MAE	16.8148	RMSE	27.4824	MAPE	23.0736
2023-04-18 22:48:47,044 - [*] Year 2015 load from data/district3F11T17/FastData/2015_30day.npz
2023-04-18 22:48:47,300 - [*] Year 2015 Dataset load!
2023-04-18 22:48:47,300 - [*] load from exp/district3F11T17/incremental-naive2023-04-18-22:41:35.345044/2014/best_model.pkl
2023-04-18 22:49:32,025 - [*] Year 2015 Training start
2023-04-18 22:49:34,238 - node number torch.Size([106752, 12])
2023-04-18 22:49:36,346 - epoch:0, training loss:17.5627 validation loss:16.3597
2023-04-18 22:49:38,450 - epoch:1, training loss:16.2392 validation loss:16.1883
2023-04-18 22:49:40,609 - epoch:2, training loss:16.0878 validation loss:16.1850
2023-04-18 22:49:42,683 - epoch:3, training loss:16.1275 validation loss:16.1471
2023-04-18 22:49:44,890 - epoch:4, training loss:16.2492 validation loss:16.2393
2023-04-18 22:49:47,145 - epoch:5, training loss:16.2242 validation loss:16.9285
2023-04-18 22:49:49,616 - epoch:6, training loss:16.2036 validation loss:16.3615
2023-04-18 22:49:52,085 - epoch:7, training loss:16.1484 validation loss:16.1847
2023-04-18 22:49:54,402 - epoch:8, training loss:16.0807 validation loss:16.0982
2023-04-18 22:49:56,636 - epoch:9, training loss:16.1535 validation loss:16.1316
2023-04-18 22:49:58,857 - epoch:10, training loss:16.1588 validation loss:16.0938
2023-04-18 22:50:01,120 - epoch:11, training loss:16.1013 validation loss:16.2901
2023-04-18 22:50:03,346 - epoch:12, training loss:16.1563 validation loss:16.2055
2023-04-18 22:50:05,564 - epoch:13, training loss:16.1034 validation loss:16.4437
2023-04-18 22:50:07,822 - epoch:14, training loss:16.1011 validation loss:16.2351
2023-04-18 22:50:10,015 - epoch:15, training loss:16.0433 validation loss:16.2994
2023-04-18 22:50:12,333 - epoch:16, training loss:16.0521 validation loss:16.3821
2023-04-18 22:50:12,338 - Finished optimization, total time:30.16 s, best model:exp/district3F11T17/incremental-naive2023-04-18-22:41:35.345044/2015/16.0938_epoch_10.pkl
2023-04-18 22:50:13,131 - [*] loss:711.8552
2023-04-18 22:50:13,315 - [*] year 2015, testing
2023-04-18 22:50:13,514 - T:3	MAE	12.6610	RMSE	20.4074	MAPE	18.4481
2023-04-18 22:50:14,321 - T:6	MAE	13.8640	RMSE	22.7546	MAPE	20.0716
2023-04-18 22:50:15,524 - T:12	MAE	16.2228	RMSE	26.9621	MAPE	24.2263
2023-04-18 22:50:15,530 - [*] Year 2016 load from data/district3F11T17/FastData/2016_30day.npz
2023-04-18 22:50:15,766 - [*] Year 2016 Dataset load!
2023-04-18 22:50:15,766 - [*] load from exp/district3F11T17/incremental-naive2023-04-18-22:41:35.345044/2015/best_model.pkl
2023-04-18 22:51:15,365 - [*] Year 2016 Training start
2023-04-18 22:51:18,055 - node number torch.Size([108800, 12])
2023-04-18 22:51:21,130 - epoch:0, training loss:18.2164 validation loss:16.1740
2023-04-18 22:51:23,238 - epoch:1, training loss:16.1166 validation loss:15.7360
2023-04-18 22:51:25,308 - epoch:2, training loss:16.0388 validation loss:15.9215
2023-04-18 22:51:27,447 - epoch:3, training loss:16.0622 validation loss:15.7402
2023-04-18 22:51:29,579 - epoch:4, training loss:16.0406 validation loss:15.8310
2023-04-18 22:51:31,709 - epoch:5, training loss:16.0466 validation loss:15.7464
2023-04-18 22:51:33,823 - epoch:6, training loss:16.0864 validation loss:16.1836
2023-04-18 22:51:35,950 - epoch:7, training loss:16.1348 validation loss:15.7346
2023-04-18 22:51:38,059 - epoch:8, training loss:16.0837 validation loss:15.7760
2023-04-18 22:51:40,193 - epoch:9, training loss:16.0359 validation loss:15.8754
2023-04-18 22:51:42,305 - epoch:10, training loss:16.2778 validation loss:16.2253
2023-04-18 22:51:44,442 - epoch:11, training loss:16.1072 validation loss:15.8414
2023-04-18 22:51:46,624 - epoch:12, training loss:16.1557 validation loss:15.8843
2023-04-18 22:51:48,800 - epoch:13, training loss:16.1191 validation loss:15.9733
2023-04-18 22:51:49,450 - Finished optimization, total time:25.66 s, best model:exp/district3F11T17/incremental-naive2023-04-18-22:41:35.345044/2016/15.7346_epoch_7.pkl
2023-04-18 22:51:50,805 - [*] loss:764.4877
2023-04-18 22:51:50,954 - [*] year 2016, testing
2023-04-18 22:51:51,150 - T:3	MAE	12.0674	RMSE	21.4495	MAPE	16.1938
2023-04-18 22:51:51,596 - T:6	MAE	13.2445	RMSE	23.8249	MAPE	17.6347
2023-04-18 22:51:52,491 - T:12	MAE	15.5783	RMSE	27.8959	MAPE	21.4590
2023-04-18 22:51:52,496 - [*] Year 2017 load from data/district3F11T17/FastData/2017_30day.npz
2023-04-18 22:51:52,734 - [*] Year 2017 Dataset load!
2023-04-18 22:51:52,770 - [*] load from exp/district3F11T17/incremental-naive2023-04-18-22:41:35.345044/2016/best_model.pkl
2023-04-18 22:52:16,375 - [*] Year 2017 Training start
2023-04-18 22:52:16,886 - node number torch.Size([111488, 12])
2023-04-18 22:52:19,167 - epoch:0, training loss:19.1748 validation loss:17.7572
2023-04-18 22:52:21,246 - epoch:1, training loss:17.8278 validation loss:17.6724
2023-04-18 22:52:23,320 - epoch:2, training loss:17.7775 validation loss:17.7010
2023-04-18 22:52:25,441 - epoch:3, training loss:17.8687 validation loss:18.0896
2023-04-18 22:52:27,630 - epoch:4, training loss:17.7813 validation loss:17.6036
2023-04-18 22:52:29,852 - epoch:5, training loss:17.7664 validation loss:17.7253
2023-04-18 22:52:32,099 - epoch:6, training loss:17.7281 validation loss:17.9060
2023-04-18 22:52:34,541 - epoch:7, training loss:17.7627 validation loss:17.5551
2023-04-18 22:52:36,767 - epoch:8, training loss:17.8126 validation loss:17.9881
2023-04-18 22:52:39,057 - epoch:9, training loss:17.8316 validation loss:17.6945
2023-04-18 22:52:41,243 - epoch:10, training loss:17.7640 validation loss:17.4189
2023-04-18 22:52:43,467 - epoch:11, training loss:17.7290 validation loss:17.4564
2023-04-18 22:52:45,685 - epoch:12, training loss:17.8630 validation loss:17.7205
2023-04-18 22:52:47,927 - epoch:13, training loss:17.7902 validation loss:17.8887
2023-04-18 22:52:50,140 - epoch:14, training loss:17.9152 validation loss:17.5006
2023-04-18 22:52:52,355 - epoch:15, training loss:17.8765 validation loss:17.5828
2023-04-18 22:52:54,634 - epoch:16, training loss:17.7079 validation loss:17.5072
2023-04-18 22:52:54,868 - Finished optimization, total time:28.52 s, best model:exp/district3F11T17/incremental-naive2023-04-18-22:41:35.345044/2017/17.4189_epoch_10.pkl
2023-04-18 22:52:56,078 - [*] loss:793.4157
2023-04-18 22:52:56,225 - [*] year 2017, testing
2023-04-18 22:52:56,579 - T:3	MAE	13.6007	RMSE	22.1963	MAPE	20.0828
2023-04-18 22:52:57,343 - T:6	MAE	14.8311	RMSE	24.3850	MAPE	22.4766
2023-04-18 22:52:58,640 - T:12	MAE	17.2704	RMSE	28.4028	MAPE	27.9569
2023-04-18 22:52:58,644 - 3	mae	13.05	12.48	12.34	13.21	12.66	12.07	13.60	
2023-04-18 22:52:58,644 - 3	rmse	19.90	19.47	19.73	21.10	20.41	21.45	22.20	
2023-04-18 22:52:58,644 - 3	mape	17.24	17.04	18.90	17.88	18.45	16.19	20.08	
2023-04-18 22:52:58,644 - 6	mae	14.06	13.61	13.61	14.39	13.86	13.24	14.83	
2023-04-18 22:52:58,644 - 6	rmse	21.70	21.47	21.99	23.28	22.75	23.82	24.38	
2023-04-18 22:52:58,644 - 6	mape	19.00	18.65	22.17	19.05	20.07	17.63	22.48	
2023-04-18 22:52:58,644 - 12	mae	16.31	15.75	16.22	16.81	16.22	15.58	17.27	
2023-04-18 22:52:58,644 - 12	rmse	25.47	25.24	26.33	27.48	26.96	27.90	28.40	
2023-04-18 22:52:58,644 - 12	mape	23.75	22.32	29.08	23.07	24.23	21.46	27.96	
2023-04-18 22:52:58,644 - year	2011	total_time	90.78174000000003	average_time	1.7805682745098041	epoch	51
2023-04-18 22:52:58,644 - year	2012	total_time	45.28185799999999	average_time	1.6771155925925925	epoch	27
2023-04-18 22:52:58,644 - year	2013	total_time	24.452691	average_time	1.7466305714285715	epoch	14
2023-04-18 22:52:58,644 - year	2014	total_time	19.682230999999998	average_time	1.9682553999999999	epoch	10
2023-04-18 22:52:58,644 - year	2015	total_time	30.156369000000005	average_time	1.7739136470588235	epoch	17
2023-04-18 22:52:58,644 - year	2016	total_time	25.659318999999996	average_time	1.8328179999999998	epoch	14
2023-04-18 22:52:58,644 - year	2017	total_time	28.517668999999998	average_time	1.6775200588235295	epoch	17
