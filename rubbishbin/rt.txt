2023-04-18 23:35:12,724 - logger name:exp/district3F11T17/retrain_model2023-04-18-23:35:12.657111/retrain_model.log
2023-04-18 23:35:12,725 - params : {'conf': 'retrain_model', 'load_config': 'configs/', 'data_process': False, 'auto_test': 1, 'load': True, 'device': device(type='cuda', index=0), 'data_name': 'PEMS3-Stream', 'raw_data_path': 'data/district3F11T17/finaldata/', 'graph_path': 'data/district3F11T17/graph/', 'save_data_path': 'data/district3F11T17/FastData/', 'model_path': 'exp/district3F11T17/', 'year': 2012, 'days': 31, 'logname': 'retrain_model', '/* model related args*/': '//', 'y_len': 12, 'dropout': 0.0, 'gcn': {'in_channel': 12, 'out_channel': 12, 'hidden_channel': 64}, 'tcn': {'in_channel': 1, 'out_channel': 1, 'kernel_size': 3, 'dilation': 1}, '/*train related args*/': '//', 'train': True, 'begin_year': 2011, 'end_year': 2017, 'epoch': 100, 'batch_size': 128, 'lr': 0.01, 'loss': 'mse', '/*strategy related args*/': '//', 'strategy': 'retrain', 'increase': False, 'detect': False, 'replay': False, 'ewc': False, 'ewc_strategy': 'ewc', 'ewc_lambda': 1.0, 'subgraph_train': False, 'time': '2023-04-18-23:35:12.657111', 'path': 'exp/district3F11T17/retrain_model2023-04-18-23:35:12.657111', 'logger': <Logger __main__ (INFO)>}
2023-04-18 23:35:12,725 - [*] Year 2011 load from data/district3F11T17/FastData/2011_30day.npz
2023-04-18 23:35:46,216 - [*] Year 2011 Dataset load!
2023-04-18 23:36:43,926 - [*] Year 2011 Training start
2023-04-18 23:36:44,539 - node number torch.Size([83840, 12])
2023-04-18 23:36:54,014 - epoch:0, training loss:98.9984 validation loss:51.6941
2023-04-18 23:36:56,183 - epoch:1, training loss:37.9545 validation loss:27.7959
2023-04-18 23:36:57,869 - epoch:2, training loss:25.3123 validation loss:22.5087
2023-04-18 23:36:59,546 - epoch:3, training loss:22.1610 validation loss:20.5532
2023-04-18 23:37:01,124 - epoch:4, training loss:20.5842 validation loss:19.4505
2023-04-18 23:37:02,737 - epoch:5, training loss:19.6448 validation loss:19.3844
2023-04-18 23:37:04,362 - epoch:6, training loss:19.0565 validation loss:18.5681
2023-04-18 23:37:05,985 - epoch:7, training loss:18.7368 validation loss:18.5246
2023-04-18 23:37:07,611 - epoch:8, training loss:18.5264 validation loss:18.3150
2023-04-18 23:37:09,194 - epoch:9, training loss:18.4108 validation loss:18.1499
2023-04-18 23:37:10,796 - epoch:10, training loss:18.3011 validation loss:17.9418
2023-04-18 23:37:12,442 - epoch:11, training loss:18.1272 validation loss:18.3113
2023-04-18 23:37:14,041 - epoch:12, training loss:18.1906 validation loss:17.7855
2023-04-18 23:37:15,601 - epoch:13, training loss:17.9171 validation loss:17.6672
2023-04-18 23:37:17,362 - epoch:14, training loss:17.7737 validation loss:17.7934
2023-04-18 23:37:19,025 - epoch:15, training loss:17.6618 validation loss:17.3328
2023-04-18 23:37:20,589 - epoch:16, training loss:17.6705 validation loss:17.1943
2023-04-18 23:37:22,189 - epoch:17, training loss:17.3895 validation loss:17.6085
2023-04-18 23:37:23,811 - epoch:18, training loss:17.3182 validation loss:17.1149
2023-04-18 23:37:25,438 - epoch:19, training loss:17.1850 validation loss:16.9659
2023-04-18 23:37:27,229 - epoch:20, training loss:17.1056 validation loss:17.2881
2023-04-18 23:37:28,882 - epoch:21, training loss:16.9980 validation loss:16.7319
2023-04-18 23:37:30,523 - epoch:22, training loss:16.9306 validation loss:16.6515
2023-04-18 23:37:32,190 - epoch:23, training loss:16.9592 validation loss:16.6356
2023-04-18 23:37:33,859 - epoch:24, training loss:16.8726 validation loss:16.8389
2023-04-18 23:37:35,449 - epoch:25, training loss:16.8631 validation loss:16.5725
2023-04-18 23:37:37,119 - epoch:26, training loss:16.9164 validation loss:16.4464
2023-04-18 23:37:38,761 - epoch:27, training loss:16.7603 validation loss:17.0866
2023-04-18 23:37:40,379 - epoch:28, training loss:16.7736 validation loss:16.4996
2023-04-18 23:37:41,992 - epoch:29, training loss:16.6970 validation loss:16.7912
2023-04-18 23:37:43,654 - epoch:30, training loss:16.6675 validation loss:16.3940
2023-04-18 23:37:45,270 - epoch:31, training loss:16.5769 validation loss:16.3884
2023-04-18 23:37:46,888 - epoch:32, training loss:16.6362 validation loss:16.4474
2023-04-18 23:37:48,553 - epoch:33, training loss:16.5851 validation loss:16.3374
2023-04-18 23:37:50,177 - epoch:34, training loss:16.6269 validation loss:16.4796
2023-04-18 23:37:51,838 - epoch:35, training loss:16.6366 validation loss:16.7755
2023-04-18 23:37:53,483 - epoch:36, training loss:16.6142 validation loss:16.3624
2023-04-18 23:37:55,072 - epoch:37, training loss:16.6228 validation loss:16.2902
2023-04-18 23:37:56,663 - epoch:38, training loss:16.5222 validation loss:16.4647
2023-04-18 23:37:58,245 - epoch:39, training loss:16.5082 validation loss:16.3712
2023-04-18 23:37:59,848 - epoch:40, training loss:16.4836 validation loss:16.3257
2023-04-18 23:38:01,444 - epoch:41, training loss:16.5027 validation loss:16.4434
2023-04-18 23:38:03,170 - epoch:42, training loss:16.4552 validation loss:16.4578
2023-04-18 23:38:04,782 - epoch:43, training loss:16.4650 validation loss:16.3891
2023-04-18 23:38:04,823 - Finished optimization, total time:61.59 s, best model:exp/district3F11T17/retrain_model2023-04-18-23:35:12.657111/2011/16.2902_epoch_37.pkl
2023-04-18 23:38:05,767 - [*] loss:622.4694
2023-04-18 23:38:05,969 - [*] year 2011, testing
2023-04-18 23:38:06,288 - T:3	MAE	12.9278	RMSE	19.7306	MAPE	16.0873
2023-04-18 23:38:06,614 - T:6	MAE	13.9566	RMSE	21.5588	MAPE	17.6727
2023-04-18 23:38:07,367 - T:12	MAE	16.0764	RMSE	25.1620	MAPE	21.0695
2023-04-18 23:38:07,371 - [*] Year 2012 load from data/district3F11T17/FastData/2012_30day.npz
2023-04-18 23:38:07,507 - [*] Year 2012 Dataset load!
2023-04-18 23:38:27,523 - [*] Year 2012 Training start
2023-04-18 23:38:28,621 - node number torch.Size([91520, 12])
2023-04-18 23:38:30,245 - epoch:0, training loss:96.2236 validation loss:52.7154
2023-04-18 23:38:32,061 - epoch:1, training loss:35.6205 validation loss:26.6926
2023-04-18 23:38:33,798 - epoch:2, training loss:23.3344 validation loss:20.2898
2023-04-18 23:38:35,588 - epoch:3, training loss:19.7040 validation loss:18.6807
2023-04-18 23:38:37,353 - epoch:4, training loss:18.8552 validation loss:18.1723
2023-04-18 23:38:39,095 - epoch:5, training loss:18.5185 validation loss:17.9845
2023-04-18 23:38:40,945 - epoch:6, training loss:18.3007 validation loss:17.7871
2023-04-18 23:38:42,711 - epoch:7, training loss:18.0756 validation loss:17.5927
2023-04-18 23:38:44,434 - epoch:8, training loss:17.8715 validation loss:17.4963
2023-04-18 23:38:46,850 - epoch:9, training loss:17.7259 validation loss:17.2603
2023-04-18 23:38:48,657 - epoch:10, training loss:17.6370 validation loss:17.0819
2023-04-18 23:38:50,486 - epoch:11, training loss:17.4477 validation loss:16.9923
2023-04-18 23:38:52,373 - epoch:12, training loss:17.3351 validation loss:16.9241
2023-04-18 23:38:54,202 - epoch:13, training loss:17.3912 validation loss:16.8749
2023-04-18 23:38:55,980 - epoch:14, training loss:17.3743 validation loss:16.8613
2023-04-18 23:38:57,873 - epoch:15, training loss:17.1345 validation loss:17.0508
2023-04-18 23:38:59,844 - epoch:16, training loss:17.0257 validation loss:16.5031
2023-04-18 23:39:01,747 - epoch:17, training loss:16.9208 validation loss:16.6948
2023-04-18 23:39:03,637 - epoch:18, training loss:16.9215 validation loss:16.3979
2023-04-18 23:39:05,522 - epoch:19, training loss:16.7408 validation loss:16.3116
2023-04-18 23:39:07,365 - epoch:20, training loss:16.6714 validation loss:16.3773
2023-04-18 23:39:09,287 - epoch:21, training loss:16.6195 validation loss:16.1616
2023-04-18 23:39:11,172 - epoch:22, training loss:16.6042 validation loss:16.1168
2023-04-18 23:39:13,051 - epoch:23, training loss:16.5284 validation loss:16.0477
2023-04-18 23:39:14,936 - epoch:24, training loss:16.5421 validation loss:16.5177
2023-04-18 23:39:16,831 - epoch:25, training loss:16.5508 validation loss:16.2008
2023-04-18 23:39:18,769 - epoch:26, training loss:16.4117 validation loss:16.1765
2023-04-18 23:39:20,707 - epoch:27, training loss:16.3762 validation loss:16.1460
2023-04-18 23:39:22,580 - epoch:28, training loss:16.3762 validation loss:15.9027
2023-04-18 23:39:24,450 - epoch:29, training loss:16.3483 validation loss:15.8679
2023-04-18 23:39:26,302 - epoch:30, training loss:16.2687 validation loss:15.8780
2023-04-18 23:39:28,142 - epoch:31, training loss:16.2927 validation loss:15.9674
2023-04-18 23:39:29,985 - epoch:32, training loss:16.2733 validation loss:15.9768
2023-04-18 23:39:31,805 - epoch:33, training loss:16.4065 validation loss:15.9325
2023-04-18 23:39:33,668 - epoch:34, training loss:16.2561 validation loss:15.7756
2023-04-18 23:39:35,597 - epoch:35, training loss:16.2104 validation loss:15.9235
2023-04-18 23:39:37,509 - epoch:36, training loss:16.1992 validation loss:15.7469
2023-04-18 23:39:39,494 - epoch:37, training loss:16.2409 validation loss:15.7790
2023-04-18 23:39:41,396 - epoch:38, training loss:16.2220 validation loss:15.7647
2023-04-18 23:39:43,266 - epoch:39, training loss:16.1460 validation loss:15.7349
2023-04-18 23:39:45,211 - epoch:40, training loss:16.1552 validation loss:15.6899
2023-04-18 23:39:47,091 - epoch:41, training loss:16.1755 validation loss:15.6997
2023-04-18 23:39:48,987 - epoch:42, training loss:16.2340 validation loss:15.6624
2023-04-18 23:39:50,907 - epoch:43, training loss:16.1332 validation loss:15.8171
2023-04-18 23:39:52,761 - epoch:44, training loss:16.1329 validation loss:15.8235
2023-04-18 23:39:54,672 - epoch:45, training loss:16.1331 validation loss:15.7589
2023-04-18 23:39:56,582 - epoch:46, training loss:16.1897 validation loss:15.7374
2023-04-18 23:39:58,446 - epoch:47, training loss:16.1004 validation loss:15.6330
2023-04-18 23:40:00,358 - epoch:48, training loss:16.1124 validation loss:15.6384
2023-04-18 23:40:02,237 - epoch:49, training loss:16.1134 validation loss:15.6386
2023-04-18 23:40:04,142 - epoch:50, training loss:16.0671 validation loss:15.6285
2023-04-18 23:40:06,060 - epoch:51, training loss:16.0178 validation loss:15.6492
2023-04-18 23:40:07,949 - epoch:52, training loss:16.0060 validation loss:15.6014
2023-04-18 23:40:09,866 - epoch:53, training loss:16.0581 validation loss:15.5750
2023-04-18 23:40:11,773 - epoch:54, training loss:16.0245 validation loss:15.5610
2023-04-18 23:40:13,659 - epoch:55, training loss:16.0623 validation loss:15.6323
2023-04-18 23:40:15,572 - epoch:56, training loss:16.0269 validation loss:15.9658
2023-04-18 23:40:17,510 - epoch:57, training loss:16.0187 validation loss:15.6074
2023-04-18 23:40:19,388 - epoch:58, training loss:15.9933 validation loss:16.0274
2023-04-18 23:40:21,230 - epoch:59, training loss:16.0284 validation loss:15.5329
2023-04-18 23:40:23,128 - epoch:60, training loss:16.0231 validation loss:15.5369
2023-04-18 23:40:25,023 - epoch:61, training loss:16.0250 validation loss:15.5830
2023-04-18 23:40:26,903 - epoch:62, training loss:15.9722 validation loss:15.5202
2023-04-18 23:40:28,810 - epoch:63, training loss:16.0361 validation loss:15.6420
2023-04-18 23:40:30,673 - epoch:64, training loss:15.9696 validation loss:15.6955
2023-04-18 23:40:32,606 - epoch:65, training loss:16.0020 validation loss:15.5380
2023-04-18 23:40:34,523 - epoch:66, training loss:15.9795 validation loss:15.5183
2023-04-18 23:40:36,394 - epoch:67, training loss:15.9300 validation loss:15.6665
2023-04-18 23:40:38,259 - epoch:68, training loss:15.9440 validation loss:15.5682
2023-04-18 23:40:40,241 - epoch:69, training loss:15.9639 validation loss:15.6539
2023-04-18 23:40:42,127 - epoch:70, training loss:16.1002 validation loss:15.5527
2023-04-18 23:40:44,069 - epoch:71, training loss:15.9322 validation loss:15.4967
2023-04-18 23:40:45,960 - epoch:72, training loss:15.9879 validation loss:15.4978
2023-04-18 23:40:47,801 - epoch:73, training loss:15.8943 validation loss:15.6081
2023-04-18 23:40:49,746 - epoch:74, training loss:15.9889 validation loss:15.5542
2023-04-18 23:40:51,682 - epoch:75, training loss:15.9537 validation loss:15.5406
2023-04-18 23:40:53,551 - epoch:76, training loss:15.9437 validation loss:15.6072
2023-04-18 23:40:55,467 - epoch:77, training loss:16.0318 validation loss:15.6020
2023-04-18 23:40:56,273 - Finished optimization, total time:110.34 s, best model:exp/district3F11T17/retrain_model2023-04-18-23:35:12.657111/2012/15.4967_epoch_71.pkl
2023-04-18 23:40:58,901 - [*] loss:599.0294
2023-04-18 23:40:58,994 - [*] year 2012, testing
2023-04-18 23:40:59,158 - T:3	MAE	12.3812	RMSE	19.3102	MAPE	16.4434
2023-04-18 23:40:59,752 - T:6	MAE	13.3537	RMSE	21.0561	MAPE	17.6083
2023-04-18 23:41:00,909 - T:12	MAE	15.4468	RMSE	24.6802	MAPE	21.1258
2023-04-18 23:41:00,914 - [*] Year 2013 load from data/district3F11T17/FastData/2013_30day.npz
2023-04-18 23:41:01,271 - [*] Year 2013 Dataset load!
2023-04-18 23:41:20,044 - [*] Year 2013 Training start
2023-04-18 23:41:21,755 - node number torch.Size([100608, 12])
2023-04-18 23:41:23,933 - epoch:0, training loss:99.5950 validation loss:58.9704
2023-04-18 23:41:25,993 - epoch:1, training loss:37.4046 validation loss:28.0670
2023-04-18 23:41:28,086 - epoch:2, training loss:23.4830 validation loss:20.8759
2023-04-18 23:41:30,033 - epoch:3, training loss:19.0518 validation loss:18.9297
2023-04-18 23:41:32,147 - epoch:4, training loss:18.0269 validation loss:18.3607
2023-04-18 23:41:34,225 - epoch:5, training loss:17.6752 validation loss:17.9783
2023-04-18 23:41:36,326 - epoch:6, training loss:17.4856 validation loss:18.0999
2023-04-18 23:41:38,399 - epoch:7, training loss:17.3012 validation loss:18.3207
2023-04-18 23:41:40,410 - epoch:8, training loss:17.1427 validation loss:17.8051
2023-04-18 23:41:42,492 - epoch:9, training loss:17.0188 validation loss:17.4709
2023-04-18 23:41:44,598 - epoch:10, training loss:16.8293 validation loss:17.2701
2023-04-18 23:41:46,702 - epoch:11, training loss:16.7321 validation loss:17.8073
2023-04-18 23:41:48,821 - epoch:12, training loss:16.6766 validation loss:17.1682
2023-04-18 23:41:50,875 - epoch:13, training loss:16.4880 validation loss:17.2689
2023-04-18 23:41:52,947 - epoch:14, training loss:16.3948 validation loss:16.7866
2023-04-18 23:41:54,988 - epoch:15, training loss:16.4870 validation loss:16.9751
2023-04-18 23:41:57,097 - epoch:16, training loss:16.2392 validation loss:17.1066
2023-04-18 23:41:59,197 - epoch:17, training loss:16.2766 validation loss:16.5996
2023-04-18 23:42:01,361 - epoch:18, training loss:16.2271 validation loss:16.8644
2023-04-18 23:42:03,528 - epoch:19, training loss:16.1158 validation loss:16.6303
2023-04-18 23:42:05,614 - epoch:20, training loss:16.2447 validation loss:16.9888
2023-04-18 23:42:07,676 - epoch:21, training loss:16.0421 validation loss:17.0117
2023-04-18 23:42:09,751 - epoch:22, training loss:16.0704 validation loss:17.2593
2023-04-18 23:42:11,912 - epoch:23, training loss:16.0857 validation loss:16.6174
2023-04-18 23:42:12,422 - Finished optimization, total time:39.18 s, best model:exp/district3F11T17/retrain_model2023-04-18-23:35:12.657111/2013/16.5996_epoch_17.pkl
2023-04-18 23:42:13,644 - [*] loss:721.6929
2023-04-18 23:42:13,787 - [*] year 2013, testing
2023-04-18 23:42:14,006 - T:3	MAE	13.1476	RMSE	20.6404	MAPE	23.4536
2023-04-18 23:42:14,573 - T:6	MAE	14.3008	RMSE	22.8013	MAPE	25.1320
2023-04-18 23:42:15,801 - T:12	MAE	16.7275	RMSE	27.0784	MAPE	27.4690
2023-04-18 23:42:15,805 - [*] Year 2014 load from data/district3F11T17/FastData/2014_30day.npz
2023-04-18 23:42:16,078 - [*] Year 2014 Dataset load!
2023-04-18 23:42:31,273 - [*] Year 2014 Training start
2023-04-18 23:42:32,777 - node number torch.Size([105216, 12])
2023-04-18 23:42:34,932 - epoch:0, training loss:99.3342 validation loss:59.6997
2023-04-18 23:42:37,126 - epoch:1, training loss:46.3329 validation loss:38.8409
2023-04-18 23:42:39,374 - epoch:2, training loss:35.7017 validation loss:33.4095
2023-04-18 23:42:41,480 - epoch:3, training loss:28.2738 validation loss:23.5377
2023-04-18 23:42:43,688 - epoch:4, training loss:20.3814 validation loss:19.4634
2023-04-18 23:42:45,828 - epoch:5, training loss:19.2394 validation loss:19.1399
2023-04-18 23:42:47,977 - epoch:6, training loss:19.0542 validation loss:19.5743
2023-04-18 23:42:50,210 - epoch:7, training loss:18.8836 validation loss:18.8137
2023-04-18 23:42:52,447 - epoch:8, training loss:18.6691 validation loss:18.6683
2023-04-18 23:42:54,654 - epoch:9, training loss:18.5196 validation loss:19.1223
2023-04-18 23:42:56,795 - epoch:10, training loss:18.5574 validation loss:18.4580
2023-04-18 23:42:58,909 - epoch:11, training loss:18.3660 validation loss:18.6298
2023-04-18 23:43:01,034 - epoch:12, training loss:18.3206 validation loss:18.3484
2023-04-18 23:43:03,181 - epoch:13, training loss:18.2998 validation loss:18.3546
2023-04-18 23:43:05,285 - epoch:14, training loss:18.1772 validation loss:18.5393
2023-04-18 23:43:07,410 - epoch:15, training loss:18.1181 validation loss:18.4770
2023-04-18 23:43:09,529 - epoch:16, training loss:18.1298 validation loss:18.3303
2023-04-18 23:43:11,666 - epoch:17, training loss:18.0870 validation loss:18.0876
2023-04-18 23:43:13,809 - epoch:18, training loss:18.0000 validation loss:18.2535
2023-04-18 23:43:15,934 - epoch:19, training loss:17.9439 validation loss:18.4987
2023-04-18 23:43:18,082 - epoch:20, training loss:17.9174 validation loss:18.3261
2023-04-18 23:43:20,162 - epoch:21, training loss:17.7949 validation loss:18.5236
2023-04-18 23:43:22,330 - epoch:22, training loss:17.7298 validation loss:17.7967
2023-04-18 23:43:24,445 - epoch:23, training loss:17.6853 validation loss:17.7944
2023-04-18 23:43:26,535 - epoch:24, training loss:17.6092 validation loss:17.7916
2023-04-18 23:43:28,670 - epoch:25, training loss:17.5881 validation loss:17.6739
2023-04-18 23:43:30,786 - epoch:26, training loss:17.5410 validation loss:17.8460
2023-04-18 23:43:32,881 - epoch:27, training loss:17.4470 validation loss:17.6507
2023-04-18 23:43:35,053 - epoch:28, training loss:17.3978 validation loss:17.5666
2023-04-18 23:43:37,176 - epoch:29, training loss:17.3885 validation loss:17.5958
2023-04-18 23:43:39,329 - epoch:30, training loss:17.4012 validation loss:17.5656
2023-04-18 23:43:41,482 - epoch:31, training loss:17.4159 validation loss:17.6390
2023-04-18 23:43:43,651 - epoch:32, training loss:17.3321 validation loss:17.4432
2023-04-18 23:43:45,740 - epoch:33, training loss:17.3758 validation loss:17.6854
2023-04-18 23:43:47,862 - epoch:34, training loss:17.2466 validation loss:17.5460
2023-04-18 23:43:49,987 - epoch:35, training loss:17.2458 validation loss:17.5691
2023-04-18 23:43:52,136 - epoch:36, training loss:17.5401 validation loss:17.4989
2023-04-18 23:43:54,375 - epoch:37, training loss:17.3739 validation loss:17.7481
2023-04-18 23:43:56,522 - epoch:38, training loss:17.2783 validation loss:17.4451
2023-04-18 23:43:56,928 - Finished optimization, total time:64.39 s, best model:exp/district3F11T17/retrain_model2023-04-18-23:35:12.657111/2014/17.4432_epoch_32.pkl
2023-04-18 23:43:58,535 - [*] loss:776.8986
2023-04-18 23:43:58,688 - [*] year 2014, testing
2023-04-18 23:43:58,950 - T:3	MAE	13.4873	RMSE	21.3658	MAPE	21.6155
2023-04-18 23:43:59,682 - T:6	MAE	14.6472	RMSE	23.6041	MAPE	22.8572
2023-04-18 23:44:00,586 - T:12	MAE	17.2715	RMSE	28.1729	MAPE	26.2122
2023-04-18 23:44:00,587 - [*] Year 2015 load from data/district3F11T17/FastData/2015_30day.npz
2023-04-18 23:44:01,366 - [*] Year 2015 Dataset load!
2023-04-18 23:44:21,896 - [*] Year 2015 Training start
2023-04-18 23:44:22,552 - node number torch.Size([106752, 12])
2023-04-18 23:44:24,607 - epoch:0, training loss:99.6215 validation loss:42.3942
2023-04-18 23:44:26,854 - epoch:1, training loss:30.4845 validation loss:24.0815
2023-04-18 23:44:29,050 - epoch:2, training loss:21.9737 validation loss:20.1306
2023-04-18 23:44:31,237 - epoch:3, training loss:19.6999 validation loss:19.3541
2023-04-18 23:44:33,357 - epoch:4, training loss:18.5474 validation loss:18.0073
2023-04-18 23:44:35,489 - epoch:5, training loss:17.4469 validation loss:16.8710
2023-04-18 23:44:37,668 - epoch:6, training loss:16.7792 validation loss:17.0927
2023-04-18 23:44:39,869 - epoch:7, training loss:16.5326 validation loss:16.5409
2023-04-18 23:44:42,110 - epoch:8, training loss:16.3446 validation loss:16.3922
2023-04-18 23:44:44,306 - epoch:9, training loss:16.3692 validation loss:16.6050
2023-04-18 23:44:46,524 - epoch:10, training loss:16.2178 validation loss:16.4618
2023-04-18 23:44:48,744 - epoch:11, training loss:16.1554 validation loss:16.2475
2023-04-18 23:44:50,895 - epoch:12, training loss:16.1103 validation loss:16.2303
2023-04-18 23:44:53,088 - epoch:13, training loss:16.0851 validation loss:16.3446
2023-04-18 23:44:55,245 - epoch:14, training loss:16.1358 validation loss:16.3116
2023-04-18 23:44:57,496 - epoch:15, training loss:16.1291 validation loss:16.2123
2023-04-18 23:44:59,736 - epoch:16, training loss:16.1262 validation loss:16.1749
2023-04-18 23:45:02,006 - epoch:17, training loss:16.0590 validation loss:16.0196
2023-04-18 23:45:04,168 - epoch:18, training loss:16.1485 validation loss:16.0451
2023-04-18 23:45:06,475 - epoch:19, training loss:16.0340 validation loss:16.0754
2023-04-18 23:45:08,671 - epoch:20, training loss:16.0102 validation loss:16.0609
2023-04-18 23:45:10,818 - epoch:21, training loss:16.2171 validation loss:16.4811
2023-04-18 23:45:13,076 - epoch:22, training loss:16.0593 validation loss:15.9883
2023-04-18 23:45:15,310 - epoch:23, training loss:16.0856 validation loss:16.1849
2023-04-18 23:45:17,495 - epoch:24, training loss:16.0880 validation loss:16.0099
2023-04-18 23:45:19,681 - epoch:25, training loss:16.0116 validation loss:16.1748
2023-04-18 23:45:21,880 - epoch:26, training loss:16.0136 validation loss:16.0575
2023-04-18 23:45:24,053 - epoch:27, training loss:15.9548 validation loss:16.3165
2023-04-18 23:45:26,216 - epoch:28, training loss:15.9400 validation loss:16.0866
2023-04-18 23:45:26,559 - Finished optimization, total time:48.01 s, best model:exp/district3F11T17/retrain_model2023-04-18-23:35:12.657111/2015/15.9883_epoch_22.pkl
2023-04-18 23:45:27,875 - [*] loss:704.5778
2023-04-18 23:45:27,997 - [*] year 2015, testing
2023-04-18 23:45:28,204 - T:3	MAE	12.7933	RMSE	20.6253	MAPE	18.9165
2023-04-18 23:45:28,689 - T:6	MAE	13.8984	RMSE	22.8166	MAPE	20.1291
2023-04-18 23:45:29,660 - T:12	MAE	16.1053	RMSE	26.8263	MAPE	22.4978
2023-04-18 23:45:29,661 - [*] Year 2016 load from data/district3F11T17/FastData/2016_30day.npz
2023-04-18 23:45:30,150 - [*] Year 2016 Dataset load!
2023-04-18 23:45:51,382 - [*] Year 2016 Training start
2023-04-18 23:45:53,400 - node number torch.Size([108800, 12])
2023-04-18 23:45:55,362 - epoch:0, training loss:97.2334 validation loss:62.7461
2023-04-18 23:45:57,477 - epoch:1, training loss:47.8803 validation loss:38.2414
2023-04-18 23:45:59,543 - epoch:2, training loss:33.1785 validation loss:29.0999
2023-04-18 23:46:01,698 - epoch:3, training loss:26.6717 validation loss:24.3164
2023-04-18 23:46:03,849 - epoch:4, training loss:22.9615 validation loss:21.3369
2023-04-18 23:46:06,116 - epoch:5, training loss:20.6113 validation loss:19.5359
2023-04-18 23:46:08,361 - epoch:6, training loss:19.3375 validation loss:18.3685
2023-04-18 23:46:10,545 - epoch:7, training loss:18.6788 validation loss:17.8859
2023-04-18 23:46:12,768 - epoch:8, training loss:18.2741 validation loss:17.5748
2023-04-18 23:46:14,925 - epoch:9, training loss:18.0641 validation loss:17.5274
2023-04-18 23:46:17,198 - epoch:10, training loss:17.9463 validation loss:17.6511
2023-04-18 23:46:19,457 - epoch:11, training loss:17.8668 validation loss:17.2081
2023-04-18 23:46:21,667 - epoch:12, training loss:17.7454 validation loss:17.1522
2023-04-18 23:46:23,871 - epoch:13, training loss:17.7594 validation loss:17.6269
2023-04-18 23:46:26,144 - epoch:14, training loss:17.7612 validation loss:17.2630
2023-04-18 23:46:28,361 - epoch:15, training loss:17.6491 validation loss:17.2260
2023-04-18 23:46:30,543 - epoch:16, training loss:17.5818 validation loss:17.2766
2023-04-18 23:46:32,786 - epoch:17, training loss:17.6613 validation loss:17.1362
2023-04-18 23:46:35,005 - epoch:18, training loss:17.6051 validation loss:16.9896
2023-04-18 23:46:37,231 - epoch:19, training loss:17.5317 validation loss:17.1470
2023-04-18 23:46:39,482 - epoch:20, training loss:17.4973 validation loss:17.0071
2023-04-18 23:46:41,704 - epoch:21, training loss:17.4509 validation loss:16.9050
2023-04-18 23:46:44,003 - epoch:22, training loss:17.4264 validation loss:16.8130
2023-04-18 23:46:46,249 - epoch:23, training loss:17.3077 validation loss:16.8212
2023-04-18 23:46:48,479 - epoch:24, training loss:17.2324 validation loss:16.8043
2023-04-18 23:46:50,726 - epoch:25, training loss:17.3674 validation loss:16.6511
2023-04-18 23:46:52,952 - epoch:26, training loss:17.1294 validation loss:16.5416
2023-04-18 23:46:55,210 - epoch:27, training loss:17.0566 validation loss:17.1911
2023-04-18 23:46:57,446 - epoch:28, training loss:17.0641 validation loss:16.5225
2023-04-18 23:46:59,589 - epoch:29, training loss:17.0269 validation loss:16.4904
2023-04-18 23:47:01,835 - epoch:30, training loss:17.0253 validation loss:16.5645
2023-04-18 23:47:07,082 - epoch:31, training loss:16.9836 validation loss:16.6994
2023-04-18 23:47:09,332 - epoch:32, training loss:16.9761 validation loss:16.7621
2023-04-18 23:47:11,530 - epoch:33, training loss:16.9836 validation loss:16.8913
2023-04-18 23:47:13,732 - epoch:34, training loss:16.9336 validation loss:16.4966
2023-04-18 23:47:15,919 - epoch:35, training loss:16.9540 validation loss:16.9461
2023-04-18 23:47:16,367 - Finished optimization, total time:63.89 s, best model:exp/district3F11T17/retrain_model2023-04-18-23:35:12.657111/2016/16.4904_epoch_29.pkl
2023-04-18 23:47:17,498 - [*] loss:852.2175
2023-04-18 23:47:17,663 - [*] year 2016, testing
2023-04-18 23:47:17,827 - T:3	MAE	12.3667	RMSE	22.0541	MAPE	17.1056
2023-04-18 23:47:18,148 - T:6	MAE	13.6658	RMSE	24.6817	MAPE	20.1227
2023-04-18 23:47:19,311 - T:12	MAE	16.3845	RMSE	29.4491	MAPE	26.9429
2023-04-18 23:47:19,317 - [*] Year 2017 load from data/district3F11T17/FastData/2017_30day.npz
2023-04-18 23:47:19,636 - [*] Year 2017 Dataset load!
2023-04-18 23:48:34,561 - [*] Year 2017 Training start
2023-04-18 23:48:38,591 - node number torch.Size([111488, 12])
2023-04-18 23:48:45,186 - epoch:0, training loss:104.6885 validation loss:50.3935
2023-04-18 23:48:47,557 - epoch:1, training loss:33.5914 validation loss:24.3951
2023-04-18 23:48:49,813 - epoch:2, training loss:22.6310 validation loss:20.8081
2023-04-18 23:48:51,958 - epoch:3, training loss:20.9635 validation loss:20.4249
2023-04-18 23:48:54,042 - epoch:4, training loss:20.6858 validation loss:20.0758
2023-04-18 23:48:56,189 - epoch:5, training loss:20.3316 validation loss:19.8828
2023-04-18 23:48:58,430 - epoch:6, training loss:20.0890 validation loss:19.9244
2023-04-18 23:49:00,613 - epoch:7, training loss:19.8236 validation loss:19.5696
2023-04-18 23:49:02,843 - epoch:8, training loss:19.6628 validation loss:19.5517
2023-04-18 23:49:05,045 - epoch:9, training loss:19.4667 validation loss:19.2828
2023-04-18 23:49:07,127 - epoch:10, training loss:19.3796 validation loss:19.3207
2023-04-18 23:49:09,249 - epoch:11, training loss:19.3030 validation loss:18.9300
2023-04-18 23:49:11,306 - epoch:12, training loss:19.1150 validation loss:19.2326
2023-04-18 23:49:13,477 - epoch:13, training loss:19.1396 validation loss:18.5164
2023-04-18 23:49:15,744 - epoch:14, training loss:18.9080 validation loss:18.2819
2023-04-18 23:49:18,025 - epoch:15, training loss:18.5127 validation loss:18.5482
2023-04-18 23:49:20,615 - epoch:16, training loss:18.3249 validation loss:17.9785
2023-04-18 23:49:22,975 - epoch:17, training loss:18.2413 validation loss:17.8696
2023-04-18 23:49:25,241 - epoch:18, training loss:18.1518 validation loss:17.8076
2023-04-18 23:49:27,460 - epoch:19, training loss:18.1047 validation loss:17.9320
2023-04-18 23:49:29,619 - epoch:20, training loss:18.0218 validation loss:17.9783
2023-04-18 23:49:31,853 - epoch:21, training loss:18.0302 validation loss:17.6751
2023-04-18 23:49:34,064 - epoch:22, training loss:17.9524 validation loss:17.8305
2023-04-18 23:49:36,273 - epoch:23, training loss:17.9961 validation loss:17.6919
2023-04-18 23:49:38,417 - epoch:24, training loss:17.9825 validation loss:17.8473
2023-04-18 23:49:40,498 - epoch:25, training loss:17.8857 validation loss:17.7598
2023-04-18 23:49:42,605 - epoch:26, training loss:17.9604 validation loss:17.5310
2023-04-18 23:49:44,734 - epoch:27, training loss:17.8896 validation loss:17.8479
2023-04-18 23:49:46,982 - epoch:28, training loss:17.8552 validation loss:18.0065
2023-04-18 23:49:49,377 - epoch:29, training loss:18.0614 validation loss:17.6146
2023-04-18 23:49:51,666 - epoch:30, training loss:17.8966 validation loss:18.3157
2023-04-18 23:49:53,954 - epoch:31, training loss:17.8649 validation loss:17.5714
2023-04-18 23:49:56,206 - epoch:32, training loss:17.8564 validation loss:17.5150
2023-04-18 23:49:58,482 - epoch:33, training loss:17.8718 validation loss:18.0198
2023-04-18 23:50:00,723 - epoch:34, training loss:17.8059 validation loss:17.6920
2023-04-18 23:50:03,041 - epoch:35, training loss:17.7901 validation loss:17.4309
2023-04-18 23:50:05,416 - epoch:36, training loss:17.7618 validation loss:17.4202
2023-04-18 23:50:07,779 - epoch:37, training loss:17.8610 validation loss:17.4841
2023-04-18 23:50:09,975 - epoch:38, training loss:17.7595 validation loss:17.6080
2023-04-18 23:50:12,147 - epoch:39, training loss:17.7177 validation loss:17.4595
2023-04-18 23:50:14,218 - epoch:40, training loss:17.7181 validation loss:17.6277
2023-04-18 23:50:16,497 - epoch:41, training loss:18.0014 validation loss:18.1188
2023-04-18 23:50:18,960 - epoch:42, training loss:17.8709 validation loss:17.8529
2023-04-18 23:50:19,015 - Finished optimization, total time:79.86 s, best model:exp/district3F11T17/retrain_model2023-04-18-23:35:12.657111/2017/17.4202_epoch_36.pkl
2023-04-18 23:50:19,877 - [*] loss:796.3596
2023-04-18 23:50:20,023 - [*] year 2017, testing
2023-04-18 23:50:20,232 - T:3	MAE	13.8301	RMSE	22.5003	MAPE	18.5933
2023-04-18 23:50:20,944 - T:6	MAE	14.9390	RMSE	24.5531	MAPE	20.2715
2023-04-18 23:50:22,097 - T:12	MAE	17.2336	RMSE	28.4474	MAPE	24.1426
2023-04-18 23:50:22,102 - 3	mae	12.93	12.38	13.15	13.49	12.79	12.37	13.83	
2023-04-18 23:50:22,102 - 3	rmse	19.73	19.31	20.64	21.37	20.63	22.05	22.50	
2023-04-18 23:50:22,102 - 3	mape	16.09	16.44	23.45	21.62	18.92	17.11	18.59	
2023-04-18 23:50:22,102 - 6	mae	13.96	13.35	14.30	14.65	13.90	13.67	14.94	
2023-04-18 23:50:22,102 - 6	rmse	21.56	21.06	22.80	23.60	22.82	24.68	24.55	
2023-04-18 23:50:22,102 - 6	mape	17.67	17.61	25.13	22.86	20.13	20.12	20.27	
2023-04-18 23:50:22,102 - 12	mae	16.08	15.45	16.73	17.27	16.11	16.38	17.23	
2023-04-18 23:50:22,102 - 12	rmse	25.16	24.68	27.08	28.17	26.83	29.45	28.45	
2023-04-18 23:50:22,102 - 12	mape	21.07	21.13	27.47	26.21	22.50	26.94	24.14	
2023-04-18 23:50:22,102 - year	2011	total_time	61.586956	average_time	1.3997121590909094	epoch	44
2023-04-18 23:50:22,102 - year	2012	total_time	110.34471900000001	average_time	1.4146855256410256	epoch	78
2023-04-18 23:50:22,102 - year	2013	total_time	39.17514899999999	average_time	1.632307833333333	epoch	24
2023-04-18 23:50:22,102 - year	2014	total_time	64.393785	average_time	1.6511317179487173	epoch	39
2023-04-18 23:50:22,102 - year	2015	total_time	48.009499	average_time	1.6555103103448279	epoch	29
2023-04-18 23:50:22,102 - year	2016	total_time	63.89292999999998	average_time	1.7748126666666666	epoch	36
2023-04-18 23:50:22,103 - year	2017	total_time	79.86376799999998	average_time	1.8573082790697681	epoch	43
