2023-06-19 18:27:31,244 - logger name:exp/ECL-Informer2023-06-19-18:27:31.244703/ECL-Informer.log
2023-06-19 18:27:31,245 - params : {'conf': 'ECL-Informer', 'data_name': 'electricity', 'iteration': 1, 'auto_test': 1, 'load': False, 'build_graph': False, 'root_path': '', 'exp_path': 'exp/', 'val_test_mix': False, 'end_phase': 1, 'seq_len': 96, 'pred_len': 96, 'device': device(type='cuda', index=1), '/* model related args*/': '//', 'model_name': 'informer', 'label_len': 48, 'features': 'M', 'target': 'OT', 'graph_input': False, 'individual': False, 'test_model_path': '/Disk/fhyega/code/PatchTST/PatchTST_supervised/checkpoints/electricity_96_96_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0/checkpoint.pth', 'e_layers': 2, 'd_layers': 1, 'factor': 3, 'n_heads': 8, 'd_model': 512, 'd_ff': 2048, 'dropout': 0.05, 'fc_dropout': 0.05, 'head_dropout': 0, 'patch_len': 16, 'stride': 8, 'des': 'Exp', 'padding_patch': 'end', 'revin': 1, 'affine': 0, 'subtract_last': 0, 'decomposition': 0, 'kernel_size': 25, 'output_attention': 0, 'embed_type': 0, 'activation': 'gelu', 'lradj': 'type3', 'distil': 1, 'linear_output': 0, '/*train related args*/': '//', 'train': True, 'epoch': 100, 'batch_size': 128, 'lr': 0.0001, 'loss': 'mse', '/*dataset related args*/': '//', 'save_data_path': 'data/ECL/', 'data_process': True, 'embed': 'timeF', 'freq': 'h', 'begin_phase': 0, 'phase_len': 26304, 'val_ratio': 0.33, 'graph_size': 321, '/*strategy related args*/': '//', 'strategy': 'incremental', 'increase': False, 'detect': False, 'detect_strategy': 'feature', 'replay': False, 'replay_strategy': 'random', 'repaly_num_samples': 100, 'ewc': False, 'ewc_strategy': 'ewc', 'ewc_lambda': 0.0001, 'subgraph_train': False, 'num_hops': 2, 'logname': 'ECL-Informer', 'time': '2023-06-19-18:27:31.244703', 'path': 'exp/ECL-Informer2023-06-19-18:27:31.244703', 'num_workers': 4, 'logger': <Logger __main__ (INFO)>}
2023-06-19 18:27:31,245 - [*] phase 0 start training
train 18221
val 2537
test 5165
2023-06-19 18:27:38,033 - [*] phase 0 Dataset load!
2023-06-19 18:27:39,327 - [*] phase 0 Training start
2023-06-19 18:28:22,849 - epoch:0, training loss:1.1822 validation loss:0.9826
Updating learning rate to 0.0001
2023-06-19 18:29:03,914 - epoch:1, training loss:0.7453 validation loss:0.5640
Updating learning rate to 0.0001
2023-06-19 18:29:45,463 - epoch:2, training loss:0.5012 validation loss:0.4771
Updating learning rate to 0.0001
2023-06-19 18:30:27,424 - epoch:3, training loss:0.4131 validation loss:0.4420
Updating learning rate to 9e-05
2023-06-19 18:31:09,261 - epoch:4, training loss:0.3208 validation loss:0.3377
Updating learning rate to 8.1e-05
2023-06-19 18:31:50,052 - epoch:5, training loss:0.2619 validation loss:0.3170
Updating learning rate to 7.290000000000001e-05
2023-06-19 18:32:31,560 - epoch:6, training loss:0.2313 validation loss:0.2897
Updating learning rate to 6.561e-05
2023-06-19 18:33:14,870 - epoch:7, training loss:0.2131 validation loss:0.2797
Updating learning rate to 5.904900000000001e-05
2023-06-19 18:33:57,681 - epoch:8, training loss:0.2014 validation loss:0.2793
Updating learning rate to 5.3144100000000005e-05
2023-06-19 18:34:41,360 - epoch:9, training loss:0.1924 validation loss:0.2665
Updating learning rate to 4.782969000000001e-05
2023-06-19 18:35:23,627 - epoch:10, training loss:0.1864 validation loss:0.2569
Updating learning rate to 4.304672100000001e-05
2023-06-19 18:36:07,067 - epoch:11, training loss:0.1815 validation loss:0.2564
Updating learning rate to 3.874204890000001e-05
2023-06-19 18:36:51,839 - epoch:12, training loss:0.1770 validation loss:0.2567
Updating learning rate to 3.486784401000001e-05
2023-06-19 18:37:34,164 - epoch:13, training loss:0.1737 validation loss:0.2530
Updating learning rate to 3.138105960900001e-05
2023-06-19 18:38:19,348 - epoch:14, training loss:0.1708 validation loss:0.2500
Updating learning rate to 2.824295364810001e-05
2023-06-19 18:39:03,354 - epoch:15, training loss:0.1676 validation loss:0.2530
Updating learning rate to 2.541865828329001e-05
2023-06-19 18:39:47,172 - epoch:16, training loss:0.1653 validation loss:0.2580
Updating learning rate to 2.287679245496101e-05
2023-06-19 18:40:29,579 - epoch:17, training loss:0.1636 validation loss:0.2524
Updating learning rate to 2.0589113209464907e-05
2023-06-19 18:41:13,140 - epoch:18, training loss:0.1618 validation loss:0.2496
Updating learning rate to 1.8530201888518416e-05
2023-06-19 18:41:56,240 - epoch:19, training loss:0.1603 validation loss:0.2497
Updating learning rate to 1.6677181699666577e-05
2023-06-19 18:42:41,999 - epoch:20, training loss:0.1588 validation loss:0.2504
Updating learning rate to 1.5009463529699919e-05
2023-06-19 18:43:27,027 - epoch:21, training loss:0.1575 validation loss:0.2471
Updating learning rate to 1.3508517176729929e-05
2023-06-19 18:44:12,166 - epoch:22, training loss:0.1563 validation loss:0.2512
Updating learning rate to 1.2157665459056936e-05
2023-06-19 18:44:58,347 - epoch:23, training loss:0.1553 validation loss:0.2505
Updating learning rate to 1.0941898913151242e-05
2023-06-19 18:45:43,721 - epoch:24, training loss:0.1542 validation loss:0.2504
Updating learning rate to 9.847709021836118e-06
2023-06-19 18:46:28,485 - epoch:25, training loss:0.1534 validation loss:0.2490
Updating learning rate to 8.862938119652508e-06
2023-06-19 18:47:14,583 - epoch:26, training loss:0.1528 validation loss:0.2493
Updating learning rate to 7.976644307687255e-06
2023-06-19 18:48:00,123 - epoch:27, training loss:0.1520 validation loss:0.2476
Updating learning rate to 7.178979876918531e-06
2023-06-19 18:48:45,762 - epoch:28, training loss:0.1514 validation loss:0.2500
Updating learning rate to 6.4610818892266776e-06
2023-06-19 18:49:32,411 - epoch:29, training loss:0.1509 validation loss:0.2455
Updating learning rate to 5.8149737003040096e-06
2023-06-19 18:50:18,725 - epoch:30, training loss:0.1503 validation loss:0.2497
Updating learning rate to 5.23347633027361e-06
2023-06-19 18:51:04,378 - epoch:31, training loss:0.1499 validation loss:0.2488
Updating learning rate to 4.710128697246249e-06
2023-06-19 18:51:49,718 - epoch:32, training loss:0.1495 validation loss:0.2484
Updating learning rate to 4.239115827521624e-06
2023-06-19 18:52:35,571 - epoch:33, training loss:0.1493 validation loss:0.2490
Updating learning rate to 3.815204244769462e-06
2023-06-19 18:53:21,119 - epoch:34, training loss:0.1488 validation loss:0.2494
Updating learning rate to 3.4336838202925152e-06
2023-06-19 18:54:05,877 - epoch:35, training loss:0.1486 validation loss:0.2476
Updating learning rate to 3.090315438263264e-06
2023-06-19 18:54:51,948 - epoch:36, training loss:0.1482 validation loss:0.2484
Updating learning rate to 2.7812838944369375e-06
2023-06-19 18:55:37,569 - epoch:37, training loss:0.1481 validation loss:0.2476
Updating learning rate to 2.503155504993244e-06
2023-06-19 18:56:23,059 - epoch:38, training loss:0.1478 validation loss:0.2490
Updating learning rate to 2.2528399544939195e-06
2023-06-19 18:57:08,996 - epoch:39, training loss:0.1475 validation loss:0.2474
Updating learning rate to 2.0275559590445276e-06
2023-06-19 18:57:55,645 - epoch:40, training loss:0.1474 validation loss:0.2477
Updating learning rate to 1.8248003631400751e-06
2023-06-19 18:58:39,444 - epoch:41, training loss:0.1473 validation loss:0.2488
Updating learning rate to 1.6423203268260676e-06
2023-06-19 18:59:25,788 - epoch:42, training loss:0.1471 validation loss:0.2488
Updating learning rate to 1.4780882941434609e-06
2023-06-19 19:00:07,984 - epoch:43, training loss:0.1470 validation loss:0.2487
Updating learning rate to 1.3302794647291146e-06
2023-06-19 19:00:53,146 - epoch:44, training loss:0.1470 validation loss:0.2463
Updating learning rate to 1.1972515182562034e-06
2023-06-19 19:01:38,244 - epoch:45, training loss:0.1469 validation loss:0.2487
Updating learning rate to 1.077526366430583e-06
2023-06-19 19:02:23,852 - epoch:46, training loss:0.1467 validation loss:0.2471
Updating learning rate to 9.697737297875248e-07
2023-06-19 19:03:09,889 - epoch:47, training loss:0.1466 validation loss:0.2475
Updating learning rate to 8.727963568087723e-07
2023-06-19 19:03:54,139 - epoch:48, training loss:0.1465 validation loss:0.2460
Updating learning rate to 7.855167211278951e-07
2023-06-19 19:04:40,666 - epoch:49, training loss:0.1464 validation loss:0.2482
Updating learning rate to 7.069650490151056e-07
2023-06-19 19:05:28,000 - epoch:50, training loss:0.1463 validation loss:0.2471
Updating learning rate to 6.36268544113595e-07
2023-06-19 19:06:14,295 - epoch:51, training loss:0.1463 validation loss:0.2465
Updating learning rate to 5.726416897022355e-07
2023-06-19 19:06:59,006 - epoch:52, training loss:0.1463 validation loss:0.2476
Updating learning rate to 5.15377520732012e-07
2023-06-19 19:07:51,942 - epoch:53, training loss:0.1462 validation loss:0.2469
Updating learning rate to 4.6383976865881085e-07
2023-06-19 19:08:35,977 - epoch:54, training loss:0.1462 validation loss:0.2463
Updating learning rate to 4.174557917929298e-07
2023-06-19 19:09:19,318 - epoch:55, training loss:0.1462 validation loss:0.2467
Updating learning rate to 3.7571021261363677e-07
2023-06-19 19:10:05,853 - epoch:56, training loss:0.1461 validation loss:0.2468
Updating learning rate to 3.381391913522731e-07
2023-06-19 19:10:51,352 - epoch:57, training loss:0.1461 validation loss:0.2486
Updating learning rate to 3.043252722170458e-07
2023-06-19 19:11:36,809 - epoch:58, training loss:0.1461 validation loss:0.2473
Updating learning rate to 2.7389274499534124e-07
2023-06-19 19:12:19,937 - epoch:59, training loss:0.1459 validation loss:0.2457
Updating learning rate to 2.465034704958071e-07
2023-06-19 19:13:06,527 - epoch:60, training loss:0.1460 validation loss:0.2480
Updating learning rate to 2.218531234462264e-07
2023-06-19 19:13:53,928 - epoch:61, training loss:0.1460 validation loss:0.2467
Updating learning rate to 1.9966781110160376e-07
2023-06-19 19:14:38,439 - epoch:62, training loss:0.1460 validation loss:0.2488
Updating learning rate to 1.797010299914434e-07
2023-06-19 19:15:24,103 - epoch:63, training loss:0.1460 validation loss:0.2470
Updating learning rate to 1.6173092699229907e-07
2023-06-19 19:16:08,278 - epoch:64, training loss:0.1458 validation loss:0.2474
Updating learning rate to 1.4555783429306916e-07
2023-06-19 19:16:55,079 - epoch:65, training loss:0.1459 validation loss:0.2468
Updating learning rate to 1.3100205086376224e-07
2023-06-19 19:17:41,185 - epoch:66, training loss:0.1458 validation loss:0.2481
Updating learning rate to 1.1790184577738603e-07
2023-06-19 19:18:33,036 - epoch:67, training loss:0.1459 validation loss:0.2479
Updating learning rate to 1.0611166119964742e-07
2023-06-19 19:19:24,684 - epoch:68, training loss:0.1458 validation loss:0.2481
Updating learning rate to 9.550049507968268e-08
2023-06-19 19:20:12,763 - epoch:69, training loss:0.1458 validation loss:0.2490
Updating learning rate to 8.595044557171442e-08
2023-06-19 19:21:07,816 - epoch:70, training loss:0.1458 validation loss:0.2491
Updating learning rate to 7.735540101454298e-08
2023-06-19 19:21:54,549 - epoch:71, training loss:0.1458 validation loss:0.2483
Updating learning rate to 6.961986091308869e-08
2023-06-19 19:22:42,422 - epoch:72, training loss:0.1458 validation loss:0.2476
Updating learning rate to 6.265787482177981e-08
2023-06-19 19:23:28,403 - epoch:73, training loss:0.1458 validation loss:0.2467
Updating learning rate to 5.639208733960184e-08
2023-06-19 19:24:13,975 - epoch:74, training loss:0.1458 validation loss:0.2474
Updating learning rate to 5.075287860564165e-08
2023-06-19 19:24:59,796 - epoch:75, training loss:0.1458 validation loss:0.2474
Updating learning rate to 4.567759074507749e-08
2023-06-19 19:25:51,845 - epoch:76, training loss:0.1458 validation loss:0.2466
Updating learning rate to 4.1109831670569744e-08
2023-06-19 19:26:46,806 - epoch:77, training loss:0.1457 validation loss:0.2461
Updating learning rate to 3.6998848503512764e-08
2023-06-19 19:27:36,269 - epoch:78, training loss:0.1459 validation loss:0.2471
Updating learning rate to 3.3298963653161496e-08
2023-06-19 19:28:24,332 - epoch:79, training loss:0.1459 validation loss:0.2467
Updating learning rate to 2.996906728784534e-08
2023-06-19 19:29:09,882 - epoch:80, training loss:0.1457 validation loss:0.2486
Updating learning rate to 2.697216055906081e-08
2023-06-19 19:29:56,023 - epoch:81, training loss:0.1456 validation loss:0.2467
Updating learning rate to 2.427494450315473e-08
2023-06-19 19:30:41,307 - epoch:82, training loss:0.1457 validation loss:0.2474
Updating learning rate to 2.1847450052839257e-08
2023-06-19 19:31:28,710 - epoch:83, training loss:0.1458 validation loss:0.2474
Updating learning rate to 1.9662705047555332e-08
2023-06-19 19:32:15,889 - epoch:84, training loss:0.1457 validation loss:0.2471
Updating learning rate to 1.7696434542799797e-08
2023-06-19 19:33:02,072 - epoch:85, training loss:0.1457 validation loss:0.2454
Updating learning rate to 1.5926791088519817e-08
2023-06-19 19:33:48,627 - epoch:86, training loss:0.1457 validation loss:0.2478
Updating learning rate to 1.4334111979667836e-08
2023-06-19 19:34:34,374 - epoch:87, training loss:0.1458 validation loss:0.2464
Updating learning rate to 1.2900700781701054e-08
2023-06-19 19:35:20,613 - epoch:88, training loss:0.1457 validation loss:0.2477
Updating learning rate to 1.161063070353095e-08
2023-06-19 19:36:03,609 - epoch:89, training loss:0.1457 validation loss:0.2468
Updating learning rate to 1.0449567633177854e-08
2023-06-19 19:36:50,970 - epoch:90, training loss:0.1457 validation loss:0.2477
Updating learning rate to 9.404610869860069e-09
2023-06-19 19:37:37,642 - epoch:91, training loss:0.1457 validation loss:0.2477
Updating learning rate to 8.464149782874063e-09
2023-06-19 19:38:22,980 - epoch:92, training loss:0.1457 validation loss:0.2469
Updating learning rate to 7.617734804586658e-09
2023-06-19 19:39:09,083 - epoch:93, training loss:0.1457 validation loss:0.2476
Updating learning rate to 6.855961324127991e-09
2023-06-19 19:39:55,815 - epoch:94, training loss:0.1458 validation loss:0.2480
Updating learning rate to 6.170365191715193e-09
2023-06-19 19:40:44,555 - epoch:95, training loss:0.1458 validation loss:0.2476
Updating learning rate to 5.5533286725436726e-09
2023-06-19 19:41:29,150 - epoch:96, training loss:0.1457 validation loss:0.2462
Updating learning rate to 4.997995805289306e-09
2023-06-19 19:42:15,278 - epoch:97, training loss:0.1458 validation loss:0.2466
Updating learning rate to 4.498196224760375e-09
2023-06-19 19:43:00,472 - epoch:98, training loss:0.1456 validation loss:0.2471
Updating learning rate to 4.048376602284338e-09
2023-06-19 19:43:45,492 - epoch:99, training loss:0.1457 validation loss:0.2461
Updating learning rate to 3.643538942055904e-09
2023-06-19 19:43:52,954 - [*] loss:0.3573
2023-06-19 19:43:54,960 - [*] phase 0, testing
2023-06-19 19:44:03,194 - T:96	MAE	0.4758	RMSE	0.4366	MAPE	397.2195
2023-06-19 19:44:03,218 - [*] phase 1 start training
