2023-09-10 19:54:24,149 - logger name:exp/ECL-FEDformer2023-09-10-19:54:24.149639/ECL-FEDformer.log
2023-09-10 19:54:24,150 - params : {'loss': 'huber', 'conf': 'ECL-FEDformer', 'data_name': 'ETTm1', 'iteration': 1, 'train': 1, 'mainrs': 0, 'abl': 0, 'abl_tmp_context': 0, 'abl_ae': 0, 'no_tmp': 0, 'load': True, 'build_graph': False, 'same_init': True, 'grad_norm': False, 'refiner_residual': 0, 'root_path': '', 'exp_path': 'exp/', 'val_test_mix': False, 'lr': 0.0001, 'lradj': 'TST', 'dropout': 0.05, 'fc_dropout': 0.05, 'head_dropout': 0.0, 'patch_len': 16, 'stride': 8, 'd_ff': 512, 'd_model': 128, 'n_heads': 8, 'seq_len': 336, 'pred_len': 96, 'noise_rate': 0.5, 'device': device(type='cuda', index=1), 'test_model_path': '/Disk/fhyega/code/BASE/exp/ECL-PatchTST2023-08-26-13:08:31.837686/0/best_model.pkl', 'idx': -1, 'aligner': 1, 'always_align': 1, 'refiner': 1, 'rec_block_num': 1, 'enhance': 1, 'enhance_type': 5, 'seed': 34, 'batch_size': 64, 'share_head': 0, 'add_noise': 1, 'add_norm': 0, 'jitter_sigma': 0.4, 'slope_rate': 0.01, 'slope_range': 0.2, 'alpha': 10.0, 'beta': 1.0, 'gamma': 0.15, 'feature_jittering': 1, 'rec_intra_feature': 0, 'rec_ori': 1, 'mid_dim': 128, 'test_en': 0, 'debugger': 0, 'summary': 0, 'omega': 1.0, 'theta': 1.5, 'mask_border': 1, 'sup_weight': 10.0, 'rec_length_ratio': 0.8, 'ref_dropout': 0.0, 'ref_block_num': 1, 'add_FFN': 1, 'add_residual': 0, 'rec_all': 0, 'e_layers': 2, 'early_break': 0, 'early_stop': 10, 'lo': None, '/* model related args*/': '//', 'model_name': 'FEDformer', 'label_len': 48, 'features': 'M', 'target': 'OT', 'graph_input': False, 'individual': False, 'd_layers': 1, 'factor': 1, 'des': 'Exp', 'padding_patch': 'end', 'revin': 1, 'affine': 0, 'subtract_last': 0, 'decomposition': 0, 'kernel_size': 25, 'output_attention': 0, 'embed_type': 0, 'activation': 'gelu', 'distil': 1, 'linear_output': 0, 'pct_start': 0.2, 'num_kernels': 6, 'top_k': 5, 'moving_avg': 25, 'indie': 0, '/*train related args*/': '//', 'epoch': 30, '/*dataset related args*/': '//', 'save_data_path': 'data/ECL/', 'data_process': True, 'embed': 'timeF', 'freq': 'h', 'begin_phase': 0, 'end_phase': 1, 'phase_len': -1, 'val_ratio': 0.33, 'graph_size': 321, '/*strategy related args*/': '//', 'strategy': 'incremental', 'increase': False, 'detect': False, 'detect_strategy': 'feature', 'replay': False, 'replay_strategy': 'random', 'repaly_num_samples': 100, 'ewc': False, 'ewc_strategy': 'ewc', 'ewc_lambda': 0.0001, 'subgraph_train': False, 'num_hops': 2, 'logname': 'ECL-FEDformer', 'time': '2023-09-10-19:54:24.149639', 'path': 'exp/ECL-FEDformer2023-09-10-19:54:24.149639', 'num_workers': 4, 'start_train': 0, 'train_mode': 'pretrain', 'get_score': False, 'use_cm': True, 'logger': <Logger __main__ (INFO)>}
2023-09-10 19:54:24,150 - [*] phase 0 start training
0 69680
train 34129
val 11425
test 11425
2023-09-10 19:54:24,979 - [*] phase 0 Dataset load!
dropout 0.05
dropout 0.05
fourier enhanced block used!
modes=32, index=[2, 7, 10, 14, 24, 26, 30, 40, 45, 47, 56, 60, 65, 67, 71, 76, 78, 79, 82, 86, 87, 104, 112, 113, 129, 133, 136, 143, 144, 151, 163, 166]
fourier enhanced block used!
modes=32, index=[2, 6, 11, 12, 15, 16, 17, 22, 27, 36, 45, 50, 58, 59, 60, 61, 69, 76, 77, 78, 87, 99, 100, 104, 106, 108, 115, 119, 120, 121, 122, 124]
 fourier enhanced cross attention used!
modes_q=32, index_q=[3, 5, 10, 15, 19, 21, 22, 23, 33, 34, 35, 46, 47, 48, 50, 54, 61, 63, 69, 74, 76, 78, 81, 84, 86, 88, 101, 106, 108, 111, 118, 127]
modes_kv=32, index_kv=[4, 5, 10, 11, 13, 18, 22, 25, 28, 29, 31, 35, 37, 51, 66, 68, 72, 73, 84, 87, 93, 98, 102, 109, 112, 136, 138, 139, 147, 157, 160, 164]
1 True None
2023-09-10 19:54:25,292 - [*] phase 0 Training start
train 34129
2023-09-10 19:58:16,473 - epoch:0, training loss:0.3321 validation loss:0.3861
(34129, 1)
(34129, 1) True
train 34129
vs, vt 0.38610503110805705 0.3892932363145844
Updating learning rate to 1.0434711851666469e-05
Updating learning rate to 1.0434711851666469e-05
(34129, 1)
(34129, 1) True
train 34129
vs, vt 0.33786437864410146 0.343341291283762
need align? ->  False 0.343341291283762
2023-09-10 20:08:28,255 - epoch:1, training loss:16.4047 validation loss:0.3379
Updating learning rate to 2.8013617547750165e-05
Updating learning rate to 2.8013617547750165e-05
(34129, 1)
(34129, 1) True
train 34129
vs, vt 0.26522286819013136 0.3070107729241835
need align? ->  False 0.3070107729241835
2023-09-10 20:16:16,007 - epoch:2, training loss:14.2108 validation loss:0.2652
Updating learning rate to 5.202358405400454e-05
Updating learning rate to 5.202358405400454e-05
(34129, 1)
(34129, 1) True
train 34129
vs, vt 0.255571867146805 0.27279990994730474
need align? ->  False 0.27279990994730474
2023-09-10 20:24:03,521 - epoch:3, training loss:10.3831 validation loss:0.2556
Updating learning rate to 7.602722736893337e-05
Updating learning rate to 7.602722736893337e-05
(34129, 1)
(34129, 1) True
train 34129
vs, vt 0.2492042961816548 0.2649443198265976
need align? ->  False 0.2649443198265976
2023-09-10 20:31:50,662 - epoch:4, training loss:6.7987 validation loss:0.2492
Updating learning rate to 9.358885882079718e-05
Updating learning rate to 9.358885882079718e-05
(34129, 1)
(34129, 1) True
train 34129
vs, vt 0.2459233637545362 0.25937637588914547
need align? ->  False 0.25937637588914547
2023-09-10 20:39:39,799 - epoch:5, training loss:5.4714 validation loss:0.2459
Updating learning rate to 9.999999849213968e-05
Updating learning rate to 9.999999849213968e-05
(34129, 1)
(34129, 1) True
train 34129
vs, vt 0.24452830076883625 0.25634663808029456
need align? ->  False 0.25634663808029456
2023-09-10 20:47:18,827 - epoch:6, training loss:4.7362 validation loss:0.2445
Updating learning rate to 9.957064049206628e-05
Updating learning rate to 9.957064049206628e-05
(34129, 1)
(34129, 1) True
train 34129
vs, vt 0.24230924952130078 0.2530164926952823
need align? ->  False 0.2530164926952823
2023-09-10 20:52:37,230 - epoch:7, training loss:3.8483 validation loss:0.2423
Updating learning rate to 9.829311851165108e-05
Updating learning rate to 9.829311851165108e-05
(34129, 1)
(34129, 1) True
train 34129
vs, vt 0.24065632645727536 0.24849387832693548
need align? ->  False 0.24849387832693548
2023-09-10 20:57:46,206 - epoch:8, training loss:4.0889 validation loss:0.2407
Updating learning rate to 9.618929130617497e-05
Updating learning rate to 9.618929130617497e-05
(34129, 1)
(34129, 1) True
train 34129
vs, vt 0.2393477292283953 0.24822368595603458
need align? ->  False 0.24822368595603458
2023-09-10 21:02:53,244 - epoch:9, training loss:3.6675 validation loss:0.2393
Updating learning rate to 9.329515594241475e-05
Updating learning rate to 9.329515594241475e-05
(34129, 1)
(34129, 1) True
train 34129
vs, vt 0.23817200340621963 0.24820838198481993
need align? ->  False 0.24820838198481993
2023-09-10 21:08:02,007 - epoch:10, training loss:3.4238 validation loss:0.2382
Updating learning rate to 8.966023187885026e-05
Updating learning rate to 8.966023187885026e-05
(34129, 1)
(34129, 1) True
train 34129
vs, vt 0.23523225745592038 0.24559405672899837
need align? ->  False 0.24559405672899837
2023-09-10 21:13:11,234 - epoch:11, training loss:3.5132 validation loss:0.2352
Updating learning rate to 8.534671367400045e-05
Updating learning rate to 8.534671367400045e-05
(34129, 1)
(34129, 1) True
train 34129
vs, vt 0.23490109623477445 0.24446665349952335
need align? ->  False 0.24446665349952335
2023-09-10 21:18:20,412 - epoch:12, training loss:3.3943 validation loss:0.2349
Updating learning rate to 8.042840682028348e-05
Updating learning rate to 8.042840682028348e-05
(34129, 1)
(34129, 1) True
train 34129
vs, vt 0.23332141198259493 0.24227802682272548
need align? ->  False 0.24227802682272548
2023-09-10 21:23:29,747 - epoch:13, training loss:3.4139 validation loss:0.2333
Updating learning rate to 7.498946491157874e-05
Updating learning rate to 7.498946491157874e-05
(34129, 1)
(34129, 1) True
train 34129
vs, vt 0.2327415028888753 0.2407205137294098
need align? ->  False 0.2407205137294098
2023-09-10 21:28:38,230 - epoch:14, training loss:3.3829 validation loss:0.2327
Updating learning rate to 6.912294975190372e-05
Updating learning rate to 6.912294975190372e-05
(34129, 1)
(34129, 1) True
train 34129
vs, vt 0.23116988201714095 0.2379813901039475
need align? ->  False 0.2379813901039475
2023-09-10 21:33:46,708 - epoch:15, training loss:3.4650 validation loss:0.2312
Updating learning rate to 6.292923904214577e-05
Updating learning rate to 6.292923904214577e-05
(34129, 1)
(34129, 1) True
train 34129
vs, vt 0.23050052452020806 0.23720385223710339
need align? ->  False 0.23720385223710339
2023-09-10 21:38:55,406 - epoch:16, training loss:3.5374 validation loss:0.2305
Updating learning rate to 5.6514308889769877e-05
Updating learning rate to 5.6514308889769877e-05
(34129, 1)
(34129, 1) True
train 34129
vs, vt 0.23135436413674382 0.23741242512228103
need align? ->  False 0.23720385223710339
2023-09-10 21:44:03,198 - epoch:17, training loss:3.3418 validation loss:0.2314
Updating learning rate to 4.9987920528237804e-05
Updating learning rate to 4.9987920528237804e-05
(34129, 1)
(34129, 1) True
train 34129
vs, vt 0.2314400903505986 0.23644084008878835
need align? ->  False 0.23644084008878835
2023-09-10 21:49:13,039 - epoch:18, training loss:3.3283 validation loss:0.2314
Updating learning rate to 4.3461742271872124e-05
Updating learning rate to 4.3461742271872124e-05
(34129, 1)
(34129, 1) True
train 34129
vs, vt 0.23131586061842616 0.23674937248146732
need align? ->  False 0.23644084008878835
2023-09-10 21:54:22,249 - epoch:19, training loss:3.4716 validation loss:0.2313
Updating learning rate to 3.704743884003767e-05
Updating learning rate to 3.704743884003767e-05
(34129, 1)
(34129, 1) True
train 34129
vs, vt 0.23135379822560528 0.23668711578379797
need align? ->  False 0.23644084008878835
2023-09-10 21:59:29,631 - epoch:20, training loss:3.4618 validation loss:0.2314
Updating learning rate to 3.0854760742834e-05
Updating learning rate to 3.0854760742834e-05
(34129, 1)
(34129, 1) True
train 34129
vs, vt 0.2300248376026167 0.2343410638124583
need align? ->  False 0.2343410638124583
2023-09-10 22:04:39,266 - epoch:21, training loss:3.4546 validation loss:0.2300
Updating learning rate to 2.4989666419439063e-05
Updating learning rate to 2.4989666419439063e-05
(34129, 1)
(34129, 1) True
train 34129
vs, vt 0.2303486198145251 0.23425388862717086
need align? ->  False 0.23425388862717086
2023-09-10 22:09:48,034 - epoch:22, training loss:3.5814 validation loss:0.2303
Updating learning rate to 1.9552509259837427e-05
Updating learning rate to 1.9552509259837427e-05
(34129, 1)
(34129, 1) True
train 34129
vs, vt 0.230230041826404 0.23417872700361567
need align? ->  False 0.23417872700361567
2023-09-10 22:14:57,463 - epoch:23, training loss:3.5586 validation loss:0.2302
Updating learning rate to 1.4636320530494689e-05
Updating learning rate to 1.4636320530494689e-05
(34129, 1)
(34129, 1) True
train 34129
vs, vt 0.22999652221216169 0.23346234558347884
need align? ->  False 0.23346234558347884
2023-09-10 22:20:06,918 - epoch:24, training loss:3.5456 validation loss:0.2300
Updating learning rate to 1.0325217583594908e-05
Updating learning rate to 1.0325217583594908e-05
(34129, 1)
(34129, 1) True
train 34129
vs, vt 0.22974769211264962 0.23345289106725314
need align? ->  False 0.23345289106725314
2023-09-10 22:25:16,249 - epoch:25, training loss:3.5099 validation loss:0.2297
Updating learning rate to 6.6929645858230745e-06
Updating learning rate to 6.6929645858230745e-06
(34129, 1)
(34129, 1) True
train 34129
vs, vt 0.22966423100016636 0.23296374346873613
need align? ->  False 0.23296374346873613
2023-09-10 22:30:25,939 - epoch:26, training loss:3.4890 validation loss:0.2297
Updating learning rate to 3.801710393021869e-06
Updating learning rate to 3.801710393021869e-06
(34129, 1)
(34129, 1) True
train 34129
vs, vt 0.22956704202643985 0.23288982111814968
need align? ->  False 0.23288982111814968
2023-09-10 22:35:35,581 - epoch:27, training loss:3.4817 validation loss:0.2296
Updating learning rate to 1.7009251660372196e-06
Updating learning rate to 1.7009251660372196e-06
(34129, 1)
(34129, 1) True
train 34129
vs, vt 0.22954351973183995 0.23284271072242513
need align? ->  False 0.23284271072242513
2023-09-10 22:40:45,114 - epoch:28, training loss:3.4852 validation loss:0.2295
Updating learning rate to 4.265539225505273e-07
Updating learning rate to 4.265539225505273e-07
(34129, 1)
(34129, 1) True
train 34129
vs, vt 0.22954690156702223 0.23280913524288038
need align? ->  False 0.23280913524288038
2023-09-10 22:45:55,721 - epoch:29, training loss:3.4872 validation loss:0.2295
Updating learning rate to 4.015078603225348e-10
Updating learning rate to 4.015078603225348e-10
dropout 0.05
dropout 0.05
fourier enhanced block used!
modes=32, index=[3, 5, 6, 18, 19, 33, 34, 35, 37, 41, 47, 48, 49, 52, 58, 62, 65, 67, 70, 73, 75, 88, 97, 100, 110, 132, 140, 147, 156, 162, 163, 164]
fourier enhanced block used!
modes=32, index=[8, 10, 20, 29, 30, 32, 36, 41, 53, 56, 64, 65, 67, 71, 73, 74, 75, 78, 82, 86, 87, 88, 99, 101, 102, 106, 107, 121, 123, 125, 127, 129]
 fourier enhanced cross attention used!
modes_q=32, index_q=[2, 3, 5, 9, 11, 16, 17, 19, 30, 34, 36, 42, 48, 50, 53, 55, 58, 62, 67, 72, 74, 76, 83, 97, 103, 106, 114, 116, 118, 120, 130, 131]
modes_kv=32, index_kv=[2, 4, 24, 25, 26, 29, 32, 35, 41, 49, 56, 58, 60, 67, 73, 99, 104, 105, 108, 116, 121, 123, 125, 126, 133, 137, 149, 152, 155, 164, 165, 167]
check exp/ECL-FEDformer2023-09-10-19:54:24.149639/0/0.2295_epoch_28.pkl  &  0.23280913524288038
2023-09-10 22:46:07,479 - [*] loss:0.7580
2023-09-10 22:46:07,488 - [*] phase 0, testing
2023-09-10 22:46:07,617 - T:96	MAE	0.547647	RMSE	0.759155	MAPE	294.509506
2023-09-10 22:46:07,618 - 96	mae	0.5476	
2023-09-10 22:46:07,618 - 96	rmse	0.7592	
2023-09-10 22:46:07,618 - 96	mape	294.5095	
----*-----
2023-09-10 22:46:19,438 - [*] loss:0.7845
2023-09-10 22:46:19,447 - [*] phase 0, testing
2023-09-10 22:46:19,567 - T:96	MAE	0.562798	RMSE	0.785602	MAPE	304.630566
2023-09-10 22:46:31,447 - [*] loss:0.9214
2023-09-10 22:46:31,456 - [*] phase 0, testing
2023-09-10 22:46:31,583 - T:96	MAE	0.605614	RMSE	0.922692	MAPE	323.564792
2023-09-10 22:46:46,929 - [*] loss:0.7991
2023-09-10 22:46:46,938 - [*] phase 0, testing
2023-09-10 22:46:47,062 - T:96	MAE	0.577692	RMSE	0.800285	MAPE	290.309000
2023-09-10 22:46:59,006 - [*] loss:0.7576
2023-09-10 22:46:59,015 - [*] phase 0, testing
2023-09-10 22:46:59,138 - T:96	MAE	0.546959	RMSE	0.758694	MAPE	277.298951
----*-----
avg under noise: 0.5732654482126236 0.816818118095398
2023-09-10 22:47:06,779 - [*] loss:0.7572
2023-09-10 22:47:06,788 - [*] phase 0, testing
2023-09-10 22:47:06,918 - T:96	MAE	0.547424	RMSE	0.758398	MAPE	294.284797
2023-09-10 22:47:06,918 - 96	mae	0.5474	
2023-09-10 22:47:06,919 - 96	rmse	0.7584	
2023-09-10 22:47:06,919 - 96	mape	294.2848	
----*-----
2023-09-10 22:47:14,704 - [*] loss:0.7855
2023-09-10 22:47:14,714 - [*] phase 0, testing
2023-09-10 22:47:14,840 - T:96	MAE	0.563559	RMSE	0.786647	MAPE	304.691458
2023-09-10 22:47:22,468 - [*] loss:0.9294
2023-09-10 22:47:22,477 - [*] phase 0, testing
2023-09-10 22:47:22,602 - T:96	MAE	0.607048	RMSE	0.930502	MAPE	324.962497
2023-09-10 22:47:33,589 - [*] loss:0.8009
2023-09-10 22:47:33,597 - [*] phase 0, testing
2023-09-10 22:47:33,722 - T:96	MAE	0.577559	RMSE	0.802114	MAPE	290.539408
2023-09-10 22:47:41,579 - [*] loss:0.7575
2023-09-10 22:47:41,588 - [*] phase 0, testing
2023-09-10 22:47:41,715 - T:96	MAE	0.547242	RMSE	0.758661	MAPE	277.736497
----*-----
avg under noise: 0.5738519728183746 0.8194810897111893
