2023-09-06 05:58:22,079 - logger name:exp/ECL-PatchTST2023-09-06-05:58:22.078468/ECL-PatchTST.log
2023-09-06 05:58:22,079 - params : {'loss': 'huber', 'conf': 'ECL-PatchTST', 'data_name': 'ETTm1', 'iteration': 1, 'train': 1, 'mainrs': 0, 'abl': 0, 'abl_tmp_context': 0, 'abl_ae': 0, 'no_tmp': 0, 'load': True, 'build_graph': False, 'same_init': True, 'grad_norm': False, 'refiner_residual': 0, 'root_path': '', 'exp_path': 'exp/', 'val_test_mix': False, 'lr': 0.0001, 'lradj': 'TST', 'dropout': 0.2, 'fc_dropout': 0.2, 'head_dropout': 0.0, 'patch_len': 16, 'stride': 8, 'd_ff': 256, 'd_model': 128, 'n_heads': 16, 'seq_len': 336, 'pred_len': 192, 'noise_rate': 0.5, 'device': device(type='cuda', index=0), 'test_model_path': '/Disk/fhyega/code/BASE/exp/ECL-PatchTST2023-08-26-13:08:31.837686/0/best_model.pkl', 'idx': -1, 'aligner': 1, 'always_align': 1, 'refiner': 1, 'rec_block_num': 1, 'enhance': 1, 'enhance_type': 5, 'seed': 34, 'batch_size': 64, 'share_head': 0, 'add_noise': 1, 'add_norm': 0, 'jitter_sigma': 0.4, 'slope_rate': 0.01, 'slope_range': 0.2, 'alpha': 10.0, 'beta': 1.0, 'gamma': 0.15, 'feature_jittering': 1, 'rec_intra_feature': 0, 'rec_ori': 1, 'mid_dim': 128, 'test_en': 0, 'debugger': 0, 'summary': 0, 'omega': 1.0, 'theta': 1.5, 'mask_border': 1, 'sup_weight': 10.0, 'rec_length_ratio': 0.8, 'ref_dropout': 0.0, 'ref_block_num': 1, 'add_FFN': 1, 'add_residual': 0, 'rec_all': 0, 'e_layers': 3, 'early_break': 0, 'early_stop': 10, '/* model related args*/': '//', 'model_name': 'PatchTST', 'label_len': 48, 'features': 'M', 'target': 'OT', 'graph_input': False, 'individual': False, 'd_layers': 1, 'factor': 1, 'des': 'Exp', 'padding_patch': 'end', 'revin': 1, 'affine': 0, 'subtract_last': 0, 'decomposition': 0, 'kernel_size': 25, 'output_attention': 0, 'embed_type': 0, 'activation': 'gelu', 'distil': 1, 'linear_output': 1, 'pct_start': 0.2, 'indie': 1, '/*train related args*/': '//', 'epoch': 30, '/*dataset related args*/': '//', 'save_data_path': 'data/ECL/', 'data_process': True, 'embed': 'timeF', 'freq': 'h', 'begin_phase': 0, 'end_phase': 1, 'phase_len': -1, 'val_ratio': 0.33, 'graph_size': 321, '/*strategy related args*/': '//', 'strategy': 'incremental', 'increase': False, 'detect': False, 'detect_strategy': 'feature', 'replay': False, 'replay_strategy': 'random', 'repaly_num_samples': 100, 'ewc': False, 'ewc_strategy': 'ewc', 'ewc_lambda': 0.0001, 'subgraph_train': False, 'num_hops': 2, 'logname': 'ECL-PatchTST', 'time': '2023-09-06-05:58:22.078468', 'path': 'exp/ECL-PatchTST2023-09-06-05:58:22.078468', 'num_workers': 4, 'start_train': 0, 'train_mode': 'pretrain', 'get_score': False, 'use_cm': True, 'logger': <Logger __main__ (INFO)>}
2023-09-06 05:58:22,079 - [*] phase 0 start training
0 69680
train 34033
val 11329
test 11329
2023-09-06 05:58:22,937 - [*] phase 0 Dataset load!
1 True None
2023-09-06 05:58:24,002 - [*] phase 0 Training start
train 34033
2023-09-06 06:01:20,356 - epoch:0, training loss:0.1824 validation loss:0.2085
(34033, 7)
(34033, 7) True
train 34033
vs, vt 0.20848981709627623 0.21517786178528592
Updating learning rate to 1.0434726665328864e-05
Updating learning rate to 1.0434726665328864e-05
(34033, 7)
(34033, 7) True
train 34033
vs, vt 0.2078944534021482 0.20795131600304936
need align? ->  False 0.20795131600304936
2023-09-06 06:07:03,632 - epoch:1, training loss:9.9227 validation loss:0.2079
Updating learning rate to 2.8013668858919874e-05
Updating learning rate to 2.8013668858919874e-05
(34033, 7)
(34033, 7) True
train 34033
vs, vt 0.20402486364911782 0.20607339762402385
need align? ->  False 0.20607339762402385
2023-09-06 06:11:19,995 - epoch:2, training loss:3.2772 validation loss:0.2040
Updating learning rate to 5.2023672910715735e-05
Updating learning rate to 5.2023672910715735e-05
(34033, 7)
(34033, 7) False
train 34033
vs, vt 0.20789461639406306 0.20538748430318376
need align? ->  True 0.20538748430318376
2023-09-06 06:15:31,241 - epoch:3, training loss:1.5410 validation loss:0.2079
Updating learning rate to 7.602732993293542e-05
Updating learning rate to 7.602732993293542e-05
(34033, 7)
(34033, 7) True
train 34033
vs, vt 0.20275892951431568 0.20570929252197234
need align? ->  False 0.20538748430318376
2023-09-06 06:19:38,266 - epoch:4, training loss:1.2519 validation loss:0.2028
Updating learning rate to 9.3588932762817e-05
Updating learning rate to 9.3588932762817e-05
(34033, 7)
(34033, 7) False
train 34033
vs, vt 0.20065016268093264 0.20587674773224954
need align? ->  False 0.20538748430318376
2023-09-06 06:23:44,205 - epoch:5, training loss:1.0033 validation loss:0.2007
Updating learning rate to 9.999999848075964e-05
Updating learning rate to 9.999999848075964e-05
(34033, 7)
(34033, 7) True
train 34033
vs, vt 0.20157724692161832 0.20523499021453134
need align? ->  False 0.20523499021453134
2023-09-06 06:28:06,312 - epoch:6, training loss:0.9222 validation loss:0.2016
Updating learning rate to 9.957063444389977e-05
Updating learning rate to 9.957063444389977e-05
(34033, 7)
(34033, 7) False
train 34033
vs, vt 0.20252584406499113 0.2037189356103707
need align? ->  False 0.2037189356103707
2023-09-06 06:32:14,147 - epoch:7, training loss:0.9113 validation loss:0.2025
Updating learning rate to 9.829310653018389e-05
Updating learning rate to 9.829310653018389e-05
(34033, 7)
(34033, 7) False
train 34033
vs, vt 0.20025683142077388 0.205554711894038
need align? ->  False 0.2037189356103707
2023-09-06 06:36:03,428 - epoch:8, training loss:0.8790 validation loss:0.2003
Updating learning rate to 9.618927359641333e-05
Updating learning rate to 9.618927359641333e-05
(34033, 7)
(34033, 7) True
train 34033
vs, vt 0.19979800198101597 0.20256899322351712
need align? ->  False 0.20256899322351712
2023-09-06 06:40:13,325 - epoch:9, training loss:0.8398 validation loss:0.1998
Updating learning rate to 9.329513280737758e-05
Updating learning rate to 9.329513280737758e-05
(34033, 7)
(34033, 7) True
train 34033
vs, vt 0.2020666856695427 0.2044891357170732
need align? ->  False 0.20256899322351712
2023-09-06 06:44:21,593 - epoch:10, training loss:0.9338 validation loss:0.2021
Updating learning rate to 8.966020371438448e-05
Updating learning rate to 8.966020371438448e-05
(34033, 7)
(34033, 7) True
train 34033
vs, vt 0.19771544938760527 0.20314897320578607
need align? ->  False 0.20256899322351712
2023-09-06 06:48:12,068 - epoch:11, training loss:0.8878 validation loss:0.1977
Updating learning rate to 8.534668096200788e-05
Updating learning rate to 8.534668096200788e-05
(34033, 7)
(34033, 7) True
train 34033
vs, vt 0.1990035626032714 0.20198530354275462
need align? ->  False 0.20198530354275462
2023-09-06 06:52:20,264 - epoch:12, training loss:0.8663 validation loss:0.1990
Updating learning rate to 8.042837012047538e-05
Updating learning rate to 8.042837012047538e-05
(34033, 7)
(34033, 7) True
train 34033
vs, vt 0.2031115290572804 0.20320932077390425
need align? ->  True 0.20198530354275462
2023-09-06 06:56:33,500 - epoch:13, training loss:0.9707 validation loss:0.2031
Updating learning rate to 7.498942485189898e-05
Updating learning rate to 7.498942485189898e-05
(34033, 7)
(34033, 7) False
train 34033
vs, vt 0.20057657970052756 0.20286999743306236
need align? ->  False 0.20198530354275462
2023-09-06 07:00:29,589 - epoch:14, training loss:0.9448 validation loss:0.2006
Updating learning rate to 6.912290701778455e-05
Updating learning rate to 6.912290701778455e-05
(34033, 7)
(34033, 7) False
train 34033
vs, vt 0.1996177766848816 0.20244428973770542
need align? ->  False 0.20198530354275462
2023-09-06 07:04:31,675 - epoch:15, training loss:0.9246 validation loss:0.1996
Updating learning rate to 6.29291943647798e-05
Updating learning rate to 6.29291943647798e-05
(34033, 7)
(34033, 7) False
train 34033
vs, vt 0.1972947038626403 0.20173797817126418
need align? ->  False 0.20173797817126418
2023-09-06 07:08:47,561 - epoch:16, training loss:0.9145 validation loss:0.1973
Updating learning rate to 5.651426303359923e-05
Updating learning rate to 5.651426303359923e-05
(34033, 7)
(34033, 7) False
train 34033
vs, vt 0.19867539776258925 0.20053921284133128
need align? ->  False 0.20053921284133128
2023-09-06 07:12:43,040 - epoch:17, training loss:1.0179 validation loss:0.1987
Updating learning rate to 4.99878742778743e-05
Updating learning rate to 4.99878742778743e-05
(34033, 7)
(34033, 7) False
train 34033
vs, vt 0.19799008990606565 0.20046466191330653
need align? ->  False 0.20046466191330653
2023-09-06 07:16:41,780 - epoch:18, training loss:1.0219 validation loss:0.1980
Updating learning rate to 4.346169641867228e-05
Updating learning rate to 4.346169641867228e-05
(34033, 7)
(34033, 7) False
train 34033
vs, vt 0.19760093672640539 0.19878282743307313
need align? ->  False 0.19878282743307313
2023-09-06 07:20:54,462 - epoch:19, training loss:1.0265 validation loss:0.1976
Updating learning rate to 3.704739416856244e-05
Updating learning rate to 3.704739416856244e-05
(34033, 7)
(34033, 7) False
train 34033
vs, vt 0.198178271982777 0.19959814260514935
need align? ->  False 0.19878282743307313
2023-09-06 07:24:57,094 - epoch:20, training loss:1.0443 validation loss:0.1982
Updating learning rate to 3.0854718017424746e-05
Updating learning rate to 3.0854718017424746e-05
(34033, 7)
(34033, 7) True
train 34033
vs, vt 0.1992540673007456 0.19906614157842117
need align? ->  True 0.19878282743307313
2023-09-06 07:28:53,900 - epoch:21, training loss:1.0349 validation loss:0.1993
Updating learning rate to 2.4989626371139337e-05
Updating learning rate to 2.4989626371139337e-05
(34033, 7)
(34033, 7) False
train 34033
vs, vt 0.19717791429563855 0.199435877498616
need align? ->  False 0.19878282743307313
2023-09-06 07:33:04,831 - epoch:22, training loss:1.0290 validation loss:0.1972
Updating learning rate to 1.9552472573884788e-05
Updating learning rate to 1.9552472573884788e-05
(34033, 7)
(34033, 7) True
train 34033
vs, vt 0.1982889108443528 0.19857172525665734
need align? ->  False 0.19857172525665734
2023-09-06 07:37:14,365 - epoch:23, training loss:1.0234 validation loss:0.1983
Updating learning rate to 1.4636287834595912e-05
Updating learning rate to 1.4636287834595912e-05
(34033, 7)
(34033, 7) False
train 34033
vs, vt 0.19926594976293907 0.1988875279726272
need align? ->  True 0.19857172525665734
2023-09-06 07:41:11,633 - epoch:24, training loss:1.0634 validation loss:0.1993
Updating learning rate to 1.0325189437185909e-05
Updating learning rate to 1.0325189437185909e-05
(34033, 7)
(34033, 7) False
train 34033
vs, vt 0.19787846737949366 0.1993223303363899
need align? ->  False 0.19857172525665734
2023-09-06 07:45:25,027 - epoch:25, training loss:1.0589 validation loss:0.1979
Updating learning rate to 6.692941470496724e-06
Updating learning rate to 6.692941470496724e-06
(34033, 7)
(34033, 7) True
train 34033
vs, vt 0.1972798512139347 0.19914203572474168
need align? ->  False 0.19857172525665734
2023-09-06 07:49:53,364 - epoch:26, training loss:1.0568 validation loss:0.1973
Updating learning rate to 3.8016927042877923e-06
Updating learning rate to 3.8016927042877923e-06
(34033, 7)
(34033, 7) True
train 34033
vs, vt 0.19727773328175705 0.19900870754310254
need align? ->  False 0.19857172525665734
2023-09-06 07:53:49,737 - epoch:27, training loss:1.0562 validation loss:0.1973
Updating learning rate to 1.7009132065545696e-06
Updating learning rate to 1.7009132065545696e-06
(34033, 7)
(34033, 7) True
train 34033
vs, vt 0.19767119214357284 0.19912936630543698
need align? ->  False 0.19857172525665734
2023-09-06 07:57:49,008 - epoch:28, training loss:1.0556 validation loss:0.1977
Updating learning rate to 4.265478969493755e-07
Updating learning rate to 4.265478969493755e-07
(34033, 7)
(34033, 7) True
train 34033
vs, vt 0.19747227380114996 0.19908835012675002
need align? ->  False 0.19857172525665734
2023-09-06 08:02:04,106 - epoch:29, training loss:1.0548 validation loss:0.1975
Updating learning rate to 4.0151924035722596e-10
Updating learning rate to 4.0151924035722596e-10
check exp/ECL-PatchTST2023-09-06-05:58:22.078468/0/0.1972_epoch_22.pkl  &  0.19857172525665734
2023-09-06 08:02:37,368 - [*] loss:0.3241
2023-09-06 08:02:37,564 - [*] phase 0, testing
2023-09-06 08:02:39,181 - T:192	MAE	0.361943	RMSE	0.325360	MAPE	219.363666
2023-09-06 08:02:39,188 - 192	mae	0.3619	
2023-09-06 08:02:39,188 - 192	rmse	0.3254	
2023-09-06 08:02:39,188 - 192	mape	219.3637	
2023-09-06 08:03:09,472 - [*] loss:0.3215
2023-09-06 08:03:09,750 - [*] phase 0, testing
2023-09-06 08:03:11,952 - T:192	MAE	0.359081	RMSE	0.322675	MAPE	220.622563
2023-09-06 08:03:46,256 - [*] loss:0.3241
2023-09-06 08:03:46,490 - [*] phase 0, testing
2023-09-06 08:03:48,167 - T:192	MAE	0.361943	RMSE	0.325360	MAPE	219.363666
2023-09-06 08:04:18,393 - [*] loss:0.3435
2023-09-06 08:04:18,415 - [*] phase 0, testing
2023-09-06 08:04:20,327 - T:192	MAE	0.363571	RMSE	0.344949	MAPE	224.812984
2023-09-06 08:04:20,327 - 192	mae	0.3636	
2023-09-06 08:04:20,327 - 192	rmse	0.3449	
2023-09-06 08:04:20,327 - 192	mape	224.8130	
