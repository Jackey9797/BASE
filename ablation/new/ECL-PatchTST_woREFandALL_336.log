2023-09-15 04:47:17,038 - logger name:exp/ECL-PatchTST2023-09-15-04:47:17.038728/ECL-PatchTST.log
2023-09-15 04:47:17,039 - params : {'loss': 'huber', 'conf': 'ECL-PatchTST', 'data_name': 'ETTm1', 'iteration': 1, 'train': 1, 'mainrs': 0, 'abl': 1, 'abl_tmp_context': 0, 'abl_ae': 0, 'no_tmp': 0, 'load': True, 'build_graph': False, 'same_init': True, 'grad_norm': False, 'refiner_residual': 1, 'root_path': '', 'exp_path': 'exp/', 'val_test_mix': False, 'lr': 0.0001, 'lradj': 'TST', 'dropout': 0.2, 'fc_dropout': 0.2, 'head_dropout': 0.0, 'patch_len': 16, 'stride': 8, 'd_ff': 256, 'd_model': 128, 'n_heads': 16, 'seq_len': 336, 'pred_len': 336, 'noise_rate': 0.5, 'device': device(type='cuda', index=0), 'test_model_path': '/Disk/fhyega/code/BASE/exp/ECL-PatchTST2023-08-26-13:08:31.837686/0/best_model.pkl', 'idx': -1, 'aligner': 1, 'always_align': 1, 'refiner': 1, 'rec_block_num': 1, 'enhance': 1, 'enhance_type': 5, 'seed': 34, 'batch_size': 64, 'share_head': 0, 'add_noise': 1, 'add_norm': 0, 'jitter_sigma': 0.4, 'slope_rate': 0.01, 'slope_range': 0.2, 'alpha': 10.0, 'beta': 1.0, 'gamma': 0.15, 'feature_jittering': 1, 'rec_intra_feature': 0, 'rec_ori': 1, 'mid_dim': 128, 'test_en': 0, 'debugger': 0, 'summary': 0, 'omega': 1.0, 'theta': 1.5, 'mask_border': 1, 'sup_weight': 10.0, 'rec_length_ratio': 0.8, 'ref_dropout': 0.0, 'ref_block_num': 1, 'add_FFN': 1, 'add_residual': 0, 'rec_all': 0, 'e_layers': 3, 'early_break': 0, 'early_stop': 10, 'lo': None, '/* model related args*/': '//', 'model_name': 'PatchTST', 'label_len': 48, 'features': 'M', 'target': 'OT', 'graph_input': False, 'individual': False, 'd_layers': 1, 'factor': 1, 'des': 'Exp', 'padding_patch': 'end', 'revin': 1, 'affine': 0, 'subtract_last': 0, 'decomposition': 0, 'kernel_size': 25, 'output_attention': 0, 'embed_type': 0, 'activation': 'gelu', 'distil': 1, 'linear_output': 1, 'pct_start': 0.2, 'indie': 1, '/*train related args*/': '//', 'epoch': 30, '/*dataset related args*/': '//', 'save_data_path': 'data/ECL/', 'data_process': True, 'embed': 'timeF', 'freq': 'h', 'begin_phase': 0, 'end_phase': 1, 'phase_len': -1, 'val_ratio': 0.33, 'graph_size': 321, '/*strategy related args*/': '//', 'strategy': 'incremental', 'increase': False, 'detect': False, 'detect_strategy': 'feature', 'replay': False, 'replay_strategy': 'random', 'repaly_num_samples': 100, 'ewc': False, 'ewc_strategy': 'ewc', 'ewc_lambda': 0.0001, 'subgraph_train': False, 'num_hops': 2, 'logname': 'ECL-PatchTST', 'time': '2023-09-15-04:47:17.038728', 'path': 'exp/ECL-PatchTST2023-09-15-04:47:17.038728', 'num_workers': 4, 'start_train': 0, 'train_mode': 'pretrain', 'get_score': False, 'use_cm': True, 'logger': <Logger __main__ (INFO)>}
2023-09-15 04:47:17,039 - [*] phase 0 start training
0 69680
train 33889
val 11185
test 11185
2023-09-15 04:47:17,884 - [*] phase 0 Dataset load!
1 True None
2023-09-15 04:47:18,016 - [*] phase 0 Training start
train 33889
2023-09-15 04:47:56,315 - epoch:0, training loss:0.1932 validation loss:0.2528
(33889, 7)
(33889, 7) True
train 33889
vs, vt 0.25275956907442637 0.2574721706977912
Updating learning rate to 1.0434741591055141e-05
Updating learning rate to 1.0434741591055141e-05
(33889, 7)
(33889, 7) True
train 33889
0 tensor(1.2289, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1754, device='cuda:0', grad_fn=<MulBackward0>)
0 tensor(1.1716, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1631, device='cuda:0', grad_fn=<MulBackward0>)
0 tensor(0.9913, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1635, device='cuda:0', grad_fn=<MulBackward0>)
0 tensor(0.8786, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1746, device='cuda:0', grad_fn=<MulBackward0>)
0 tensor(0.8273, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1682, device='cuda:0', grad_fn=<MulBackward0>)
0 tensor(0.7881, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1664, device='cuda:0', grad_fn=<MulBackward0>)
0 tensor(0.6825, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1606, device='cuda:0', grad_fn=<MulBackward0>)
0 tensor(0.6208, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1395, device='cuda:0', grad_fn=<MulBackward0>)
0 tensor(0.6158, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1437, device='cuda:0', grad_fn=<MulBackward0>)
0 tensor(0.5841, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1538, device='cuda:0', grad_fn=<MulBackward0>)
0 tensor(0.5617, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1538, device='cuda:0', grad_fn=<MulBackward0>)
0 tensor(0.4840, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1395, device='cuda:0', grad_fn=<MulBackward0>)
0 tensor(0.5384, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1530, device='cuda:0', grad_fn=<MulBackward0>)
0 tensor(0.4816, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1491, device='cuda:0', grad_fn=<MulBackward0>)
vs, vt 0.25103964490549907 0.25254859347428593
need align? ->  False 0.25254859347428593
2023-09-15 04:49:47,364 - epoch:1, training loss:2.2817 validation loss:0.2510
Updating learning rate to 2.8013720558234977e-05
Updating learning rate to 2.8013720558234977e-05
(33889, 7)
(33889, 7) False
train 33889
tensor(5.8278, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4973, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1503, device='cuda:0', grad_fn=<MulBackward0>)
tensor(3.8601, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5263, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1623, device='cuda:0', grad_fn=<MulBackward0>)
tensor(2.6514, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4737, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1424, device='cuda:0', grad_fn=<MulBackward0>)
tensor(2.2994, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4430, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1510, device='cuda:0', grad_fn=<MulBackward0>)
tensor(2.4032, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4462, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1580, device='cuda:0', grad_fn=<MulBackward0>)
tensor(2.4131, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5041, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1678, device='cuda:0', grad_fn=<MulBackward0>)
tensor(1.9687, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4654, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1626, device='cuda:0', grad_fn=<MulBackward0>)
tensor(1.2504, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4466, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1582, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.6631, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4270, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1657, device='cuda:0', grad_fn=<MulBackward0>)
tensor(1.3855, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4750, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1742, device='cuda:0', grad_fn=<MulBackward0>)
tensor(1.1200, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4373, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1535, device='cuda:0', grad_fn=<MulBackward0>)
tensor(1.3331, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3482, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1372, device='cuda:0', grad_fn=<MulBackward0>)
tensor(1.0517, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3968, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1536, device='cuda:0', grad_fn=<MulBackward0>)
tensor(1.0407, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4735, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1844, device='cuda:0', grad_fn=<MulBackward0>)
vs, vt 0.25034391441515513 0.2541128356541906
need align? ->  False 0.25254859347428593
2023-09-15 04:51:10,479 - epoch:2, training loss:3.5477 validation loss:0.2503
Updating learning rate to 5.202376243952299e-05
Updating learning rate to 5.202376243952299e-05
(33889, 7)
(33889, 7) True
train 33889
tensor(0.8466, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4500, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1670, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.9764, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3807, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1510, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.9095, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4101, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1574, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.8773, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3964, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1630, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.8165, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3604, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1427, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.5441, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3460, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1447, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.7276, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3830, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1512, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.4343, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3733, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1648, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.6074, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4140, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1680, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.4974, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4005, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1676, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.4953, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4479, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1825, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.4509, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3519, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1371, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.3996, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4083, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1665, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.3930, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3562, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1487, device='cuda:0', grad_fn=<MulBackward0>)
vs, vt 0.25178094069872586 0.2535144973652703
need align? ->  False 0.25254859347428593
2023-09-15 04:52:33,635 - epoch:3, training loss:1.9746 validation loss:0.2518
Updating learning rate to 7.602743327256502e-05
Updating learning rate to 7.602743327256502e-05
(33889, 7)
(33889, 7) False
train 33889
tensor(0.2812, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3889, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1517, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.3124, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3671, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1365, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.2733, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3685, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1508, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.2084, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3735, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1550, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.2461, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3374, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1484, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.1764, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3940, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1520, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.1738, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3930, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1522, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.1838, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3844, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1613, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.1405, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3183, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1336, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.1375, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3956, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1474, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.1153, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.2936, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1374, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0784, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3517, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1425, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0794, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3290, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1451, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0825, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3664, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1511, device='cuda:0', grad_fn=<MulBackward0>)
vs, vt 0.2519569951082979 0.25403808018990925
need align? ->  False 0.25254859347428593
2023-09-15 04:53:56,859 - epoch:4, training loss:1.4439 validation loss:0.2520
Updating learning rate to 9.358900726372054e-05
Updating learning rate to 9.358900726372054e-05
(33889, 7)
(33889, 7) True
train 33889
tensor(0.0700, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3580, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1526, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0689, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3610, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1562, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0522, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3747, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1516, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0418, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3235, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1546, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0332, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3435, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1362, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0326, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3690, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1542, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0244, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3406, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1424, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0275, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3883, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1523, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0213, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3537, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1434, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0170, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4005, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1705, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0163, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3425, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1532, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0108, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3135, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1270, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0147, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3672, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1541, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0194, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3386, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1570, device='cuda:0', grad_fn=<MulBackward0>)
vs, vt 0.25134010602320944 0.2533244173654488
need align? ->  False 0.25254859347428593
2023-09-15 04:55:19,695 - epoch:5, training loss:1.2416 validation loss:0.2513
Updating learning rate to 9.999999846925029e-05
Updating learning rate to 9.999999846925029e-05
(33889, 7)
(33889, 7) True
train 33889
tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3175, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1469, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0136, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3830, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1556, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0097, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3547, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1405, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0060, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3706, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1464, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0101, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3567, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1428, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0084, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3620, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1406, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0099, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3849, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1418, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0096, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3620, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1483, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0067, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3417, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1415, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0157, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3337, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1533, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0119, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3172, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1366, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0072, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3857, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1552, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0083, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3892, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1669, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0140, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4034, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1588, device='cuda:0', grad_fn=<MulBackward0>)
vs, vt 0.2502170241943428 0.2570437583540167
need align? ->  False 0.25254859347428593
2023-09-15 04:56:42,772 - epoch:6, training loss:1.1988 validation loss:0.2502
Updating learning rate to 9.957062834995753e-05
Updating learning rate to 9.957062834995753e-05
(33889, 7)
(33889, 7) False
train 33889
tensor(0.0133, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3555, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1494, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0075, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3671, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1669, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0094, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3477, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1494, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0152, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3320, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1365, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0071, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4038, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1694, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0106, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3791, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1716, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0077, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3175, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1418, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0086, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3340, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1393, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0052, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3294, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1341, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0085, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3225, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1536, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0126, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3471, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1458, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0057, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3693, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1495, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0062, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3586, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1512, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0075, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3636, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1576, device='cuda:0', grad_fn=<MulBackward0>)
vs, vt 0.2505290439299175 0.2537756749348981
need align? ->  False 0.25254859347428593
2023-09-15 04:58:06,046 - epoch:7, training loss:1.1833 validation loss:0.2505
Updating learning rate to 9.829309445807781e-05
Updating learning rate to 9.829309445807781e-05
(33889, 7)
(33889, 7) True
train 33889
tensor(0.0067, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3749, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1511, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0079, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3926, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1640, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3478, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1485, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0056, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3558, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1562, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0097, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3510, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1513, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0051, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4610, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1759, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0048, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3678, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1526, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0081, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3527, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1620, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0063, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3313, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1369, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0071, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3766, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1501, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0072, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3886, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1690, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0053, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3398, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1376, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0041, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3514, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1584, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3702, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1604, device='cuda:0', grad_fn=<MulBackward0>)
vs, vt 0.24924683040806225 0.2581275961441653
need align? ->  False 0.25254859347428593
2023-09-15 04:59:29,009 - epoch:8, training loss:1.1732 validation loss:0.2492
Updating learning rate to 9.618925575270048e-05
Updating learning rate to 9.618925575270048e-05
(33889, 7)
(33889, 7) True
train 33889
tensor(0.0081, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3429, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1477, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0034, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3527, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1561, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0044, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3273, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1253, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0073, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3643, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1635, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0044, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3893, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1630, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0046, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.2910, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1314, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0039, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3268, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1413, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0067, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3438, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1555, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0047, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3509, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1610, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0051, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.2926, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1343, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0043, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3295, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1482, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0077, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3311, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1417, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3673, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1551, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0091, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3595, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1632, device='cuda:0', grad_fn=<MulBackward0>)
vs, vt 0.252236376617636 0.2577614827028343
need align? ->  False 0.25254859347428593
2023-09-15 05:00:52,374 - epoch:9, training loss:1.1655 validation loss:0.2522
Updating learning rate to 9.329510949736885e-05
Updating learning rate to 9.329510949736885e-05
(33889, 7)
(33889, 7) False
train 33889
tensor(0.0054, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3780, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1592, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0065, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3323, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1616, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0080, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3308, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1457, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0095, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3355, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1549, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0063, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3172, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1579, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0058, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3152, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1427, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0045, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4017, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1475, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0056, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3414, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1570, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0043, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3302, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1414, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0061, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3427, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1531, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0028, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3234, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1450, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0055, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3080, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1429, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0045, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3710, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1622, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0050, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3315, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1495, device='cuda:0', grad_fn=<MulBackward0>)
vs, vt 0.24936918088368007 0.25570307891283717
need align? ->  False 0.25254859347428593
2023-09-15 05:02:15,767 - epoch:10, training loss:1.1597 validation loss:0.2494
Updating learning rate to 8.966017533692057e-05
Updating learning rate to 8.966017533692057e-05
(33889, 7)
(33889, 7) True
train 33889
tensor(0.0086, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3361, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1504, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0052, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3411, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1443, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0034, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4002, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1585, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0083, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3879, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1656, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0036, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3468, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1488, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0037, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3349, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1598, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0033, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3901, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1764, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0052, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3569, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1417, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0034, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3136, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1360, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0054, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3490, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1421, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0056, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3213, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1605, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0063, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3320, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1501, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0041, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3726, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1529, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0041, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3821, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1588, device='cuda:0', grad_fn=<MulBackward0>)
vs, vt 0.24839328197496277 0.25512309572526387
need align? ->  False 0.25254859347428593
2023-09-15 05:03:39,311 - epoch:11, training loss:1.1550 validation loss:0.2484
Updating learning rate to 8.534664800263505e-05
Updating learning rate to 8.534664800263505e-05
(33889, 7)
(33889, 7) False
train 33889
tensor(0.0044, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3678, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1665, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0039, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4113, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1761, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0052, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3642, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1586, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0041, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3683, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1556, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0035, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3391, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1511, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0054, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3759, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1575, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0028, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3835, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1485, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0030, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3479, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1374, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0039, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3271, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1463, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3760, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1597, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3159, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1369, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0048, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3483, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1606, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0032, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3340, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1504, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0041, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3226, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1396, device='cuda:0', grad_fn=<MulBackward0>)
vs, vt 0.2500054585295064 0.254988956962313
need align? ->  False 0.25254859347428593
2023-09-15 05:05:02,472 - epoch:12, training loss:1.1513 validation loss:0.2500
Updating learning rate to 8.042833314313765e-05
Updating learning rate to 8.042833314313765e-05
(33889, 7)
(33889, 7) True
train 33889
tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3266, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1526, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0052, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3532, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1475, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0032, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3307, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1428, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0059, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3278, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1566, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0030, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3543, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1546, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3188, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1427, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0027, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3116, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1320, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0037, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3789, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1578, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3229, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1371, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0066, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3566, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1404, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0030, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3458, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1559, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0033, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3008, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1387, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0057, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3470, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1565, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0045, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3271, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1432, device='cuda:0', grad_fn=<MulBackward0>)
vs, vt 0.25008693018129896 0.2590740577876568
need align? ->  False 0.25254859347428593
2023-09-15 05:06:26,030 - epoch:13, training loss:1.1475 validation loss:0.2501
Updating learning rate to 7.498938448928887e-05
Updating learning rate to 7.498938448928887e-05
(33889, 7)
(33889, 7) True
train 33889
tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3726, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1544, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3263, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1390, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0031, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3530, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1490, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0044, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3530, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1707, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0032, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3598, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1524, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0030, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3425, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1465, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.2889, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1332, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0037, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3767, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1600, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3277, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1415, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3567, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1548, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0037, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3393, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1376, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0029, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3426, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1602, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3615, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1464, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0046, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3072, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1284, device='cuda:0', grad_fn=<MulBackward0>)
vs, vt 0.2475039116186755 0.25930728944284576
need align? ->  False 0.25254859347428593
2023-09-15 05:07:49,173 - epoch:14, training loss:1.1447 validation loss:0.2475
Updating learning rate to 6.912286396051747e-05
Updating learning rate to 6.912286396051747e-05
(33889, 7)
(33889, 7) True
train 33889
tensor(0.0029, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3239, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1535, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3420, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1464, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0028, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3514, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1502, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3871, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1650, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0039, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3095, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1340, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0028, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3415, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1494, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3444, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1635, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4190, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1681, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3219, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1731, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3249, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1499, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3480, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1472, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3866, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1578, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0027, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3641, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1519, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3161, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1364, device='cuda:0', grad_fn=<MulBackward0>)
vs, vt 0.25226967232567926 0.2590551593473979
need align? ->  False 0.25254859347428593
2023-09-15 05:09:12,518 - epoch:15, training loss:1.1418 validation loss:0.2523
Updating learning rate to 6.292914934957758e-05
Updating learning rate to 6.292914934957758e-05
(33889, 7)
(33889, 7) False
train 33889
tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4004, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1588, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0028, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3355, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1597, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3327, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1475, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3409, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1520, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3585, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1570, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0031, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3789, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1498, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3695, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1618, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0037, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3387, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1556, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3503, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1500, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3303, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1420, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0039, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3711, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1583, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4233, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1641, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3308, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1545, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0028, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3422, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1436, device='cuda:0', grad_fn=<MulBackward0>)
vs, vt 0.25066414896930966 0.2608322377715792
need align? ->  False 0.25254859347428593
2023-09-15 05:10:36,112 - epoch:16, training loss:1.1398 validation loss:0.2507
Updating learning rate to 5.651421683068443e-05
Updating learning rate to 5.651421683068443e-05
(33889, 7)
(33889, 7) False
train 33889
tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3827, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1652, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4091, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1526, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3213, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1315, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3170, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1433, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3601, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1575, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3601, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1533, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0033, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3302, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1222, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3451, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1534, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.2801, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1403, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0033, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3499, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1596, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3228, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1347, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3186, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1357, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3714, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1705, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3408, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1442, device='cuda:0', grad_fn=<MulBackward0>)
vs, vt 0.24799580846514022 0.26063574335404804
need align? ->  False 0.25254859347428593
2023-09-15 05:11:59,178 - epoch:17, training loss:1.1381 validation loss:0.2480
Updating learning rate to 4.99878276777916e-05
Updating learning rate to 4.99878276777916e-05
(33889, 7)
(33889, 7) True
train 33889
tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3184, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1451, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0032, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3121, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1601, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3676, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1696, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0041, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3508, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1607, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3278, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1408, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3479, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1432, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3398, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1471, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3373, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1540, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3556, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1554, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3281, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1274, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3517, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1615, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0003, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3272, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1481, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0027, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3339, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1509, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3962, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1600, device='cuda:0', grad_fn=<MulBackward0>)
vs, vt 0.24817185423203877 0.25985421438302314
need align? ->  False 0.25254859347428593
2023-09-15 05:13:22,170 - epoch:18, training loss:1.1359 validation loss:0.2482
Updating learning rate to 4.346165021876202e-05
Updating learning rate to 4.346165021876202e-05
(33889, 7)
(33889, 7) True
train 33889
tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3466, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1469, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3975, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1410, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3695, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1484, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3761, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1816, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3707, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1450, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0044, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3699, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1526, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4330, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1706, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3249, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1351, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3577, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1558, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0043, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3251, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1404, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3181, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1415, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3699, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1650, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3170, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1581, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3656, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1548, device='cuda:0', grad_fn=<MulBackward0>)
vs, vt 0.2472144507084574 0.2591840291236128
need align? ->  False 0.25254859347428593
2023-09-15 05:14:45,092 - epoch:19, training loss:1.1341 validation loss:0.2472
Updating learning rate to 3.704734915931789e-05
Updating learning rate to 3.704734915931789e-05
(33889, 7)
(33889, 7) False
train 33889
tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3747, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1628, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.2979, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1449, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0027, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.2942, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1243, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3087, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1311, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3778, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1559, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3723, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1533, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3528, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1456, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0004, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4098, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1620, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3155, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1274, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4289, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1704, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3852, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1696, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3334, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1585, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3671, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1471, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0004, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3540, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1639, device='cuda:0', grad_fn=<MulBackward0>)
vs, vt 0.24860380994422096 0.2597360545183931
need align? ->  False 0.25254859347428593
2023-09-15 05:16:08,309 - epoch:20, training loss:1.1328 validation loss:0.2486
Updating learning rate to 3.085467496896657e-05
Updating learning rate to 3.085467496896657e-05
(33889, 7)
(33889, 7) True
train 33889
tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3336, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1416, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3865, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1503, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3349, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1626, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3292, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1500, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3358, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1349, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4038, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1814, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3417, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1397, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3463, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1451, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3112, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1389, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0005, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3156, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1397, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3551, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1477, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3525, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1425, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3549, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1546, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3566, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1513, device='cuda:0', grad_fn=<MulBackward0>)
vs, vt 0.24960490582244738 0.2591137011774949
need align? ->  False 0.25254859347428593
2023-09-15 05:17:31,600 - epoch:21, training loss:1.1312 validation loss:0.2496
Updating learning rate to 2.4989586020038574e-05
Updating learning rate to 2.4989586020038574e-05
(33889, 7)
(33889, 7) True
train 33889
tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3934, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1772, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3254, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1518, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3417, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1393, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3504, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1520, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3296, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1462, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3130, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1318, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3580, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1355, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3429, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1421, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3295, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1503, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3477, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1422, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3405, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1650, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3312, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1429, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3348, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1471, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3093, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1558, device='cuda:0', grad_fn=<MulBackward0>)
vs, vt 0.24784110169325557 0.26125738346150945
need align? ->  False 0.25254859347428593
2023-09-15 05:18:54,616 - epoch:22, training loss:1.1303 validation loss:0.2478
Updating learning rate to 1.9552435610559948e-05
Updating learning rate to 1.9552435610559948e-05
(33889, 7)
(33889, 7) True
train 33889
tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3297, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1561, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3259, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1408, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3750, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1605, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3253, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1432, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3277, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1342, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0050, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3104, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1261, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0002, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.2995, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1247, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0004, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3524, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1512, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3125, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1481, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3340, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1505, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3802, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1430, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3459, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1460, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3960, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1526, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3258, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1307, device='cuda:0', grad_fn=<MulBackward0>)
vs, vt 0.24955995168004716 0.2600361874273845
need align? ->  False 0.25254859347428593
2023-09-15 05:20:17,711 - epoch:23, training loss:1.1293 validation loss:0.2496
Updating learning rate to 1.4636254891499773e-05
Updating learning rate to 1.4636254891499773e-05
(33889, 7)
(33889, 7) True
train 33889
tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3562, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1454, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0004, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3840, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1786, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3721, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1601, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0005, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3632, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1643, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0002, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3641, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1450, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0001, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3339, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1390, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3340, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1503, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3413, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1587, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3488, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1627, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0005, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3244, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1446, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3416, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1467, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3163, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1403, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4146, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1473, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3531, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1558, device='cuda:0', grad_fn=<MulBackward0>)
vs, vt 0.24816951142890112 0.261606842896768
need align? ->  False 0.25254859347428593
2023-09-15 05:21:40,921 - epoch:24, training loss:1.1285 validation loss:0.2482
Updating learning rate to 1.0325161077983956e-05
Updating learning rate to 1.0325161077983956e-05
(33889, 7)
(33889, 7) True
train 33889
tensor(0.0005, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3763, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1587, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4367, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1746, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0004, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3178, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1389, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3167, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1331, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3389, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1564, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3520, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1572, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3834, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1515, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3096, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1521, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0002, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3295, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1346, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0004, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3395, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1539, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3415, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1366, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3439, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1416, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0003, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3347, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1438, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3709, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1553, device='cuda:0', grad_fn=<MulBackward0>)
vs, vt 0.24864469457949911 0.26084040643913403
need align? ->  False 0.25254859347428593
2023-09-15 05:23:04,081 - epoch:25, training loss:1.1283 validation loss:0.2486
Updating learning rate to 6.692918180422756e-06
Updating learning rate to 6.692918180422756e-06
(33889, 7)
(33889, 7) True
train 33889
tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3728, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1676, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3368, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1490, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3819, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1396, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3550, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1764, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3577, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1689, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.2964, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1283, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4281, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1577, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3882, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1555, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3244, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1350, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3045, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1301, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3107, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1286, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3540, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1444, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3405, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1547, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3048, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1261, device='cuda:0', grad_fn=<MulBackward0>)
vs, vt 0.248440306356975 0.26065626949071885
need align? ->  False 0.25254859347428593
2023-09-15 05:24:27,337 - epoch:26, training loss:1.1275 validation loss:0.2484
Updating learning rate to 3.801674881841454e-06
Updating learning rate to 3.801674881841454e-06
(33889, 7)
(33889, 7) True
train 33889
tensor(0.0003, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3343, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1426, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3408, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1650, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0005, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3092, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1453, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3098, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1338, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0003, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3066, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1498, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3803, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1596, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.2982, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1486, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3729, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1490, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0003, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3605, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1597, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3457, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1528, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0003, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3196, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1373, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3260, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1385, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0005, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3562, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1462, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3638, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1495, device='cuda:0', grad_fn=<MulBackward0>)
vs, vt 0.24837834038904735 0.260843847649438
need align? ->  False 0.25254859347428593
2023-09-15 05:25:50,682 - epoch:27, training loss:1.1275 validation loss:0.2484
Updating learning rate to 1.7009011566828463e-06
Updating learning rate to 1.7009011566828463e-06
(33889, 7)
(33889, 7) True
train 33889
tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4078, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1676, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0001, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.2881, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1372, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3149, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1552, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3603, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1405, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3703, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1389, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3207, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1535, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0005, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.2936, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1355, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0003, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3375, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1440, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4081, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1729, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0005, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3327, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1368, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3144, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1275, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3377, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1369, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3777, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1479, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3072, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1361, device='cuda:0', grad_fn=<MulBackward0>)
vs, vt 0.24782246664166452 0.2610422401343073
need align? ->  False 0.25254859347428593
2023-09-15 05:27:14,129 - epoch:28, training loss:1.1271 validation loss:0.2478
Updating learning rate to 4.265418258289065e-07
Updating learning rate to 4.265418258289065e-07
(33889, 7)
(33889, 7) True
train 33889
tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3212, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1395, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0003, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3463, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1410, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3412, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1290, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3335, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1277, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3938, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1568, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0005, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3790, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1664, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0004, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3537, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1428, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0003, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3244, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1294, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3674, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1676, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0005, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3129, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1363, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0004, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3640, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1496, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0003, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3513, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1460, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3295, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1419, device='cuda:0', grad_fn=<MulBackward0>)
tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3735, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.1712, device='cuda:0', grad_fn=<MulBackward0>)
vs, vt 0.2479227636541639 0.2607576667836734
need align? ->  False 0.25254859347428593
2023-09-15 05:28:37,319 - epoch:29, training loss:1.1271 validation loss:0.2479
Updating learning rate to 4.015307497157289e-10
Updating learning rate to 4.015307497157289e-10
check exp/ECL-PatchTST2023-09-15-04:47:17.038728/0/0.2472_epoch_19.pkl  &  0.25254859347428593
2023-09-15 05:28:41,725 - [*] loss:0.3681
2023-09-15 05:28:41,758 - [*] phase 0, testing
2023-09-15 05:28:42,239 - T:336	MAE	0.385156	RMSE	0.368013	MAPE	234.659219
2023-09-15 05:28:42,240 - 336	mae	0.3852	
2023-09-15 05:28:42,240 - 336	rmse	0.3680	
2023-09-15 05:28:42,240 - 336	mape	234.6592	
----*-----
2023-09-15 05:28:46,714 - [*] loss:0.3818
2023-09-15 05:28:46,742 - [*] phase 0, testing
2023-09-15 05:28:47,212 - T:336	MAE	0.400905	RMSE	0.381705	MAPE	233.936739
2023-09-15 05:28:51,518 - [*] loss:0.4178
2023-09-15 05:28:51,545 - [*] phase 0, testing
2023-09-15 05:28:52,030 - T:336	MAE	0.421695	RMSE	0.417710	MAPE	228.635335
2023-09-15 05:28:59,015 - [*] loss:0.4367
2023-09-15 05:28:59,041 - [*] phase 0, testing
2023-09-15 05:28:59,518 - T:336	MAE	0.444670	RMSE	0.436649	MAPE	246.563673
2023-09-15 05:29:04,058 - [*] loss:0.3712
2023-09-15 05:29:04,084 - [*] phase 0, testing
2023-09-15 05:29:04,557 - T:336	MAE	0.392227	RMSE	0.371075	MAPE	212.164259
----*-----
avg under noise: 0.41487427800893784 0.4017845243215561
2023-09-15 05:29:08,333 - [*] loss:0.3681
2023-09-15 05:29:08,359 - [*] phase 0, testing
2023-09-15 05:29:08,843 - T:336	MAE	0.385156	RMSE	0.368013	MAPE	234.657669
2023-09-15 05:29:08,843 - 336	mae	0.3852	
2023-09-15 05:29:08,843 - 336	rmse	0.3680	
2023-09-15 05:29:08,843 - 336	mape	234.6577	
----*-----
2023-09-15 05:29:12,644 - [*] loss:0.3819
2023-09-15 05:29:12,671 - [*] phase 0, testing
2023-09-15 05:29:13,149 - T:336	MAE	0.400987	RMSE	0.381825	MAPE	234.450984
2023-09-15 05:29:16,962 - [*] loss:0.4182
2023-09-15 05:29:16,989 - [*] phase 0, testing
2023-09-15 05:29:17,475 - T:336	MAE	0.421820	RMSE	0.418104	MAPE	228.170323
2023-09-15 05:29:24,041 - [*] loss:0.4368
2023-09-15 05:29:24,067 - [*] phase 0, testing
2023-09-15 05:29:24,528 - T:336	MAE	0.444730	RMSE	0.436778	MAPE	246.624255
2023-09-15 05:29:28,539 - [*] loss:0.3712
2023-09-15 05:29:28,566 - [*] phase 0, testing
2023-09-15 05:29:29,044 - T:336	MAE	0.392153	RMSE	0.371095	MAPE	212.173057
----*-----
avg under noise: 0.4149223417043686 0.40195073187351227
