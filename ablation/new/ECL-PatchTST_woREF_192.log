2023-09-14 22:42:14,081 - logger name:exp/ECL-PatchTST2023-09-14-22:42:14.080920/ECL-PatchTST.log
2023-09-14 22:42:14,081 - params : {'loss': 'huber', 'conf': 'ECL-PatchTST', 'data_name': 'ETTm1', 'iteration': 1, 'train': 1, 'mainrs': 0, 'abl': 1, 'abl_tmp_context': 0, 'abl_ae': 0, 'no_tmp': 0, 'load': True, 'build_graph': False, 'same_init': True, 'grad_norm': False, 'refiner_residual': 0, 'root_path': '', 'exp_path': 'exp/', 'val_test_mix': False, 'lr': 0.0001, 'lradj': 'TST', 'dropout': 0.2, 'fc_dropout': 0.2, 'head_dropout': 0.0, 'patch_len': 16, 'stride': 8, 'd_ff': 256, 'd_model': 128, 'n_heads': 16, 'seq_len': 336, 'pred_len': 192, 'noise_rate': 0.5, 'device': device(type='cuda', index=0), 'test_model_path': '/Disk/fhyega/code/BASE/exp/ECL-PatchTST2023-08-26-13:08:31.837686/0/best_model.pkl', 'idx': -1, 'aligner': 1, 'always_align': 1, 'refiner': 0, 'rec_block_num': 1, 'enhance': 0, 'enhance_type': 5, 'seed': 34, 'batch_size': 64, 'share_head': 0, 'add_noise': 1, 'add_norm': 0, 'jitter_sigma': 0.4, 'slope_rate': 0.01, 'slope_range': 0.2, 'alpha': 10.0, 'beta': 1.0, 'gamma': 0.15, 'feature_jittering': 1, 'rec_intra_feature': 0, 'rec_ori': 1, 'mid_dim': 128, 'test_en': 0, 'debugger': 0, 'summary': 0, 'omega': 1.0, 'theta': 1.5, 'mask_border': 1, 'sup_weight': 10.0, 'rec_length_ratio': 0.8, 'ref_dropout': 0.0, 'ref_block_num': 1, 'add_FFN': 1, 'add_residual': 0, 'rec_all': 0, 'e_layers': 3, 'early_break': 0, 'early_stop': 10, 'lo': None, '/* model related args*/': '//', 'model_name': 'PatchTST', 'label_len': 48, 'features': 'M', 'target': 'OT', 'graph_input': False, 'individual': False, 'd_layers': 1, 'factor': 1, 'des': 'Exp', 'padding_patch': 'end', 'revin': 1, 'affine': 0, 'subtract_last': 0, 'decomposition': 0, 'kernel_size': 25, 'output_attention': 0, 'embed_type': 0, 'activation': 'gelu', 'distil': 1, 'linear_output': 1, 'pct_start': 0.2, 'indie': 1, '/*train related args*/': '//', 'epoch': 30, '/*dataset related args*/': '//', 'save_data_path': 'data/ECL/', 'data_process': True, 'embed': 'timeF', 'freq': 'h', 'begin_phase': 0, 'end_phase': 1, 'phase_len': -1, 'val_ratio': 0.33, 'graph_size': 321, '/*strategy related args*/': '//', 'strategy': 'incremental', 'increase': False, 'detect': False, 'detect_strategy': 'feature', 'replay': False, 'replay_strategy': 'random', 'repaly_num_samples': 100, 'ewc': False, 'ewc_strategy': 'ewc', 'ewc_lambda': 0.0001, 'subgraph_train': False, 'num_hops': 2, 'logname': 'ECL-PatchTST', 'time': '2023-09-14-22:42:14.080920', 'path': 'exp/ECL-PatchTST2023-09-14-22:42:14.080920', 'num_workers': 4, 'start_train': 0, 'train_mode': 'pretrain', 'get_score': False, 'use_cm': True, 'logger': <Logger __main__ (INFO)>}
2023-09-14 22:42:14,081 - [*] phase 0 start training
0 69680
train 34033
val 11329
test 11329
2023-09-14 22:42:14,903 - [*] phase 0 Dataset load!
0 True None
2023-09-14 22:42:15,040 - [*] phase 0 Training start
train 34033
2023-09-14 22:42:52,785 - epoch:0, training loss:0.1826 validation loss:0.2089
(34033, 7)
(34033, 7) True
train 34033
vs, vt 0.20888322305059834 0.21553286732163993
Updating learning rate to 1.0434726665328864e-05
Updating learning rate to 1.0434726665328864e-05
(34033, 7)
(34033, 7) True
train 34033
vs, vt 0.20296851650215267 0.20824830730058505
need align? ->  False 0.20824830730058505
2023-09-14 22:44:34,891 - epoch:1, training loss:1.6241 validation loss:0.2030
Updating learning rate to 2.8013668858919874e-05
Updating learning rate to 2.8013668858919874e-05
(34033, 7)
(34033, 7) False
train 34033
vs, vt 0.20383622811249133 0.2064254196423493
need align? ->  False 0.2064254196423493
2023-09-14 22:45:48,970 - epoch:2, training loss:0.9243 validation loss:0.2038
Updating learning rate to 5.2023672910715735e-05
Updating learning rate to 5.2023672910715735e-05
(34033, 7)
(34033, 7) False
train 34033
vs, vt 0.2032563215268127 0.20868009213734878
need align? ->  False 0.2064254196423493
2023-09-14 22:47:02,662 - epoch:3, training loss:0.7478 validation loss:0.2033
Updating learning rate to 7.602732993293542e-05
Updating learning rate to 7.602732993293542e-05
(34033, 7)
(34033, 7) False
train 34033
vs, vt 0.20196600406943413 0.20590920465883245
need align? ->  False 0.20590920465883245
2023-09-14 22:48:16,450 - epoch:4, training loss:0.6832 validation loss:0.2020
Updating learning rate to 9.3588932762817e-05
Updating learning rate to 9.3588932762817e-05
(34033, 7)
(34033, 7) True
train 34033
vs, vt 0.1989979970614227 0.20692508142399654
need align? ->  False 0.20590920465883245
2023-09-14 22:49:30,639 - epoch:5, training loss:0.6035 validation loss:0.1990
Updating learning rate to 9.999999848075964e-05
Updating learning rate to 9.999999848075964e-05
(34033, 7)
(34033, 7) False
train 34033
vs, vt 0.19880643327919284 0.20385358608170842
need align? ->  False 0.20385358608170842
2023-09-14 22:50:45,083 - epoch:6, training loss:0.5730 validation loss:0.1988
Updating learning rate to 9.957063444389977e-05
Updating learning rate to 9.957063444389977e-05
(34033, 7)
(34033, 7) False
train 34033
vs, vt 0.1980454410646069 0.20276394408991497
need align? ->  False 0.20276394408991497
2023-09-14 22:51:59,190 - epoch:7, training loss:0.5658 validation loss:0.1980
Updating learning rate to 9.829310653018389e-05
Updating learning rate to 9.829310653018389e-05
(34033, 7)
(34033, 7) False
train 34033
vs, vt 0.20039383702900973 0.20221933642967363
need align? ->  False 0.20221933642967363
2023-09-14 22:53:13,573 - epoch:8, training loss:0.5629 validation loss:0.2004
Updating learning rate to 9.618927359641333e-05
Updating learning rate to 9.618927359641333e-05
(34033, 7)
(34033, 7) False
train 34033
vs, vt 0.19788180235145467 0.20327858863335646
need align? ->  False 0.20221933642967363
2023-09-14 22:54:27,574 - epoch:9, training loss:0.5745 validation loss:0.1979
Updating learning rate to 9.329513280737758e-05
Updating learning rate to 9.329513280737758e-05
(34033, 7)
(34033, 7) True
train 34033
vs, vt 0.19609676912594376 0.20232884575393092
need align? ->  False 0.20221933642967363
2023-09-14 22:55:41,403 - epoch:10, training loss:0.5654 validation loss:0.1961
Updating learning rate to 8.966020371438448e-05
Updating learning rate to 8.966020371438448e-05
(34033, 7)
(34033, 7) True
train 34033
vs, vt 0.19694612512176626 0.2011522094855148
need align? ->  False 0.2011522094855148
2023-09-14 22:56:55,628 - epoch:11, training loss:0.5613 validation loss:0.1969
Updating learning rate to 8.534668096200788e-05
Updating learning rate to 8.534668096200788e-05
(34033, 7)
(34033, 7) False
train 34033
vs, vt 0.19563018423871378 0.20076201831022006
need align? ->  False 0.20076201831022006
2023-09-14 22:58:10,017 - epoch:12, training loss:0.6236 validation loss:0.1956
Updating learning rate to 8.042837012047538e-05
Updating learning rate to 8.042837012047538e-05
(34033, 7)
(34033, 7) True
train 34033
vs, vt 0.1949943197116758 0.20085251992673017
need align? ->  False 0.20076201831022006
2023-09-14 22:59:24,101 - epoch:13, training loss:0.6377 validation loss:0.1950
Updating learning rate to 7.498942485189898e-05
Updating learning rate to 7.498942485189898e-05
(34033, 7)
(34033, 7) False
train 34033
vs, vt 0.1977301606217797 0.2008960707678219
need align? ->  False 0.20076201831022006
2023-09-14 23:00:38,021 - epoch:14, training loss:0.6285 validation loss:0.1977
Updating learning rate to 6.912290701778455e-05
Updating learning rate to 6.912290701778455e-05
(34033, 7)
(34033, 7) False
train 34033
vs, vt 0.19689044006838557 0.201690810575579
need align? ->  False 0.20076201831022006
2023-09-14 23:01:51,829 - epoch:15, training loss:0.6246 validation loss:0.1969
Updating learning rate to 6.29291943647798e-05
Updating learning rate to 6.29291943647798e-05
(34033, 7)
(34033, 7) False
train 34033
vs, vt 0.1953467381804177 0.2002711949263061
need align? ->  False 0.2002711949263061
2023-09-14 23:03:06,756 - epoch:16, training loss:0.6225 validation loss:0.1953
Updating learning rate to 5.651426303359923e-05
Updating learning rate to 5.651426303359923e-05
(34033, 7)
(34033, 7) False
train 34033
vs, vt 0.19917041140744526 0.20102960170571055
need align? ->  False 0.2002711949263061
2023-09-14 23:04:20,967 - epoch:17, training loss:0.6827 validation loss:0.1992
Updating learning rate to 4.99878742778743e-05
Updating learning rate to 4.99878742778743e-05
(34033, 7)
(34033, 7) True
train 34033
vs, vt 0.1972255486827553 0.20196822769102757
need align? ->  False 0.2002711949263061
2023-09-14 23:05:34,916 - epoch:18, training loss:0.6743 validation loss:0.1972
Updating learning rate to 4.346169641867228e-05
Updating learning rate to 4.346169641867228e-05
(34033, 7)
(34033, 7) True
train 34033
vs, vt 0.1958535159362501 0.20048340803451753
need align? ->  False 0.2002711949263061
2023-09-14 23:06:49,055 - epoch:19, training loss:0.6694 validation loss:0.1959
Updating learning rate to 3.704739416856244e-05
Updating learning rate to 3.704739416856244e-05
(34033, 7)
(34033, 7) True
train 34033
vs, vt 0.19540593036439982 0.19957918495860663
need align? ->  False 0.19957918495860663
2023-09-14 23:08:03,310 - epoch:20, training loss:0.6677 validation loss:0.1954
Updating learning rate to 3.0854718017424746e-05
Updating learning rate to 3.0854718017424746e-05
(34033, 7)
(34033, 7) True
train 34033
vs, vt 0.19565669242083356 0.19999889562722672
need align? ->  False 0.19957918495860663
2023-09-14 23:09:17,188 - epoch:21, training loss:0.7296 validation loss:0.1957
Updating learning rate to 2.4989626371139337e-05
Updating learning rate to 2.4989626371139337e-05
(34033, 7)
(34033, 7) True
train 34033
vs, vt 0.19637254479058672 0.20035116849571802
need align? ->  False 0.19957918495860663
2023-09-14 23:10:31,043 - epoch:22, training loss:0.7233 validation loss:0.1964
Updating learning rate to 1.9552472573884788e-05
Updating learning rate to 1.9552472573884788e-05
(34033, 7)
(34033, 7) True
train 34033
vs, vt 0.196339134315259 0.20023802446013086
need align? ->  False 0.19957918495860663
2023-09-14 23:11:45,143 - epoch:23, training loss:0.7216 validation loss:0.1963
Updating learning rate to 1.4636287834595912e-05
Updating learning rate to 1.4636287834595912e-05
(34033, 7)
(34033, 7) True
train 34033
vs, vt 0.19713634959934803 0.2003588176049878
need align? ->  False 0.19957918495860663
2023-09-14 23:12:59,260 - epoch:24, training loss:0.7203 validation loss:0.1971
check exp/ECL-PatchTST2023-09-14-22:42:14.080920/0/0.195_epoch_13.pkl  &  0.19957918495860663
2023-09-14 23:13:03,094 - [*] loss:0.3255
2023-09-14 23:13:03,113 - [*] phase 0, testing
2023-09-14 23:13:03,407 - T:192	MAE	0.361851	RMSE	0.326764	MAPE	226.014519
2023-09-14 23:13:03,407 - 192	mae	0.3619	
2023-09-14 23:13:03,407 - 192	rmse	0.3268	
2023-09-14 23:13:03,407 - 192	mape	226.0145	
----*-----
2023-09-14 23:13:07,189 - [*] loss:0.3416
2023-09-14 23:13:07,208 - [*] phase 0, testing
2023-09-14 23:13:07,496 - T:192	MAE	0.380147	RMSE	0.342829	MAPE	237.964177
2023-09-14 23:13:11,298 - [*] loss:0.4358
2023-09-14 23:13:11,313 - [*] phase 0, testing
2023-09-14 23:13:11,591 - T:192	MAE	0.437257	RMSE	0.436751	MAPE	282.423902
2023-09-14 23:13:18,183 - [*] loss:0.4171
2023-09-14 23:13:18,199 - [*] phase 0, testing
2023-09-14 23:13:18,486 - T:192	MAE	0.442765	RMSE	0.418728	MAPE	253.516603
2023-09-14 23:13:22,361 - [*] loss:0.3358
2023-09-14 23:13:22,376 - [*] phase 0, testing
2023-09-14 23:13:22,653 - T:192	MAE	0.374293	RMSE	0.336975	MAPE	215.509272
----*-----
avg under noise: 0.40861550718545914 0.38382086902856827
2023-09-14 23:13:26,296 - [*] loss:0.3255
2023-09-14 23:13:26,313 - [*] phase 0, testing
2023-09-14 23:13:26,601 - T:192	MAE	0.361851	RMSE	0.326764	MAPE	226.014519
2023-09-14 23:13:26,601 - 192	mae	0.3619	
2023-09-14 23:13:26,602 - 192	rmse	0.3268	
2023-09-14 23:13:26,602 - 192	mape	226.0145	
----*-----
2023-09-14 23:13:30,432 - [*] loss:0.3414
2023-09-14 23:13:30,447 - [*] phase 0, testing
2023-09-14 23:13:30,736 - T:192	MAE	0.379931	RMSE	0.342606	MAPE	237.906718
2023-09-14 23:13:34,468 - [*] loss:0.4369
2023-09-14 23:13:34,483 - [*] phase 0, testing
2023-09-14 23:13:34,766 - T:192	MAE	0.437733	RMSE	0.437325	MAPE	282.865119
2023-09-14 23:13:41,299 - [*] loss:0.4159
2023-09-14 23:13:41,315 - [*] phase 0, testing
2023-09-14 23:13:41,600 - T:192	MAE	0.442073	RMSE	0.417537	MAPE	253.875351
2023-09-14 23:13:45,437 - [*] loss:0.3365
2023-09-14 23:13:45,453 - [*] phase 0, testing
2023-09-14 23:13:45,737 - T:192	MAE	0.374733	RMSE	0.337615	MAPE	215.533781
----*-----
avg under noise: 0.408617727458477 0.3837706372141838
