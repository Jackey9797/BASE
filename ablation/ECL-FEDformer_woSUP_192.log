2023-09-07 15:34:46,357 - logger name:exp/ECL-FEDformer2023-09-07-15:34:46.357613/ECL-FEDformer.log
2023-09-07 15:34:46,357 - params : {'loss': 'huber', 'conf': 'ECL-FEDformer', 'data_name': 'ETTm1', 'iteration': 1, 'train': 1, 'mainrs': 0, 'abl': 0, 'abl_tmp_context': 0, 'abl_ae': 0, 'no_tmp': 0, 'load': True, 'build_graph': False, 'same_init': True, 'grad_norm': False, 'refiner_residual': 0, 'root_path': '', 'exp_path': 'exp/', 'val_test_mix': False, 'lr': 0.0001, 'lradj': 'TST', 'dropout': 0.05, 'fc_dropout': 0.05, 'head_dropout': 0.0, 'patch_len': 16, 'stride': 8, 'd_ff': 512, 'd_model': 128, 'n_heads': 8, 'seq_len': 96, 'pred_len': 192, 'noise_rate': 0.5, 'device': device(type='cuda', index=0), 'test_model_path': '/Disk/fhyega/code/BASE/exp/ECL-PatchTST2023-08-26-13:08:31.837686/0/best_model.pkl', 'idx': -1, 'aligner': 1, 'always_align': 1, 'refiner': 1, 'rec_block_num': 1, 'enhance': 1, 'enhance_type': 5, 'seed': 34, 'batch_size': 64, 'share_head': 0, 'add_noise': 1, 'add_norm': 0, 'jitter_sigma': 0.4, 'slope_rate': 0.01, 'slope_range': 0.2, 'alpha': 10.0, 'beta': 1.0, 'gamma': 0.15, 'feature_jittering': 1, 'rec_intra_feature': 0, 'rec_ori': 1, 'mid_dim': 128, 'test_en': 0, 'debugger': 0, 'summary': 0, 'omega': 1.0, 'theta': 1.5, 'mask_border': 1, 'sup_weight': 0.0, 'rec_length_ratio': 0.8, 'ref_dropout': 0.0, 'ref_block_num': 1, 'add_FFN': 1, 'add_residual': 0, 'rec_all': 0, 'e_layers': 2, 'early_break': 0, 'early_stop': 10, '/* model related args*/': '//', 'model_name': 'FEDformer', 'label_len': 48, 'features': 'M', 'target': 'OT', 'graph_input': False, 'individual': False, 'd_layers': 1, 'factor': 1, 'des': 'Exp', 'padding_patch': 'end', 'revin': 1, 'affine': 0, 'subtract_last': 0, 'decomposition': 0, 'kernel_size': 25, 'output_attention': 0, 'embed_type': 0, 'activation': 'gelu', 'distil': 1, 'linear_output': 0, 'pct_start': 0.2, 'num_kernels': 6, 'top_k': 5, 'moving_avg': 25, 'indie': 0, '/*train related args*/': '//', 'epoch': 30, '/*dataset related args*/': '//', 'save_data_path': 'data/ECL/', 'data_process': True, 'embed': 'timeF', 'freq': 'h', 'begin_phase': 0, 'end_phase': 1, 'phase_len': -1, 'val_ratio': 0.33, 'graph_size': 321, '/*strategy related args*/': '//', 'strategy': 'incremental', 'increase': False, 'detect': False, 'detect_strategy': 'feature', 'replay': False, 'replay_strategy': 'random', 'repaly_num_samples': 100, 'ewc': False, 'ewc_strategy': 'ewc', 'ewc_lambda': 0.0001, 'subgraph_train': False, 'num_hops': 2, 'logname': 'ECL-FEDformer', 'time': '2023-09-07-15:34:46.357613', 'path': 'exp/ECL-FEDformer2023-09-07-15:34:46.357613', 'num_workers': 4, 'start_train': 0, 'train_mode': 'pretrain', 'get_score': False, 'use_cm': True, 'logger': <Logger __main__ (INFO)>}
2023-09-07 15:34:46,358 - [*] phase 0 start training
0 69680
train 34273
val 11329
test 11329
2023-09-07 15:34:47,182 - [*] phase 0 Dataset load!
dropout 0.05
dropout 0.05
fourier enhanced block used!
modes=32, index=[0, 1, 2, 3, 6, 7, 8, 9, 10, 12, 13, 15, 16, 17, 19, 22, 23, 24, 26, 27, 28, 30, 31, 34, 37, 39, 40, 43, 44, 45, 46, 47]
fourier enhanced block used!
modes=32, index=[2, 7, 10, 12, 26, 30, 32, 33, 34, 41, 46, 47, 50, 51, 52, 55, 56, 68, 69, 71, 74, 75, 78, 82, 83, 85, 92, 97, 108, 110, 111, 114]
 fourier enhanced cross attention used!
modes_q=32, index_q=[0, 2, 6, 14, 16, 17, 20, 27, 30, 36, 49, 50, 51, 59, 60, 61, 67, 73, 75, 76, 77, 79, 82, 84, 85, 92, 96, 103, 105, 107, 112, 114]
modes_kv=32, index_kv=[1, 3, 7, 8, 9, 11, 13, 15, 17, 21, 23, 24, 25, 26, 27, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47]
1 True None
2023-09-07 15:34:47,562 - [*] phase 0 Training start
train 34273
2023-09-07 15:38:24,763 - epoch:0, training loss:0.3404 validation loss:0.3833
(34273, 1)
(34273, 1) True
train 34273
vs, vt 0.3832772280393022 0.3861126815167706
Updating learning rate to 1.0434697148810579e-05
Updating learning rate to 1.0434697148810579e-05
(34273, 1)
(34273, 1) True
train 34273
vs, vt 0.33047335130277644 0.3348229607002119
need align? ->  False 0.3348229607002119
2023-09-07 15:47:28,430 - epoch:1, training loss:6.5668 validation loss:0.3305
Updating learning rate to 2.801356662037103e-05
Updating learning rate to 2.801356662037103e-05
(34273, 1)
(34273, 1) True
train 34273
vs, vt 0.2660846673161461 0.3189055591486813
need align? ->  False 0.3189055591486813
2023-09-07 15:54:12,979 - epoch:2, training loss:5.3916 validation loss:0.2661
Updating learning rate to 5.202349586184953e-05
Updating learning rate to 5.202349586184953e-05
(34273, 1)
(34273, 1) True
train 34273
vs, vt 0.2482658036764753 0.2809976777166463
need align? ->  False 0.2809976777166463
2023-09-07 16:00:55,801 - epoch:3, training loss:4.7887 validation loss:0.2483
Updating learning rate to 7.602712557185922e-05
Updating learning rate to 7.602712557185922e-05
(34273, 1)
(34273, 1) True
train 34273
vs, vt 0.23863252936705445 0.25745139702149994
need align? ->  False 0.25745139702149994
2023-09-07 16:07:46,803 - epoch:4, training loss:4.4513 validation loss:0.2386
Updating learning rate to 9.35887854313957e-05
Updating learning rate to 9.35887854313957e-05
(34273, 1)
(34273, 1) True
train 34273
vs, vt 0.23534980550240936 0.24793271410666154
need align? ->  False 0.24793271410666154
2023-09-07 16:14:41,961 - epoch:5, training loss:4.2409 validation loss:0.2353
Updating learning rate to 9.999999850339233e-05
Updating learning rate to 9.999999850339233e-05
(34273, 1)
(34273, 1) True
train 34273
vs, vt 0.23472092553889484 0.24439212104326555
need align? ->  False 0.24439212104326555
2023-09-07 16:21:31,431 - epoch:6, training loss:4.0976 validation loss:0.2347
Updating learning rate to 9.957064649497094e-05
Updating learning rate to 9.957064649497094e-05
(34273, 1)
(34273, 1) True
train 34273
vs, vt 0.23157785426867142 0.24376051207439284
need align? ->  False 0.24376051207439284
2023-09-07 16:28:17,118 - epoch:7, training loss:3.9884 validation loss:0.2316
Updating learning rate to 9.829313040349635e-05
Updating learning rate to 9.829313040349635e-05
(34273, 1)
(34273, 1) True
train 34273
vs, vt 0.2316177864925245 0.24225318218382558
need align? ->  False 0.24225318218382558
2023-09-07 16:35:03,196 - epoch:8, training loss:3.9129 validation loss:0.2316
Updating learning rate to 9.618930888348809e-05
Updating learning rate to 9.618930888348809e-05
(34273, 1)
(34273, 1) True
train 34273
vs, vt 0.2301733811082465 0.24113589261522453
need align? ->  False 0.24113589261522453
2023-09-07 16:41:50,336 - epoch:9, training loss:3.8596 validation loss:0.2302
Updating learning rate to 9.329517890444304e-05
Updating learning rate to 9.329517890444304e-05
(34273, 1)
(34273, 1) True
train 34273
vs, vt 0.23051621281447704 0.2403797563583998
need align? ->  False 0.2403797563583998
2023-09-07 16:48:40,247 - epoch:10, training loss:3.8192 validation loss:0.2305
Updating learning rate to 8.966025983270703e-05
Updating learning rate to 8.966025983270703e-05
(34273, 1)
(34273, 1) True
train 34273
vs, vt 0.22792111933649925 0.23878352773072345
need align? ->  False 0.23878352773072345
2023-09-07 16:55:18,487 - epoch:11, training loss:3.7935 validation loss:0.2279
Updating learning rate to 8.534674614138748e-05
Updating learning rate to 8.534674614138748e-05
(34273, 1)
(34273, 1) True
train 34273
vs, vt 0.2269843171528551 0.2363769282492694
need align? ->  False 0.2363769282492694
2023-09-07 17:02:21,324 - epoch:12, training loss:3.7761 validation loss:0.2270
Updating learning rate to 8.042844324567477e-05
Updating learning rate to 8.042844324567477e-05
(34273, 1)
(34273, 1) True
train 34273
vs, vt 0.2271845925264479 0.23572722694763307
need align? ->  False 0.23572722694763307
2023-09-07 17:09:05,552 - epoch:13, training loss:3.7625 validation loss:0.2272
Updating learning rate to 7.498950467172574e-05
Updating learning rate to 7.498950467172574e-05
(34273, 1)
(34273, 1) True
train 34273
vs, vt 0.2278343615948819 0.23588638327848377
need align? ->  False 0.23572722694763307
2023-09-07 17:15:57,748 - epoch:14, training loss:3.7590 validation loss:0.2278
Updating learning rate to 6.912299216649929e-05
Updating learning rate to 6.912299216649929e-05
(34273, 1)
(34273, 1) True
train 34273
vs, vt 0.22602175479608305 0.23394360592107424
need align? ->  False 0.23394360592107424
2023-09-07 17:22:43,799 - epoch:15, training loss:3.7518 validation loss:0.2260
Updating learning rate to 6.292928338546441e-05
Updating learning rate to 6.292928338546441e-05
(34273, 1)
(34273, 1) True
train 34273
vs, vt 0.22596144527615455 0.23370840670436285
need align? ->  False 0.23370840670436285
2023-09-07 17:29:36,611 - epoch:16, training loss:3.7497 validation loss:0.2260
Updating learning rate to 5.651435440308513e-05
Updating learning rate to 5.651435440308513e-05
(34273, 1)
(34273, 1) True
train 34273
vs, vt 0.22483602295933144 0.23294196685964472
need align? ->  False 0.23294196685964472
2023-09-07 17:36:28,645 - epoch:17, training loss:3.7199 validation loss:0.2248
Updating learning rate to 4.9987966432804234e-05
Updating learning rate to 4.9987966432804234e-05
(34273, 1)
(34273, 1) True
train 34273
vs, vt 0.22626213101523646 0.23115959100090386
need align? ->  False 0.23115959100090386
2023-09-07 17:43:17,996 - epoch:18, training loss:3.6546 validation loss:0.2263
Updating learning rate to 4.346178778224986e-05
Updating learning rate to 4.346178778224986e-05
(34273, 1)
(34273, 1) True
train 34273
vs, vt 0.2246142505887854 0.23104539626602377
need align? ->  False 0.23104539626602377
2023-09-07 17:50:09,468 - epoch:19, training loss:3.9019 validation loss:0.2246
Updating learning rate to 3.704748317753153e-05
Updating learning rate to 3.704748317753153e-05
(34273, 1)
(34273, 1) True
train 34273
vs, vt 0.22560111140267233 0.23030258675388407
need align? ->  False 0.23030258675388407
2023-09-07 17:56:45,993 - epoch:20, training loss:4.0529 validation loss:0.2256
Updating learning rate to 3.0854803148817166e-05
Updating learning rate to 3.0854803148817166e-05
(34273, 1)
(34273, 1) True
train 34273
vs, vt 0.22511731054675713 0.23138906572307094
need align? ->  False 0.23030258675388407
2023-09-07 18:01:28,934 - epoch:21, training loss:4.1913 validation loss:0.2251
Updating learning rate to 2.4989706168333394e-05
Updating learning rate to 2.4989706168333394e-05
(34273, 1)
(34273, 1) True
train 34273
vs, vt 0.22485483613576782 0.23021207165935736
need align? ->  False 0.23021207165935736
2023-09-07 18:06:11,548 - epoch:22, training loss:4.1690 validation loss:0.2249
Updating learning rate to 1.955254567152836e-05
Updating learning rate to 1.955254567152836e-05
(34273, 1)
(34273, 1) True
train 34273
vs, vt 0.22498969750457934 0.2305250781891721
need align? ->  False 0.23021207165935736
2023-09-07 18:10:53,730 - epoch:23, training loss:4.2733 validation loss:0.2250
Updating learning rate to 1.4636352981968055e-05
Updating learning rate to 1.4636352981968055e-05
(34273, 1)
(34273, 1) True
train 34273
vs, vt 0.22479672037232457 0.23034510836842353
need align? ->  False 0.23021207165935736
2023-09-07 18:15:33,334 - epoch:24, training loss:4.2596 validation loss:0.2248
Updating learning rate to 1.032524551959702e-05
Updating learning rate to 1.032524551959702e-05
(34273, 1)
(34273, 1) True
train 34273
vs, vt 0.2247717882182156 0.23050297687897522
need align? ->  False 0.23021207165935736
2023-09-07 18:20:15,145 - epoch:25, training loss:4.2508 validation loss:0.2248
Updating learning rate to 6.692987528361205e-06
Updating learning rate to 6.692987528361205e-06
(34273, 1)
(34273, 1) True
train 34273
vs, vt 0.22434168447102054 0.23018113241185634
need align? ->  False 0.23018113241185634
2023-09-07 18:24:59,570 - epoch:26, training loss:4.2468 validation loss:0.2243
Updating learning rate to 3.8017279495428126e-06
Updating learning rate to 3.8017279495428126e-06
(34273, 1)
(34273, 1) True
train 34273
vs, vt 0.22463433492635743 0.23022354034225592
need align? ->  False 0.23018113241185634
2023-09-07 18:29:44,392 - epoch:27, training loss:4.2339 validation loss:0.2246
Updating learning rate to 1.7009370361440373e-06
Updating learning rate to 1.7009370361440373e-06
(34273, 1)
(34273, 1) True
train 34273
vs, vt 0.2246624535221732 0.23021054194633211
need align? ->  False 0.23018113241185634
2023-09-07 18:34:29,066 - epoch:28, training loss:4.2291 validation loss:0.2247
Updating learning rate to 4.2655990314240746e-07
Updating learning rate to 4.2655990314240746e-07
(34273, 1)
(34273, 1) True
train 34273
vs, vt 0.22463935523639234 0.23020568983943274
need align? ->  False 0.23018113241185634
2023-09-07 18:39:13,386 - epoch:29, training loss:4.2255 validation loss:0.2246
Updating learning rate to 4.014966076743239e-10
Updating learning rate to 4.014966076743239e-10
dropout 0.05
dropout 0.05
fourier enhanced block used!
modes=32, index=[0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 12, 14, 15, 16, 17, 18, 19, 21, 22, 24, 25, 27, 29, 33, 34, 35, 36, 37, 39, 42, 43, 46]
fourier enhanced block used!
modes=32, index=[0, 3, 5, 9, 15, 16, 19, 25, 30, 33, 34, 46, 49, 53, 58, 63, 67, 69, 70, 73, 80, 82, 98, 99, 101, 103, 107, 109, 112, 114, 116, 117]
 fourier enhanced cross attention used!
modes_q=32, index_q=[3, 5, 6, 7, 8, 10, 11, 16, 18, 25, 28, 29, 31, 35, 41, 45, 46, 65, 66, 69, 72, 83, 84, 86, 93, 99, 104, 105, 106, 109, 114, 117]
modes_kv=32, index_kv=[0, 3, 5, 6, 7, 8, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 25, 26, 27, 28, 29, 33, 36, 38, 39, 40, 41, 42, 44, 47]
check exp/ECL-FEDformer2023-09-07-15:34:46.357613/0/0.2243_epoch_26.pkl  &  0.23018113241185634
2023-09-07 18:39:22,928 - [*] loss:2.0617
2023-09-07 18:39:22,944 - [*] phase 0, testing
2023-09-07 18:39:23,186 - T:192	MAE	0.997984	RMSE	2.061607	MAPE	569.295073
2023-09-07 18:39:23,186 - 192	mae	0.9980	
2023-09-07 18:39:23,186 - 192	rmse	2.0616	
2023-09-07 18:39:23,186 - 192	mape	569.2951	
2023-09-07 18:39:32,073 - [*] loss:2.0615
2023-09-07 18:39:32,089 - [*] phase 0, testing
2023-09-07 18:39:32,330 - T:192	MAE	0.997922	RMSE	2.061405	MAPE	569.249487
