2023-09-07 18:39:34,308 - logger name:exp/ECL-FEDformer2023-09-07-18:39:34.308280/ECL-FEDformer.log
2023-09-07 18:39:34,308 - params : {'loss': 'huber', 'conf': 'ECL-FEDformer', 'data_name': 'ETTm1', 'iteration': 1, 'train': 1, 'mainrs': 0, 'abl': 0, 'abl_tmp_context': 0, 'abl_ae': 0, 'no_tmp': 1, 'load': True, 'build_graph': False, 'same_init': True, 'grad_norm': False, 'refiner_residual': 0, 'root_path': '', 'exp_path': 'exp/', 'val_test_mix': False, 'lr': 0.0001, 'lradj': 'TST', 'dropout': 0.05, 'fc_dropout': 0.05, 'head_dropout': 0.0, 'patch_len': 16, 'stride': 8, 'd_ff': 512, 'd_model': 128, 'n_heads': 8, 'seq_len': 96, 'pred_len': 192, 'noise_rate': 0.5, 'device': device(type='cuda', index=0), 'test_model_path': '/Disk/fhyega/code/BASE/exp/ECL-PatchTST2023-08-26-13:08:31.837686/0/best_model.pkl', 'idx': -1, 'aligner': 1, 'always_align': 1, 'refiner': 1, 'rec_block_num': 1, 'enhance': 1, 'enhance_type': 5, 'seed': 34, 'batch_size': 64, 'share_head': 0, 'add_noise': 1, 'add_norm': 0, 'jitter_sigma': 0.4, 'slope_rate': 0.01, 'slope_range': 0.2, 'alpha': 10.0, 'beta': 1.0, 'gamma': 0.15, 'feature_jittering': 1, 'rec_intra_feature': 0, 'rec_ori': 1, 'mid_dim': 128, 'test_en': 0, 'debugger': 0, 'summary': 0, 'omega': 1.0, 'theta': 1.5, 'mask_border': 1, 'sup_weight': 10.0, 'rec_length_ratio': 0.8, 'ref_dropout': 0.0, 'ref_block_num': 1, 'add_FFN': 1, 'add_residual': 0, 'rec_all': 0, 'e_layers': 2, 'early_break': 0, 'early_stop': 10, '/* model related args*/': '//', 'model_name': 'FEDformer', 'label_len': 48, 'features': 'M', 'target': 'OT', 'graph_input': False, 'individual': False, 'd_layers': 1, 'factor': 1, 'des': 'Exp', 'padding_patch': 'end', 'revin': 1, 'affine': 0, 'subtract_last': 0, 'decomposition': 0, 'kernel_size': 25, 'output_attention': 0, 'embed_type': 0, 'activation': 'gelu', 'distil': 1, 'linear_output': 0, 'pct_start': 0.2, 'num_kernels': 6, 'top_k': 5, 'moving_avg': 25, 'indie': 0, '/*train related args*/': '//', 'epoch': 30, '/*dataset related args*/': '//', 'save_data_path': 'data/ECL/', 'data_process': True, 'embed': 'timeF', 'freq': 'h', 'begin_phase': 0, 'end_phase': 1, 'phase_len': -1, 'val_ratio': 0.33, 'graph_size': 321, '/*strategy related args*/': '//', 'strategy': 'incremental', 'increase': False, 'detect': False, 'detect_strategy': 'feature', 'replay': False, 'replay_strategy': 'random', 'repaly_num_samples': 100, 'ewc': False, 'ewc_strategy': 'ewc', 'ewc_lambda': 0.0001, 'subgraph_train': False, 'num_hops': 2, 'logname': 'ECL-FEDformer', 'time': '2023-09-07-18:39:34.308280', 'path': 'exp/ECL-FEDformer2023-09-07-18:39:34.308280', 'num_workers': 4, 'start_train': 0, 'train_mode': 'pretrain', 'get_score': False, 'use_cm': True, 'logger': <Logger __main__ (INFO)>}
2023-09-07 18:39:34,308 - [*] phase 0 start training
0 69680
train 34273
val 11329
test 11329
2023-09-07 18:39:35,127 - [*] phase 0 Dataset load!
dropout 0.05
dropout 0.05
fourier enhanced block used!
modes=32, index=[0, 1, 2, 3, 6, 7, 8, 9, 10, 12, 13, 15, 16, 17, 19, 22, 23, 24, 26, 27, 28, 30, 31, 34, 37, 39, 40, 43, 44, 45, 46, 47]
fourier enhanced block used!
modes=32, index=[2, 7, 10, 12, 26, 30, 32, 33, 34, 41, 46, 47, 50, 51, 52, 55, 56, 68, 69, 71, 74, 75, 78, 82, 83, 85, 92, 97, 108, 110, 111, 114]
 fourier enhanced cross attention used!
modes_q=32, index_q=[0, 2, 6, 14, 16, 17, 20, 27, 30, 36, 49, 50, 51, 59, 60, 61, 67, 73, 75, 76, 77, 79, 82, 84, 85, 92, 96, 103, 105, 107, 112, 114]
modes_kv=32, index_kv=[1, 3, 7, 8, 9, 11, 13, 15, 17, 21, 23, 24, 25, 26, 27, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47]
1 True None
2023-09-07 18:39:35,265 - [*] phase 0 Training start
train 34273
2023-09-07 18:41:34,339 - epoch:0, training loss:0.3404 validation loss:0.3833
(34273, 1)
(34273, 1) True
train 34273
vs, vt 0.38327722829044536 0.38611267934019644
Updating learning rate to 1.0434697148810579e-05
Updating learning rate to 1.0434697148810579e-05
(34273, 1)
(34273, 1) True
train 34273
vs, vt 0.3304813151781479 0.3348206624053837
need align? ->  False 0.3348206624053837
2023-09-07 18:47:49,724 - epoch:1, training loss:16.4094 validation loss:0.3305
Updating learning rate to 2.801356662037103e-05
Updating learning rate to 2.801356662037103e-05
(34273, 1)
(34273, 1) True
train 34273
vs, vt 0.2661341732430659 0.3189141974271683
need align? ->  False 0.3189141974271683
2023-09-07 18:52:31,617 - epoch:2, training loss:14.0293 validation loss:0.2661
Updating learning rate to 5.202349586184953e-05
Updating learning rate to 5.202349586184953e-05
(34273, 1)
(34273, 1) True
train 34273
vs, vt 0.2483039597739999 0.2810198585764411
need align? ->  False 0.2810198585764411
2023-09-07 18:57:13,943 - epoch:3, training loss:9.7611 validation loss:0.2483
Updating learning rate to 7.602712557185922e-05
Updating learning rate to 7.602712557185922e-05
(34273, 1)
(34273, 1) True
train 34273
vs, vt 0.23866624786947552 0.2574825399251801
need align? ->  False 0.2574825399251801
2023-09-07 19:01:55,261 - epoch:4, training loss:6.4614 validation loss:0.2387
Updating learning rate to 9.35887854313957e-05
Updating learning rate to 9.35887854313957e-05
(34273, 1)
(34273, 1) True
train 34273
vs, vt 0.23532301449122722 0.24811166148172337
need align? ->  False 0.24811166148172337
2023-09-07 19:06:37,114 - epoch:5, training loss:5.2177 validation loss:0.2353
Updating learning rate to 9.999999850339233e-05
Updating learning rate to 9.999999850339233e-05
(34273, 1)
(34273, 1) True
train 34273
vs, vt 0.2345543901613924 0.2441782976050725
need align? ->  False 0.2441782976050725
2023-09-07 19:11:19,501 - epoch:6, training loss:4.7088 validation loss:0.2346
Updating learning rate to 9.957064649497094e-05
Updating learning rate to 9.957064649497094e-05
(34273, 1)
(34273, 1) True
train 34273
vs, vt 0.2315416932733876 0.2437446988030766
need align? ->  False 0.2437446988030766
2023-09-07 19:16:00,573 - epoch:7, training loss:4.4095 validation loss:0.2315
Updating learning rate to 9.829313040349635e-05
Updating learning rate to 9.829313040349635e-05
(34273, 1)
(34273, 1) True
train 34273
vs, vt 0.23115703356818537 0.24222909623568648
need align? ->  False 0.24222909623568648
2023-09-07 19:20:43,948 - epoch:8, training loss:4.2202 validation loss:0.2312
Updating learning rate to 9.618930888348809e-05
Updating learning rate to 9.618930888348809e-05
(34273, 1)
(34273, 1) True
train 34273
vs, vt 0.2294910013089689 0.24094129630019157
need align? ->  False 0.24094129630019157
2023-09-07 19:25:27,503 - epoch:9, training loss:4.0950 validation loss:0.2295
Updating learning rate to 9.329517890444304e-05
Updating learning rate to 9.329517890444304e-05
(34273, 1)
(34273, 1) True
train 34273
vs, vt 0.22940267932214095 0.23977312970948353
need align? ->  False 0.23977312970948353
2023-09-07 19:30:12,489 - epoch:10, training loss:4.0014 validation loss:0.2294
Updating learning rate to 8.966025983270703e-05
Updating learning rate to 8.966025983270703e-05
(34273, 1)
(34273, 1) True
train 34273
vs, vt 0.2269980175357856 0.23833118858380933
need align? ->  False 0.23833118858380933
2023-09-07 19:34:57,958 - epoch:11, training loss:3.9381 validation loss:0.2270
Updating learning rate to 8.534674614138748e-05
Updating learning rate to 8.534674614138748e-05
(34273, 1)
(34273, 1) True
train 34273
vs, vt 0.22623879422716212 0.23589803464710712
need align? ->  False 0.23589803464710712
2023-09-07 19:39:40,694 - epoch:12, training loss:3.8989 validation loss:0.2262
Updating learning rate to 8.042844324567477e-05
Updating learning rate to 8.042844324567477e-05
(34273, 1)
(34273, 1) True
train 34273
vs, vt 0.22641203755491904 0.2357073077994786
need align? ->  False 0.2357073077994786
2023-09-07 19:44:22,168 - epoch:13, training loss:3.8726 validation loss:0.2264
Updating learning rate to 7.498950467172574e-05
Updating learning rate to 7.498950467172574e-05
(34273, 1)
(34273, 1) True
train 34273
vs, vt 0.22694975606511147 0.23538928809628057
need align? ->  False 0.23538928809628057
2023-09-07 19:49:05,095 - epoch:14, training loss:3.8600 validation loss:0.2269
Updating learning rate to 6.912299216649929e-05
Updating learning rate to 6.912299216649929e-05
(34273, 1)
(34273, 1) True
train 34273
vs, vt 0.22522862743209587 0.23346714093611481
need align? ->  False 0.23346714093611481
2023-09-07 19:53:48,613 - epoch:15, training loss:3.8485 validation loss:0.2252
Updating learning rate to 6.292928338546441e-05
Updating learning rate to 6.292928338546441e-05
(34273, 1)
(34273, 1) True
train 34273
vs, vt 0.22522340503552657 0.23367234627098848
need align? ->  False 0.23346714093611481
2023-09-07 19:58:32,098 - epoch:16, training loss:3.8421 validation loss:0.2252
Updating learning rate to 5.651435440308513e-05
Updating learning rate to 5.651435440308513e-05
(34273, 1)
(34273, 1) True
train 34273
vs, vt 0.2240661969513036 0.2325578507747543
need align? ->  False 0.2325578507747543
2023-09-07 20:03:16,706 - epoch:17, training loss:3.8334 validation loss:0.2241
Updating learning rate to 4.9987966432804234e-05
Updating learning rate to 4.9987966432804234e-05
(34273, 1)
(34273, 1) True
train 34273
vs, vt 0.22526406844177943 0.23173138384152664
need align? ->  False 0.23173138384152664
2023-09-07 20:08:00,790 - epoch:18, training loss:3.6874 validation loss:0.2253
Updating learning rate to 4.346178778224986e-05
Updating learning rate to 4.346178778224986e-05
(34273, 1)
(34273, 1) True
train 34273
vs, vt 0.22367703826742225 0.23092928135328078
need align? ->  False 0.23092928135328078
2023-09-07 20:12:44,993 - epoch:19, training loss:4.0894 validation loss:0.2237
Updating learning rate to 3.704748317753153e-05
Updating learning rate to 3.704748317753153e-05
(34273, 1)
(34273, 1) True
train 34273
vs, vt 0.22460633022396753 0.23030361997779836
need align? ->  False 0.23030361997779836
2023-09-07 20:17:25,408 - epoch:20, training loss:4.2214 validation loss:0.2246
Updating learning rate to 3.0854803148817166e-05
Updating learning rate to 3.0854803148817166e-05
(34273, 1)
(34273, 1) True
train 34273
vs, vt 0.22421486901768137 0.2309793598238337
need align? ->  False 0.23030361997779836
2023-09-07 20:22:03,041 - epoch:21, training loss:4.2036 validation loss:0.2242
Updating learning rate to 2.4989706168333394e-05
Updating learning rate to 2.4989706168333394e-05
(34273, 1)
(34273, 1) True
train 34273
vs, vt 0.22395659658764855 0.23013636245905014
need align? ->  False 0.23013636245905014
2023-09-07 20:26:42,253 - epoch:22, training loss:4.1736 validation loss:0.2240
Updating learning rate to 1.955254567152836e-05
Updating learning rate to 1.955254567152836e-05
(34273, 1)
(34273, 1) True
train 34273
vs, vt 0.22389606876152285 0.23036961916708545
need align? ->  False 0.23013636245905014
2023-09-07 20:31:21,868 - epoch:23, training loss:4.2738 validation loss:0.2239
Updating learning rate to 1.4636352981968055e-05
Updating learning rate to 1.4636352981968055e-05
(34273, 1)
(34273, 1) True
train 34273
vs, vt 0.22377302292525098 0.2300148146499074
need align? ->  False 0.2300148146499074
2023-09-07 20:36:02,026 - epoch:24, training loss:4.2563 validation loss:0.2238
Updating learning rate to 1.032524551959702e-05
Updating learning rate to 1.032524551959702e-05
(34273, 1)
(34273, 1) True
train 34273
vs, vt 0.22376438175861754 0.23010324412601046
need align? ->  False 0.2300148146499074
2023-09-07 20:40:40,178 - epoch:25, training loss:4.2794 validation loss:0.2238
Updating learning rate to 6.692987528361205e-06
Updating learning rate to 6.692987528361205e-06
(34273, 1)
(34273, 1) True
train 34273
vs, vt 0.22335975882963519 0.22987747935348013
need align? ->  False 0.22987747935348013
2023-09-07 20:45:18,622 - epoch:26, training loss:4.2711 validation loss:0.2234
Updating learning rate to 3.8017279495428126e-06
Updating learning rate to 3.8017279495428126e-06
(34273, 1)
(34273, 1) True
train 34273
vs, vt 0.22366679240059986 0.2298532086476851
need align? ->  False 0.2298532086476851
2023-09-07 20:49:56,595 - epoch:27, training loss:4.3219 validation loss:0.2237
Updating learning rate to 1.7009370361440373e-06
Updating learning rate to 1.7009370361440373e-06
(34273, 1)
(34273, 1) True
train 34273
vs, vt 0.22366738984926363 0.2298355009197519
need align? ->  False 0.2298355009197519
2023-09-07 20:54:37,213 - epoch:28, training loss:4.3186 validation loss:0.2237
Updating learning rate to 4.2655990314240746e-07
Updating learning rate to 4.2655990314240746e-07
(34273, 1)
(34273, 1) True
train 34273
vs, vt 0.22364478876416602 0.22982675395905972
need align? ->  False 0.22982675395905972
2023-09-07 20:59:17,479 - epoch:29, training loss:4.3193 validation loss:0.2236
Updating learning rate to 4.014966076743239e-10
Updating learning rate to 4.014966076743239e-10
dropout 0.05
dropout 0.05
fourier enhanced block used!
modes=32, index=[0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 12, 14, 15, 16, 17, 18, 19, 21, 22, 24, 25, 27, 29, 33, 34, 35, 36, 37, 39, 42, 43, 46]
fourier enhanced block used!
modes=32, index=[0, 3, 5, 9, 15, 16, 19, 25, 30, 33, 34, 46, 49, 53, 58, 63, 67, 69, 70, 73, 80, 82, 98, 99, 101, 103, 107, 109, 112, 114, 116, 117]
 fourier enhanced cross attention used!
modes_q=32, index_q=[3, 5, 6, 7, 8, 10, 11, 16, 18, 25, 28, 29, 31, 35, 41, 45, 46, 65, 66, 69, 72, 83, 84, 86, 93, 99, 104, 105, 106, 109, 114, 117]
modes_kv=32, index_kv=[0, 3, 5, 6, 7, 8, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 25, 26, 27, 28, 29, 33, 36, 38, 39, 40, 41, 42, 44, 47]
check exp/ECL-FEDformer2023-09-07-18:39:34.308280/0/0.2234_epoch_26.pkl  &  0.22982675395905972
2023-09-07 20:59:26,581 - [*] loss:2.2339
2023-09-07 20:59:26,596 - [*] phase 0, testing
2023-09-07 20:59:26,841 - T:192	MAE	1.032308	RMSE	2.233935	MAPE	597.333002
2023-09-07 20:59:26,841 - 192	mae	1.0323	
2023-09-07 20:59:26,841 - 192	rmse	2.2339	
2023-09-07 20:59:26,841 - 192	mape	597.3330	
2023-09-07 20:59:35,176 - [*] loss:2.2340
2023-09-07 20:59:35,192 - [*] phase 0, testing
2023-09-07 20:59:35,437 - T:192	MAE	1.032331	RMSE	2.234008	MAPE	597.346163
