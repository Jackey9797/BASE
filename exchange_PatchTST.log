2023-08-28 12:54:47,803 - logger name:exp/ECL-PatchTST2023-08-28-12:54:47.803221/ECL-PatchTST.log
2023-08-28 12:54:47,803 - params : {'loss': 'mse', 'conf': 'ECL-PatchTST', 'data_name': 'exchange_rate', 'iteration': 1, 'train': 1, 'load': True, 'build_graph': False, 'same_init': True, 'grad_norm': False, 'refiner_residual': 0, 'root_path': '', 'exp_path': 'exp/', 'val_test_mix': False, 'lr': 0.0001, 'lradj': 'TST', 'dropout': 0.2, 'fc_dropout': 0.2, 'head_dropout': 0.0, 'patch_len': 16, 'stride': 8, 'd_ff': 256, 'd_model': 128, 'n_heads': 16, 'seq_len': 336, 'pred_len': 96, 'noise_rate': 0.5, 'device': device(type='cuda', index=1), 'test_model_path': '/Disk/fhyega/code/BASE/exp/ECL-PatchTST2023-08-26-13:08:31.837686/0/best_model.pkl', 'idx': -1, 'aligner': 1, 'always_align': 1, 'refiner': 1, 'rec_block_num': 1, 'enhance': 1, 'enhance_type': 5, 'seed': 34, 'batch_size': 64, 'share_head': 0, 'add_noise': 1, 'jitter_sigma': 0.4, 'slope_rate': 0.01, 'slope_range': 0.2, 'alpha': 10.0, 'beta': 1.0, 'gamma': 0.15, 'feature_jittering': 1, 'rec_intra_feature': 0, 'rec_ori': 1, 'mid_dim': 128, 'test_en': 0, 'debugger': 0, 'summary': 0, 'omega': 1.0, 'theta': 1.5, 'mask_border': 1, 'sup_weight': 10.0, 'rec_length_ratio': 0.8, 'ref_dropout': 0.0, 'ref_block_num': 2, 'add_FFN': 0, 'add_residual': 0, 'rec_all': 0, 'e_layers': 3, '/* model related args*/': '//', 'model_name': 'PatchTST', 'label_len': 48, 'features': 'M', 'target': 'OT', 'graph_input': False, 'individual': False, 'd_layers': 1, 'factor': 1, 'des': 'Exp', 'padding_patch': 'end', 'revin': 1, 'affine': 0, 'subtract_last': 0, 'decomposition': 0, 'kernel_size': 25, 'output_attention': 0, 'embed_type': 0, 'activation': 'gelu', 'distil': 1, 'linear_output': 1, 'pct_start': 0.2, '/*train related args*/': '//', 'epoch': 30, '/*dataset related args*/': '//', 'save_data_path': 'data/ECL/', 'data_process': True, 'embed': 'timeF', 'freq': 'h', 'begin_phase': 0, 'end_phase': 1, 'phase_len': -1, 'val_ratio': 0.33, 'graph_size': 321, '/*strategy related args*/': '//', 'strategy': 'incremental', 'increase': False, 'detect': False, 'detect_strategy': 'feature', 'replay': False, 'replay_strategy': 'random', 'repaly_num_samples': 100, 'ewc': False, 'ewc_strategy': 'ewc', 'ewc_lambda': 0.0001, 'subgraph_train': False, 'num_hops': 2, 'logname': 'ECL-PatchTST', 'time': '2023-08-28-12:54:47.803221', 'path': 'exp/ECL-PatchTST2023-08-28-12:54:47.803221', 'num_workers': 4, 'start_train': 0, 'train_mode': 'pretrain', 'get_score': False, 'use_cm': True, 'logger': <Logger __main__ (INFO)>}
2023-08-28 12:54:47,803 - [*] phase 0 start training
0 7588
5311 760 1517 0.7 0.2 7588
train 4880
5311 760 1517 0.7 0.2 7588
val 665
5311 760 1517 0.7 0.2 7588
test 1422
2023-08-28 12:54:47,876 - [*] phase 0 Dataset load!
2023-08-28 12:54:48,910 - [*] phase 0 Training start
5311 760 1517 0.7 0.2 7588
train 4880
2023-08-28 12:55:15,707 - epoch:0, training loss:0.3380 validation loss:0.2052
5311 760 1517 0.7 0.2 7588
train 4880
vs, vt 0.20518018102104013 0.21202550117265095
Updating learning rate to 1.0458426533505524e-05
Updating learning rate to 1.0458426533505524e-05
5311 760 1517 0.7 0.2 7588
train 4880
vs, vt 0.15724573318253865 0.17679782516577028
need align? ->  False 0.17679782516577028
2023-08-28 12:56:22,863 - epoch:1, training loss:10.3379 validation loss:0.1572
Updating learning rate to 2.8095736413660108e-05
Updating learning rate to 2.8095736413660108e-05
5311 760 1517 0.7 0.2 7588
train 4880
vs, vt 0.14233560826290736 0.14999050782485443
need align? ->  False 0.14999050782485443
2023-08-28 12:57:20,755 - epoch:2, training loss:5.4766 validation loss:0.1423
Updating learning rate to 5.2165710052561655e-05
Updating learning rate to 5.2165710052561655e-05
5311 760 1517 0.7 0.2 7588
train 4880
vs, vt 0.1321305161850019 0.1333236298100515
need align? ->  False 0.1333236298100515
2023-08-28 12:58:18,373 - epoch:3, training loss:3.1163 validation loss:0.1321
Updating learning rate to 7.619109093311602e-05
Updating learning rate to 7.619109093311602e-05
5311 760 1517 0.7 0.2 7588
train 4880
vs, vt 0.13264954496513714 0.13109145618297838
need align? ->  True 0.13109145618297838
2023-08-28 12:59:16,378 - epoch:4, training loss:2.3389 validation loss:0.1326
Updating learning rate to 9.370662249880032e-05
Updating learning rate to 9.370662249880032e-05
5311 760 1517 0.7 0.2 7588
train 4880
vs, vt 0.1297833313318816 0.13124711980873888
need align? ->  False 0.13109145618297838
2023-08-28 13:00:17,783 - epoch:5, training loss:2.0221 validation loss:0.1298
Updating learning rate to 9.99999258368374e-05
Updating learning rate to 9.99999258368374e-05
5311 760 1517 0.7 0.2 7588
train 4880
vs, vt 0.1293843754313209 0.12610984153368257
need align? ->  True 0.12610984153368257
2023-08-28 13:01:11,607 - epoch:6, training loss:1.9058 validation loss:0.1294
Updating learning rate to 9.956093061825775e-05
Updating learning rate to 9.956093061825775e-05
5311 760 1517 0.7 0.2 7588
train 4880
vs, vt 0.1322181841189211 0.1257182081991976
need align? ->  True 0.1257182081991976
2023-08-28 13:02:12,936 - epoch:7, training loss:1.8117 validation loss:0.1322
Updating learning rate to 9.827393755796923e-05
Updating learning rate to 9.827393755796923e-05
5311 760 1517 0.7 0.2 7588
train 4880
vs, vt 0.12794563716108148 0.12997967343438754
need align? ->  True 0.1257182081991976
2023-08-28 13:03:13,263 - epoch:8, training loss:1.6913 validation loss:0.1279
Updating learning rate to 9.616096746405528e-05
Updating learning rate to 9.616096746405528e-05
5311 760 1517 0.7 0.2 7588
train 4880
vs, vt 0.1286547092551535 0.12519853257320143
need align? ->  True 0.12519853257320143
2023-08-28 13:04:10,205 - epoch:9, training loss:1.6518 validation loss:0.1287
Updating learning rate to 9.325817384064872e-05
Updating learning rate to 9.325817384064872e-05
5311 760 1517 0.7 0.2 7588
train 4880
vs, vt 0.12666502493348988 0.12734343111515045
need align? ->  True 0.12519853257320143
2023-08-28 13:05:11,341 - epoch:10, training loss:1.6088 validation loss:0.1267
Updating learning rate to 8.961522429145252e-05
Updating learning rate to 8.961522429145252e-05
5311 760 1517 0.7 0.2 7588
train 4880
vs, vt 0.12919774956323885 0.12606268443844534
need align? ->  True 0.12519853257320143
2023-08-28 13:06:04,931 - epoch:11, training loss:1.5468 validation loss:0.1292
Updating learning rate to 8.52944506932698e-05
Updating learning rate to 8.52944506932698e-05
5311 760 1517 0.7 0.2 7588
train 4880
vs, vt 0.12881890108639543 0.12709236348217184
need align? ->  True 0.12519853257320143
2023-08-28 13:07:06,079 - epoch:12, training loss:1.5163 validation loss:0.1288
Updating learning rate to 8.036978268031028e-05
Updating learning rate to 8.036978268031028e-05
5311 760 1517 0.7 0.2 7588
train 4880
vs, vt 0.1262812726199627 0.12711638754064386
need align? ->  True 0.12519853257320143
2023-08-28 13:08:01,627 - epoch:13, training loss:1.4819 validation loss:0.1263
Updating learning rate to 7.49254826876516e-05
Updating learning rate to 7.49254826876516e-05
5311 760 1517 0.7 0.2 7588
train 4880
vs, vt 0.13022577864202586 0.12616610865701328
need align? ->  True 0.12519853257320143
2023-08-28 13:09:01,611 - epoch:14, training loss:1.4506 validation loss:0.1302
Updating learning rate to 6.905470419761327e-05
Updating learning rate to 6.905470419761327e-05
5311 760 1517 0.7 0.2 7588
train 4880
vs, vt 0.12766135280782526 0.13018390773372215
need align? ->  True 0.12519853257320143
2023-08-28 13:09:57,305 - epoch:15, training loss:1.4425 validation loss:0.1277
Updating learning rate to 6.285789785784716e-05
Updating learning rate to 6.285789785784716e-05
5311 760 1517 0.7 0.2 7588
train 4880
vs, vt 0.1261225352910432 0.12677018716931343
need align? ->  True 0.12519853257320143
2023-08-28 13:10:57,491 - epoch:16, training loss:1.4069 validation loss:0.1261
Updating learning rate to 5.644109274290595e-05
Updating learning rate to 5.644109274290595e-05
5311 760 1517 0.7 0.2 7588
train 4880
vs, vt 0.1251438520848751 0.12692077153108336
need align? ->  False 0.12519853257320143
2023-08-28 13:11:54,727 - epoch:17, training loss:1.3943 validation loss:0.1251
Updating learning rate to 4.991408216738078e-05
Updating learning rate to 4.991408216738078e-05
5311 760 1517 0.7 0.2 7588
train 4880
vs, vt 0.12453126467087051 0.12631747871637344
need align? ->  False 0.12519853257320143
2023-08-28 13:12:51,658 - epoch:18, training loss:1.3724 validation loss:0.1245
Updating learning rate to 4.3388545091848115e-05
Updating learning rate to 4.3388545091848115e-05
5311 760 1517 0.7 0.2 7588
train 4880
vs, vt 0.12627553431825203 0.1268743368035013
need align? ->  True 0.12519853257320143
2023-08-28 13:13:52,010 - epoch:19, training loss:1.3639 validation loss:0.1263
Updating learning rate to 3.6976135264890956e-05
Updating learning rate to 3.6976135264890956e-05
5311 760 1517 0.7 0.2 7588
train 4880
vs, vt 0.1250991252335635 0.12647801265120506
need align? ->  False 0.12519853257320143
2023-08-28 13:14:47,815 - epoch:20, training loss:1.3420 validation loss:0.1251
Updating learning rate to 3.0786570796504476e-05
Updating learning rate to 3.0786570796504476e-05
5311 760 1517 0.7 0.2 7588
train 4880
vs, vt 0.1253054765137759 0.12547478452324867
need align? ->  True 0.12519853257320143
2023-08-28 13:15:50,130 - epoch:21, training loss:1.3274 validation loss:0.1253
Updating learning rate to 2.4925756850814208e-05
Updating learning rate to 2.4925756850814208e-05
5311 760 1517 0.7 0.2 7588
train 4880
vs, vt 0.1251255991784009 0.12604280866005205
need align? ->  False 0.12519853257320143
2023-08-28 13:16:46,966 - epoch:22, training loss:1.3174 validation loss:0.1251
Updating learning rate to 1.9493973579355512e-05
Updating learning rate to 1.9493973579355512e-05
5311 760 1517 0.7 0.2 7588
train 4880
vs, vt 0.12464687871662053 0.12538280033252455
need align? ->  False 0.12519853257320143
2023-08-28 13:17:46,826 - epoch:23, training loss:1.3099 validation loss:0.1246
Updating learning rate to 1.4584160299877916e-05
Updating learning rate to 1.4584160299877916e-05
5311 760 1517 0.7 0.2 7588
train 4880
vs, vt 0.124900049445304 0.12578679688952185
need align? ->  False 0.12519853257320143
2023-08-28 13:18:43,608 - epoch:24, training loss:1.3032 validation loss:0.1249
Updating learning rate to 1.0280325278850672e-05
Updating learning rate to 1.0280325278850672e-05
5311 760 1517 0.7 0.2 7588
train 4880
vs, vt 0.1249840994450179 0.12496344982223077
need align? ->  True 0.12496344982223077
2023-08-28 13:19:41,405 - epoch:25, training loss:1.3027 validation loss:0.1250
Updating learning rate to 6.65610832673205e-06
Updating learning rate to 6.65610832673205e-06
5311 760 1517 0.7 0.2 7588
train 4880
vs, vt 0.12586954066699202 0.12541676244952463
need align? ->  True 0.12496344982223077
2023-08-28 13:20:39,187 - epoch:26, training loss:1.3599 validation loss:0.1259
Updating learning rate to 3.7735208003955953e-06
Updating learning rate to 3.7735208003955953e-06
5311 760 1517 0.7 0.2 7588
train 4880
vs, vt 0.12621227719567038 0.12505868145010687
need align? ->  True 0.12496344982223077
2023-08-28 13:21:41,841 - epoch:27, training loss:1.3467 validation loss:0.1262
Updating learning rate to 1.6818845716211614e-06
Updating learning rate to 1.6818845716211614e-06
5311 760 1517 0.7 0.2 7588
train 4880
vs, vt 0.12635722654786977 0.12519833208485084
need align? ->  True 0.12496344982223077
2023-08-28 13:22:38,895 - epoch:28, training loss:1.3448 validation loss:0.1264
Updating learning rate to 4.1698811619419244e-07
Updating learning rate to 4.1698811619419244e-07
5311 760 1517 0.7 0.2 7588
train 4880
vs, vt 0.12625222416086632 0.12507713958621025
need align? ->  True 0.12496344982223077
2023-08-28 13:23:39,364 - epoch:29, training loss:1.3449 validation loss:0.1263
Updating learning rate to 4.741631626033113e-10
Updating learning rate to 4.741631626033113e-10
check exp/ECL-PatchTST2023-08-28-12:54:47.803221/0/0.1245_epoch_18.pkl  &  0.12496344982223077
2023-08-28 13:23:47,336 - [*] loss:0.0891
2023-08-28 13:23:47,338 - [*] phase 0, testing
2023-08-28 13:23:47,360 - T:96	MAE	0.205407	RMSE	0.087322	MAPE	122.204781
2023-08-28 13:23:47,361 - 96	mae	0.2054	
2023-08-28 13:23:47,361 - 96	rmse	0.0873	
2023-08-28 13:23:47,362 - 96	mape	122.2048	
2023-08-28 13:23:50,752 - [*] loss:0.0893
2023-08-28 13:23:50,754 - [*] phase 0, testing
2023-08-28 13:23:50,775 - T:96	MAE	0.205804	RMSE	0.087523	MAPE	122.222638
2023-08-28 13:23:57,240 - [*] loss:0.0862
2023-08-28 13:23:57,242 - [*] phase 0, testing
2023-08-28 13:23:57,266 - T:96	MAE	0.203012	RMSE	0.084586	MAPE	121.651006
2023-08-28 13:23:59,994 - [*] loss:0.0896
2023-08-28 13:23:59,996 - [*] phase 0, testing
2023-08-28 13:24:00,019 - T:96	MAE	0.207574	RMSE	0.087857	MAPE	123.611104
2023-08-28 13:24:00,019 - 96	mae	0.2076	
2023-08-28 13:24:00,019 - 96	rmse	0.0879	
2023-08-28 13:24:00,019 - 96	mape	123.6111	
2023-08-28 13:24:02,192 - logger name:exp/ECL-PatchTST2023-08-28-13:24:02.191586/ECL-PatchTST.log
2023-08-28 13:24:02,192 - params : {'loss': 'mse', 'conf': 'ECL-PatchTST', 'data_name': 'exchange_rate', 'iteration': 1, 'train': 1, 'load': True, 'build_graph': False, 'same_init': True, 'grad_norm': False, 'refiner_residual': 0, 'root_path': '', 'exp_path': 'exp/', 'val_test_mix': False, 'lr': 0.0001, 'lradj': 'TST', 'dropout': 0.2, 'fc_dropout': 0.2, 'head_dropout': 0.0, 'patch_len': 16, 'stride': 8, 'd_ff': 256, 'd_model': 128, 'n_heads': 16, 'seq_len': 336, 'pred_len': 192, 'noise_rate': 0.5, 'device': device(type='cuda', index=1), 'test_model_path': '/Disk/fhyega/code/BASE/exp/ECL-PatchTST2023-08-26-13:08:31.837686/0/best_model.pkl', 'idx': -1, 'aligner': 1, 'always_align': 1, 'refiner': 1, 'rec_block_num': 1, 'enhance': 1, 'enhance_type': 5, 'seed': 34, 'batch_size': 64, 'share_head': 0, 'add_noise': 1, 'jitter_sigma': 0.4, 'slope_rate': 0.01, 'slope_range': 0.2, 'alpha': 10.0, 'beta': 1.0, 'gamma': 0.15, 'feature_jittering': 1, 'rec_intra_feature': 0, 'rec_ori': 1, 'mid_dim': 128, 'test_en': 0, 'debugger': 0, 'summary': 0, 'omega': 1.0, 'theta': 1.5, 'mask_border': 1, 'sup_weight': 10.0, 'rec_length_ratio': 0.8, 'ref_dropout': 0.0, 'ref_block_num': 2, 'add_FFN': 0, 'add_residual': 0, 'rec_all': 0, 'e_layers': 3, '/* model related args*/': '//', 'model_name': 'PatchTST', 'label_len': 48, 'features': 'M', 'target': 'OT', 'graph_input': False, 'individual': False, 'd_layers': 1, 'factor': 1, 'des': 'Exp', 'padding_patch': 'end', 'revin': 1, 'affine': 0, 'subtract_last': 0, 'decomposition': 0, 'kernel_size': 25, 'output_attention': 0, 'embed_type': 0, 'activation': 'gelu', 'distil': 1, 'linear_output': 1, 'pct_start': 0.2, '/*train related args*/': '//', 'epoch': 30, '/*dataset related args*/': '//', 'save_data_path': 'data/ECL/', 'data_process': True, 'embed': 'timeF', 'freq': 'h', 'begin_phase': 0, 'end_phase': 1, 'phase_len': -1, 'val_ratio': 0.33, 'graph_size': 321, '/*strategy related args*/': '//', 'strategy': 'incremental', 'increase': False, 'detect': False, 'detect_strategy': 'feature', 'replay': False, 'replay_strategy': 'random', 'repaly_num_samples': 100, 'ewc': False, 'ewc_strategy': 'ewc', 'ewc_lambda': 0.0001, 'subgraph_train': False, 'num_hops': 2, 'logname': 'ECL-PatchTST', 'time': '2023-08-28-13:24:02.191586', 'path': 'exp/ECL-PatchTST2023-08-28-13:24:02.191586', 'num_workers': 4, 'start_train': 0, 'train_mode': 'pretrain', 'get_score': False, 'use_cm': True, 'logger': <Logger __main__ (INFO)>}
2023-08-28 13:24:02,193 - [*] phase 0 start training
0 7588
5311 760 1517 0.7 0.2 7588
train 4784
5311 760 1517 0.7 0.2 7588
val 569
5311 760 1517 0.7 0.2 7588
test 1326
2023-08-28 13:24:02,274 - [*] phase 0 Dataset load!
2023-08-28 13:24:03,396 - [*] phase 0 Training start
5311 760 1517 0.7 0.2 7588
train 4784
2023-08-28 13:24:30,414 - epoch:0, training loss:0.4555 validation loss:0.3284
5311 760 1517 0.7 0.2 7588
train 4784
vs, vt 0.3284056915177239 0.33906040920151603
Updating learning rate to 1.0459176172485389e-05
Updating learning rate to 1.0459176172485389e-05
5311 760 1517 0.7 0.2 7588
train 4784
vs, vt 0.2604711262716187 0.288588526348273
need align? ->  False 0.288588526348273
2023-08-28 13:25:39,679 - epoch:1, training loss:10.7293 validation loss:0.2605
Updating learning rate to 2.8098331488808097e-05
Updating learning rate to 2.8098331488808097e-05
5311 760 1517 0.7 0.2 7588
train 4784
vs, vt 0.24583560228347778 0.2521965619590547
need align? ->  False 0.2521965619590547
2023-08-28 13:26:32,869 - epoch:2, training loss:5.7392 validation loss:0.2458
Updating learning rate to 5.217019879388642e-05
Updating learning rate to 5.217019879388642e-05
5311 760 1517 0.7 0.2 7588
train 4784
vs, vt 0.22470949672990376 0.23087604095538458
need align? ->  False 0.23087604095538458
2023-08-28 13:27:33,393 - epoch:3, training loss:3.4229 validation loss:0.2247
Updating learning rate to 7.619626009921239e-05
Updating learning rate to 7.619626009921239e-05
5311 760 1517 0.7 0.2 7588
train 4784
vs, vt 0.22151677641603681 0.22261696971125072
need align? ->  False 0.22261696971125072
2023-08-28 13:28:27,371 - epoch:4, training loss:2.7043 validation loss:0.2215
Updating learning rate to 9.37103252922012e-05
Updating learning rate to 9.37103252922012e-05
5311 760 1517 0.7 0.2 7588
train 4784
vs, vt 0.22036778181791306 0.22264680597517225
need align? ->  False 0.22261696971125072
2023-08-28 13:29:26,676 - epoch:5, training loss:2.4412 validation loss:0.2204
Updating learning rate to 9.999992177384562e-05
Updating learning rate to 9.999992177384562e-05
5311 760 1517 0.7 0.2 7588
train 4784
vs, vt 0.21699920462237465 0.22691880994372898
need align? ->  False 0.22261696971125072
2023-08-28 13:30:21,820 - epoch:6, training loss:2.3455 validation loss:0.2170
Updating learning rate to 9.956062278945235e-05
Updating learning rate to 9.956062278945235e-05
5311 760 1517 0.7 0.2 7588
train 4784
vs, vt 0.22301406744453642 0.22326089358992046
need align? ->  True 0.22261696971125072
2023-08-28 13:31:20,586 - epoch:7, training loss:2.2531 validation loss:0.2230
Updating learning rate to 9.827333123038641e-05
Updating learning rate to 9.827333123038641e-05
5311 760 1517 0.7 0.2 7588
train 4784
vs, vt 0.21393374767568377 0.227453523212009
need align? ->  False 0.22261696971125072
2023-08-28 13:32:16,125 - epoch:8, training loss:2.2172 validation loss:0.2139
Updating learning rate to 9.616007301212808e-05
Updating learning rate to 9.616007301212808e-05
5311 760 1517 0.7 0.2 7588
train 4784
vs, vt 0.21736027548710504 0.223452584611045
need align? ->  False 0.22261696971125072
2023-08-28 13:33:11,925 - epoch:9, training loss:2.1552 validation loss:0.2174
Updating learning rate to 9.325700656869763e-05
Updating learning rate to 9.325700656869763e-05
5311 760 1517 0.7 0.2 7588
train 4784
vs, vt 0.21507079982095295 0.23023415439658695
need align? ->  False 0.22261696971125072
2023-08-28 13:34:07,929 - epoch:10, training loss:2.1131 validation loss:0.2151
Updating learning rate to 8.961380417182421e-05
Updating learning rate to 8.961380417182421e-05
5311 760 1517 0.7 0.2 7588
train 4784
vs, vt 0.21313435915443632 0.2295203846361902
need align? ->  False 0.22261696971125072
2023-08-28 13:35:05,379 - epoch:11, training loss:2.0869 validation loss:0.2131
Updating learning rate to 8.529280202460489e-05
Updating learning rate to 8.529280202460489e-05
5311 760 1517 0.7 0.2 7588
train 4784
vs, vt 0.2119342080420918 0.23170492715305752
need align? ->  False 0.22261696971125072
2023-08-28 13:36:03,011 - epoch:12, training loss:2.0372 validation loss:0.2119
Updating learning rate to 8.036793367178669e-05
Updating learning rate to 8.036793367178669e-05
5311 760 1517 0.7 0.2 7588
train 4784
vs, vt 0.2117199409339163 0.22972141040696037
need align? ->  False 0.22261696971125072
2023-08-28 13:36:59,115 - epoch:13, training loss:1.9947 validation loss:0.2117
Updating learning rate to 7.492346497631781e-05
Updating learning rate to 7.492346497631781e-05
5311 760 1517 0.7 0.2 7588
train 4784
vs, vt 0.21462922046581903 0.23115449481540257
need align? ->  False 0.22261696971125072
2023-08-28 13:37:56,719 - epoch:14, training loss:1.9755 validation loss:0.2146
Updating learning rate to 6.905255230706963e-05
Updating learning rate to 6.905255230706963e-05
5311 760 1517 0.7 0.2 7588
train 4784
vs, vt 0.2115754195385509 0.2353766237696012
need align? ->  False 0.22261696971125072
2023-08-28 13:38:51,569 - epoch:15, training loss:1.9326 validation loss:0.2116
Updating learning rate to 6.285564860753749e-05
Updating learning rate to 6.285564860753749e-05
5311 760 1517 0.7 0.2 7588
train 4784
vs, vt 0.21394581513272393 0.23750113364722994
need align? ->  False 0.22261696971125072
2023-08-28 13:39:50,653 - epoch:16, training loss:1.9209 validation loss:0.2139
Updating learning rate to 5.643878461812666e-05
Updating learning rate to 5.643878461812666e-05
5311 760 1517 0.7 0.2 7588
train 4784
vs, vt 0.214049288796054 0.23390341384543312
need align? ->  False 0.22261696971125072
2023-08-28 13:40:48,890 - epoch:17, training loss:1.8972 validation loss:0.2140
Updating learning rate to 4.9911754660786766e-05
Updating learning rate to 4.9911754660786766e-05
5311 760 1517 0.7 0.2 7588
train 4784
vs, vt 0.21147163874573177 0.23241396082772148
need align? ->  False 0.22261696971125072
2023-08-28 13:41:44,096 - epoch:18, training loss:1.8816 validation loss:0.2115
Updating learning rate to 4.338623802772251e-05
Updating learning rate to 4.338623802772251e-05
5311 760 1517 0.7 0.2 7588
train 4784
vs, vt 0.21095365699794558 0.23158514085743162
need align? ->  False 0.22261696971125072
2023-08-28 13:42:43,655 - epoch:19, training loss:1.8696 validation loss:0.2110
Updating learning rate to 3.6973888117740604e-05
Updating learning rate to 3.6973888117740604e-05
5311 760 1517 0.7 0.2 7588
train 4784
vs, vt 0.21303340875440174 0.2299824497765965
need align? ->  False 0.22261696971125072
2023-08-28 13:43:36,172 - epoch:20, training loss:1.8561 validation loss:0.2130
Updating learning rate to 3.078442201564012e-05
Updating learning rate to 3.078442201564012e-05
5311 760 1517 0.7 0.2 7588
train 4784
vs, vt 0.213665338853995 0.23510744505458409
need align? ->  False 0.22261696971125072
2023-08-28 13:44:36,449 - epoch:21, training loss:1.8390 validation loss:0.2137
Updating learning rate to 2.49237432024722e-05
Updating learning rate to 2.49237432024722e-05
5311 760 1517 0.7 0.2 7588
train 4784
vs, vt 0.2101365683807267 0.233764025900099
need align? ->  False 0.22261696971125072
2023-08-28 13:45:32,128 - epoch:22, training loss:1.8277 validation loss:0.2101
Updating learning rate to 1.9492129517617293e-05
Updating learning rate to 1.9492129517617293e-05
5311 760 1517 0.7 0.2 7588
train 4784
vs, vt 0.2113219896952311 0.23329759968651664
need align? ->  False 0.22261696971125072
2023-08-28 13:46:32,501 - epoch:23, training loss:1.8161 validation loss:0.2113
Updating learning rate to 1.458251737715106e-05
Updating learning rate to 1.458251737715106e-05
5311 760 1517 0.7 0.2 7588
train 4784
vs, vt 0.21053578952948251 0.23291111406352785
need align? ->  False 0.22261696971125072
2023-08-28 13:47:36,906 - epoch:24, training loss:1.8094 validation loss:0.2105
Updating learning rate to 1.0278911605998568e-05
Updating learning rate to 1.0278911605998568e-05
5311 760 1517 0.7 0.2 7588
train 4784
vs, vt 0.21037796884775162 0.23362084064218733
need align? ->  False 0.22261696971125072
2023-08-28 13:48:34,443 - epoch:25, training loss:1.8014 validation loss:0.2104
Updating learning rate to 6.654948092089148e-06
Updating learning rate to 6.654948092089148e-06
5311 760 1517 0.7 0.2 7588
train 4784
vs, vt 0.21097470902734333 0.23404008977942997
need align? ->  False 0.22261696971125072
2023-08-28 13:49:35,818 - epoch:26, training loss:1.8038 validation loss:0.2110
Updating learning rate to 3.7726338558982892e-06
Updating learning rate to 3.7726338558982892e-06
5311 760 1517 0.7 0.2 7588
train 4784
vs, vt 0.21108686592843798 0.2343975173102485
need align? ->  False 0.22261696971125072
2023-08-28 13:50:33,416 - epoch:27, training loss:1.8026 validation loss:0.2111
Updating learning rate to 1.6812860931357137e-06
Updating learning rate to 1.6812860931357137e-06
5311 760 1517 0.7 0.2 7588
train 4784
vs, vt 0.2110999118950632 0.23374566187461218
need align? ->  False 0.22261696971125072
2023-08-28 13:51:27,268 - epoch:28, training loss:1.7980 validation loss:0.2111
Updating learning rate to 4.166883438534286e-07
Updating learning rate to 4.166883438534286e-07
5311 760 1517 0.7 0.2 7588
train 4784
vs, vt 0.211049970653322 0.2340839480360349
need align? ->  False 0.22261696971125072
2023-08-28 13:52:25,735 - epoch:29, training loss:1.7967 validation loss:0.2110
Updating learning rate to 4.782261543812988e-10
Updating learning rate to 4.782261543812988e-10
check exp/ECL-PatchTST2023-08-28-13:24:02.191586/0/0.2101_epoch_22.pkl  &  0.22261696971125072
2023-08-28 13:52:32,892 - [*] loss:0.1865
2023-08-28 13:52:32,895 - [*] phase 0, testing
2023-08-28 13:52:32,935 - T:192	MAE	0.307023	RMSE	0.186190	MAPE	191.942203
2023-08-28 13:52:32,936 - 192	mae	0.3070	
2023-08-28 13:52:32,936 - 192	rmse	0.1862	
2023-08-28 13:52:32,936 - 192	mape	191.9422	
2023-08-28 13:52:35,858 - [*] loss:0.1879
2023-08-28 13:52:35,861 - [*] phase 0, testing
2023-08-28 13:52:35,903 - T:192	MAE	0.308146	RMSE	0.187645	MAPE	192.759335
2023-08-28 13:52:42,427 - [*] loss:0.1812
2023-08-28 13:52:42,430 - [*] phase 0, testing
2023-08-28 13:52:42,471 - T:192	MAE	0.303246	RMSE	0.181083	MAPE	193.648553
2023-08-28 13:52:45,431 - [*] loss:0.1757
2023-08-28 13:52:45,434 - [*] phase 0, testing
2023-08-28 13:52:45,477 - T:192	MAE	0.298446	RMSE	0.175505	MAPE	191.184187
2023-08-28 13:52:45,478 - 192	mae	0.2984	
2023-08-28 13:52:45,478 - 192	rmse	0.1755	
2023-08-28 13:52:45,478 - 192	mape	191.1842	
2023-08-28 13:52:47,801 - logger name:exp/ECL-PatchTST2023-08-28-13:52:47.801165/ECL-PatchTST.log
2023-08-28 13:52:47,802 - params : {'loss': 'mse', 'conf': 'ECL-PatchTST', 'data_name': 'exchange_rate', 'iteration': 1, 'train': 1, 'load': True, 'build_graph': False, 'same_init': True, 'grad_norm': False, 'refiner_residual': 0, 'root_path': '', 'exp_path': 'exp/', 'val_test_mix': False, 'lr': 0.0001, 'lradj': 'TST', 'dropout': 0.2, 'fc_dropout': 0.2, 'head_dropout': 0.0, 'patch_len': 16, 'stride': 8, 'd_ff': 256, 'd_model': 128, 'n_heads': 16, 'seq_len': 336, 'pred_len': 336, 'noise_rate': 0.5, 'device': device(type='cuda', index=1), 'test_model_path': '/Disk/fhyega/code/BASE/exp/ECL-PatchTST2023-08-26-13:08:31.837686/0/best_model.pkl', 'idx': -1, 'aligner': 1, 'always_align': 1, 'refiner': 1, 'rec_block_num': 1, 'enhance': 1, 'enhance_type': 5, 'seed': 34, 'batch_size': 64, 'share_head': 0, 'add_noise': 1, 'jitter_sigma': 0.4, 'slope_rate': 0.01, 'slope_range': 0.2, 'alpha': 10.0, 'beta': 1.0, 'gamma': 0.15, 'feature_jittering': 1, 'rec_intra_feature': 0, 'rec_ori': 1, 'mid_dim': 128, 'test_en': 0, 'debugger': 0, 'summary': 0, 'omega': 1.0, 'theta': 1.5, 'mask_border': 1, 'sup_weight': 10.0, 'rec_length_ratio': 0.8, 'ref_dropout': 0.0, 'ref_block_num': 2, 'add_FFN': 0, 'add_residual': 0, 'rec_all': 0, 'e_layers': 3, '/* model related args*/': '//', 'model_name': 'PatchTST', 'label_len': 48, 'features': 'M', 'target': 'OT', 'graph_input': False, 'individual': False, 'd_layers': 1, 'factor': 1, 'des': 'Exp', 'padding_patch': 'end', 'revin': 1, 'affine': 0, 'subtract_last': 0, 'decomposition': 0, 'kernel_size': 25, 'output_attention': 0, 'embed_type': 0, 'activation': 'gelu', 'distil': 1, 'linear_output': 1, 'pct_start': 0.2, '/*train related args*/': '//', 'epoch': 30, '/*dataset related args*/': '//', 'save_data_path': 'data/ECL/', 'data_process': True, 'embed': 'timeF', 'freq': 'h', 'begin_phase': 0, 'end_phase': 1, 'phase_len': -1, 'val_ratio': 0.33, 'graph_size': 321, '/*strategy related args*/': '//', 'strategy': 'incremental', 'increase': False, 'detect': False, 'detect_strategy': 'feature', 'replay': False, 'replay_strategy': 'random', 'repaly_num_samples': 100, 'ewc': False, 'ewc_strategy': 'ewc', 'ewc_lambda': 0.0001, 'subgraph_train': False, 'num_hops': 2, 'logname': 'ECL-PatchTST', 'time': '2023-08-28-13:52:47.801165', 'path': 'exp/ECL-PatchTST2023-08-28-13:52:47.801165', 'num_workers': 4, 'start_train': 0, 'train_mode': 'pretrain', 'get_score': False, 'use_cm': True, 'logger': <Logger __main__ (INFO)>}
2023-08-28 13:52:47,802 - [*] phase 0 start training
0 7588
5311 760 1517 0.7 0.2 7588
train 4640
5311 760 1517 0.7 0.2 7588
val 425
5311 760 1517 0.7 0.2 7588
test 1182
2023-08-28 13:52:47,896 - [*] phase 0 Dataset load!
2023-08-28 13:52:48,997 - [*] phase 0 Training start
5311 760 1517 0.7 0.2 7588
train 4640
2023-08-28 13:53:12,728 - epoch:0, training loss:0.6279 validation loss:0.5251
5311 760 1517 0.7 0.2 7588
train 4640
vs, vt 0.5250790204320636 0.533048499907766
Updating learning rate to 1.0459967598502179e-05
Updating learning rate to 1.0459967598502179e-05
5311 760 1517 0.7 0.2 7588
train 4640
vs, vt 0.4307388131107603 0.4692000129393169
need align? ->  False 0.4692000129393169
2023-08-28 13:54:17,805 - epoch:1, training loss:11.2703 validation loss:0.4307
Updating learning rate to 2.810107117010466e-05
Updating learning rate to 2.810107117010466e-05
5311 760 1517 0.7 0.2 7588
train 4640
vs, vt 0.40970903635025024 0.4196007230452129
need align? ->  False 0.4196007230452129
2023-08-28 13:55:10,739 - epoch:2, training loss:6.3014 validation loss:0.4097
Updating learning rate to 5.217493748670853e-05
Updating learning rate to 5.217493748670853e-05
5311 760 1517 0.7 0.2 7588
train 4640
vs, vt 0.4013836405106953 0.40053347391741617
need align? ->  True 0.40053347391741617
2023-08-28 13:56:07,891 - epoch:3, training loss:4.1000 validation loss:0.4014
Updating learning rate to 7.620171669931654e-05
Updating learning rate to 7.620171669931654e-05
5311 760 1517 0.7 0.2 7588
train 4640
vs, vt 0.38135017241750446 0.40257106508527485
need align? ->  False 0.40053347391741617
2023-08-28 13:57:02,928 - epoch:4, training loss:3.4607 validation loss:0.3814
Updating learning rate to 9.371423317418648e-05
Updating learning rate to 9.371423317418648e-05
5311 760 1517 0.7 0.2 7588
train 4640
vs, vt 0.37870539511953083 0.3895507731607982
need align? ->  False 0.3895507731607982
2023-08-28 13:57:56,202 - epoch:5, training loss:3.2362 validation loss:0.3787
Updating learning rate to 9.999991736758969e-05
Updating learning rate to 9.999991736758969e-05
5311 760 1517 0.7 0.2 7588
train 4640
vs, vt 0.364246455686433 0.40267875364848543
need align? ->  False 0.3895507731607982
2023-08-28 13:58:52,406 - epoch:6, training loss:3.2231 validation loss:0.3642
Updating learning rate to 9.956029774253698e-05
Updating learning rate to 9.956029774253698e-05
5311 760 1517 0.7 0.2 7588
train 4640
vs, vt 0.3699087308985846 0.4016255906649998
need align? ->  False 0.3895507731607982
2023-08-28 13:59:50,132 - epoch:7, training loss:3.1149 validation loss:0.3699
Updating learning rate to 9.827269110445449e-05
Updating learning rate to 9.827269110445449e-05
5311 760 1517 0.7 0.2 7588
train 4640
vs, vt 0.364937356540135 0.4009434516940798
need align? ->  False 0.3895507731607982
2023-08-28 14:00:39,699 - epoch:8, training loss:2.9978 validation loss:0.3649
Updating learning rate to 9.615912875991176e-05
Updating learning rate to 9.615912875991176e-05
5311 760 1517 0.7 0.2 7588
train 4640
vs, vt 0.3720512475286211 0.4079592823982239
need align? ->  False 0.3895507731607982
2023-08-28 14:01:30,901 - epoch:9, training loss:2.9414 validation loss:0.3721
Updating learning rate to 9.32557743466141e-05
Updating learning rate to 9.32557743466141e-05
5311 760 1517 0.7 0.2 7588
train 4640
vs, vt 0.3781448666538511 0.4177899786404201
need align? ->  False 0.3895507731607982
2023-08-28 14:02:26,092 - epoch:10, training loss:2.8779 validation loss:0.3781
Updating learning rate to 8.961230506353499e-05
Updating learning rate to 8.961230506353499e-05
5311 760 1517 0.7 0.2 7588
train 4640
vs, vt 0.36794406175613403 0.4080961580787386
need align? ->  False 0.3895507731607982
2023-08-28 14:03:18,036 - epoch:11, training loss:2.8015 validation loss:0.3679
Updating learning rate to 8.529106168026842e-05
Updating learning rate to 8.529106168026842e-05
5311 760 1517 0.7 0.2 7588
train 4640
vs, vt 0.3683699369430542 0.39799108249800547
need align? ->  False 0.3895507731607982
2023-08-28 14:04:10,523 - epoch:12, training loss:2.7808 validation loss:0.3684
Updating learning rate to 8.03659818691771e-05
Updating learning rate to 8.03659818691771e-05
5311 760 1517 0.7 0.2 7588
train 4640
vs, vt 0.38147043543202536 0.4061451383999416
need align? ->  False 0.3895507731607982
2023-08-28 14:05:02,410 - epoch:13, training loss:2.7318 validation loss:0.3815
Updating learning rate to 7.49213351113189e-05
Updating learning rate to 7.49213351113189e-05
5311 760 1517 0.7 0.2 7588
train 4640
vs, vt 0.3685245173318045 0.4211470569883074
need align? ->  False 0.3895507731607982
2023-08-28 14:05:57,490 - epoch:14, training loss:2.6980 validation loss:0.3685
Updating learning rate to 6.905028082226201e-05
Updating learning rate to 6.905028082226201e-05
5311 760 1517 0.7 0.2 7588
train 4640
vs, vt 0.37108147357191357 0.4115001474108015
need align? ->  False 0.3895507731607982
2023-08-28 14:06:49,009 - epoch:15, training loss:2.6700 validation loss:0.3711
Updating learning rate to 6.2853274368656e-05
Updating learning rate to 6.2853274368656e-05
5311 760 1517 0.7 0.2 7588
train 4640
vs, vt 0.372065116252218 0.4007010779210499
need align? ->  False 0.3895507731607982
2023-08-28 14:07:42,747 - epoch:16, training loss:2.6265 validation loss:0.3721
Updating learning rate to 5.643634824905683e-05
Updating learning rate to 5.643634824905683e-05
5311 760 1517 0.7 0.2 7588
train 4640
vs, vt 0.37710247933864594 0.4046513906547001
need align? ->  False 0.3895507731607982
2023-08-28 14:08:36,886 - epoch:17, training loss:2.6054 validation loss:0.3771
Updating learning rate to 4.9909297848478885e-05
Updating learning rate to 4.9909297848478885e-05
5311 760 1517 0.7 0.2 7588
train 4640
vs, vt 0.37623085507324766 0.41162379937512533
need align? ->  False 0.3895507731607982
2023-08-28 14:09:34,732 - epoch:18, training loss:2.5764 validation loss:0.3762
Updating learning rate to 4.338380280891632e-05
Updating learning rate to 4.338380280891632e-05
5311 760 1517 0.7 0.2 7588
train 4640
vs, vt 0.3803933284112385 0.4056990146636963
need align? ->  False 0.3895507731607982
2023-08-28 14:10:26,461 - epoch:19, training loss:2.5690 validation loss:0.3804
Updating learning rate to 3.697151615970502e-05
Updating learning rate to 3.697151615970502e-05
5311 760 1517 0.7 0.2 7588
train 4640
vs, vt 0.3844611176422664 0.40642350912094116
need align? ->  False 0.3895507731607982
2023-08-28 14:11:19,463 - epoch:20, training loss:2.5394 validation loss:0.3845
Updating learning rate to 3.078215390323479e-05
Updating learning rate to 3.078215390323479e-05
5311 760 1517 0.7 0.2 7588
train 4640
vs, vt 0.3764581275837762 0.410631992987224
need align? ->  False 0.3895507731607982
2023-08-28 14:12:12,745 - epoch:21, training loss:2.5244 validation loss:0.3765
Updating learning rate to 2.492161774372921e-05
Updating learning rate to 2.492161774372921e-05
5311 760 1517 0.7 0.2 7588
train 4640
vs, vt 0.37986981868743896 0.407611363700458
need align? ->  False 0.3895507731607982
2023-08-28 14:13:07,617 - epoch:22, training loss:2.5160 validation loss:0.3799
Updating learning rate to 1.9490183079725027e-05
Updating learning rate to 1.9490183079725027e-05
5311 760 1517 0.7 0.2 7588
train 4640
vs, vt 0.3746641682726996 0.41294591554573606
need align? ->  False 0.3895507731607982
2023-08-28 14:13:58,981 - epoch:23, training loss:2.5018 validation loss:0.3747
Updating learning rate to 1.4580783264201512e-05
Updating learning rate to 1.4580783264201512e-05
5311 760 1517 0.7 0.2 7588
train 4640
vs, vt 0.37944512920720236 0.40925061064107077
need align? ->  False 0.3895507731607982
2023-08-28 14:14:51,396 - epoch:24, training loss:2.4994 validation loss:0.3794
Updating learning rate to 1.0277419489145082e-05
Updating learning rate to 1.0277419489145082e-05
5311 760 1517 0.7 0.2 7588
train 4640
vs, vt 0.3764923555510385 0.41324507764407564
need align? ->  False 0.3895507731607982
2023-08-28 14:15:46,488 - epoch:25, training loss:2.4920 validation loss:0.3765
Updating learning rate to 6.653723501864783e-06
Updating learning rate to 6.653723501864783e-06
5311 760 1517 0.7 0.2 7588
train 4640
vs, vt 0.37733231484889984 0.410922035574913
need align? ->  False 0.3895507731607982
2023-08-28 14:16:39,748 - epoch:26, training loss:2.4908 validation loss:0.3773
Updating learning rate to 3.771697745381306e-06
Updating learning rate to 3.771697745381306e-06
5311 760 1517 0.7 0.2 7588
train 4640
vs, vt 0.3770713082381657 0.4109178142888205
need align? ->  False 0.3895507731607982
2023-08-28 14:17:31,765 - epoch:27, training loss:2.4781 validation loss:0.3771
Updating learning rate to 1.6806544794366014e-06
Updating learning rate to 1.6806544794366014e-06
5311 760 1517 0.7 0.2 7588
train 4640
vs, vt 0.3781306530748095 0.4119873174599239
need align? ->  False 0.3895507731607982
2023-08-28 14:18:27,241 - epoch:28, training loss:2.4787 validation loss:0.3781
Updating learning rate to 4.163720340576901e-07
Updating learning rate to 4.163720340576901e-07
5311 760 1517 0.7 0.2 7588
train 4640
vs, vt 0.3775022711072649 0.4106238867555346
need align? ->  False 0.3895507731607982
2023-08-28 14:19:23,097 - epoch:29, training loss:2.4841 validation loss:0.3775
Updating learning rate to 4.826324103244405e-10
Updating learning rate to 4.826324103244405e-10
check exp/ECL-PatchTST2023-08-28-13:52:47.801165/0/0.3642_epoch_6.pkl  &  0.3895507731607982
2023-08-28 14:19:29,047 - [*] loss:0.3466
2023-08-28 14:19:29,052 - [*] phase 0, testing
2023-08-28 14:19:29,131 - T:336	MAE	0.430286	RMSE	0.348644	MAPE	308.677506
2023-08-28 14:19:29,131 - 336	mae	0.4303	
2023-08-28 14:19:29,131 - 336	rmse	0.3486	
2023-08-28 14:19:29,131 - 336	mape	308.6775	
2023-08-28 14:19:32,360 - [*] loss:0.3518
2023-08-28 14:19:32,365 - [*] phase 0, testing
2023-08-28 14:19:32,444 - T:336	MAE	0.434289	RMSE	0.354118	MAPE	311.451745
2023-08-28 14:19:38,511 - [*] loss:0.3210
2023-08-28 14:19:38,516 - [*] phase 0, testing
2023-08-28 14:19:38,594 - T:336	MAE	0.410186	RMSE	0.322726	MAPE	278.811979
2023-08-28 14:19:41,595 - [*] loss:0.3362
2023-08-28 14:19:41,601 - [*] phase 0, testing
2023-08-28 14:19:41,681 - T:336	MAE	0.420483	RMSE	0.338643	MAPE	291.819096
2023-08-28 14:19:41,681 - 336	mae	0.4205	
2023-08-28 14:19:41,681 - 336	rmse	0.3386	
2023-08-28 14:19:41,681 - 336	mape	291.8191	
2023-08-28 14:19:43,819 - logger name:exp/ECL-PatchTST2023-08-28-14:19:43.818500/ECL-PatchTST.log
2023-08-28 14:19:43,820 - params : {'loss': 'mse', 'conf': 'ECL-PatchTST', 'data_name': 'exchange_rate', 'iteration': 1, 'train': 1, 'load': True, 'build_graph': False, 'same_init': True, 'grad_norm': False, 'refiner_residual': 0, 'root_path': '', 'exp_path': 'exp/', 'val_test_mix': False, 'lr': 0.0001, 'lradj': 'TST', 'dropout': 0.2, 'fc_dropout': 0.2, 'head_dropout': 0.0, 'patch_len': 16, 'stride': 8, 'd_ff': 256, 'd_model': 128, 'n_heads': 16, 'seq_len': 336, 'pred_len': 720, 'noise_rate': 0.5, 'device': device(type='cuda', index=1), 'test_model_path': '/Disk/fhyega/code/BASE/exp/ECL-PatchTST2023-08-26-13:08:31.837686/0/best_model.pkl', 'idx': -1, 'aligner': 1, 'always_align': 1, 'refiner': 1, 'rec_block_num': 1, 'enhance': 1, 'enhance_type': 5, 'seed': 34, 'batch_size': 64, 'share_head': 0, 'add_noise': 1, 'jitter_sigma': 0.4, 'slope_rate': 0.01, 'slope_range': 0.2, 'alpha': 10.0, 'beta': 1.0, 'gamma': 0.15, 'feature_jittering': 1, 'rec_intra_feature': 0, 'rec_ori': 1, 'mid_dim': 128, 'test_en': 0, 'debugger': 0, 'summary': 0, 'omega': 1.0, 'theta': 1.5, 'mask_border': 1, 'sup_weight': 10.0, 'rec_length_ratio': 0.8, 'ref_dropout': 0.0, 'ref_block_num': 2, 'add_FFN': 0, 'add_residual': 0, 'rec_all': 0, 'e_layers': 3, '/* model related args*/': '//', 'model_name': 'PatchTST', 'label_len': 48, 'features': 'M', 'target': 'OT', 'graph_input': False, 'individual': False, 'd_layers': 1, 'factor': 1, 'des': 'Exp', 'padding_patch': 'end', 'revin': 1, 'affine': 0, 'subtract_last': 0, 'decomposition': 0, 'kernel_size': 25, 'output_attention': 0, 'embed_type': 0, 'activation': 'gelu', 'distil': 1, 'linear_output': 1, 'pct_start': 0.2, '/*train related args*/': '//', 'epoch': 30, '/*dataset related args*/': '//', 'save_data_path': 'data/ECL/', 'data_process': True, 'embed': 'timeF', 'freq': 'h', 'begin_phase': 0, 'end_phase': 1, 'phase_len': -1, 'val_ratio': 0.33, 'graph_size': 321, '/*strategy related args*/': '//', 'strategy': 'incremental', 'increase': False, 'detect': False, 'detect_strategy': 'feature', 'replay': False, 'replay_strategy': 'random', 'repaly_num_samples': 100, 'ewc': False, 'ewc_strategy': 'ewc', 'ewc_lambda': 0.0001, 'subgraph_train': False, 'num_hops': 2, 'logname': 'ECL-PatchTST', 'time': '2023-08-28-14:19:43.818500', 'path': 'exp/ECL-PatchTST2023-08-28-14:19:43.818500', 'num_workers': 4, 'start_train': 0, 'train_mode': 'pretrain', 'get_score': False, 'use_cm': True, 'logger': <Logger __main__ (INFO)>}
2023-08-28 14:19:43,820 - [*] phase 0 start training
0 7588
5311 760 1517 0.7 0.2 7588
train 4256
5311 760 1517 0.7 0.2 7588
val 41
5311 760 1517 0.7 0.2 7588
test 798
2023-08-28 14:19:43,903 - [*] phase 0 Dataset load!
2023-08-28 14:19:44,963 - [*] phase 0 Training start
5311 760 1517 0.7 0.2 7588
train 4256
2023-08-28 14:20:03,269 - epoch:0, training loss:1.0055 validation loss:1.2464
5311 760 1517 0.7 0.2 7588
train 4256
vs, vt 1.2463809251785278 1.2306686639785767
Updating learning rate to 1.0462630726707457e-05
Updating learning rate to 1.0462630726707457e-05
5311 760 1517 0.7 0.2 7588
train 4256
vs, vt 1.5856599807739258 1.3702223300933838
need align? ->  True 1.2306686639785767
2023-08-28 14:20:57,208 - epoch:1, training loss:12.5896 validation loss:1.5857
Updating learning rate to 2.81102897439222e-05
Updating learning rate to 2.81102897439222e-05
5311 760 1517 0.7 0.2 7588
train 4256
vs, vt 1.5555102825164795 1.671473503112793
need align? ->  True 1.2306686639785767
2023-08-28 14:21:46,833 - epoch:2, training loss:8.3653 validation loss:1.5555
Updating learning rate to 5.2190881075848036e-05
Updating learning rate to 5.2190881075848036e-05
5311 760 1517 0.7 0.2 7588
train 4256
vs, vt 1.401548981666565 1.5932981967926025
need align? ->  True 1.2306686639785767
2023-08-28 14:22:30,963 - epoch:3, training loss:7.3240 validation loss:1.4015
Updating learning rate to 7.622007266169379e-05
Updating learning rate to 7.622007266169379e-05
5311 760 1517 0.7 0.2 7588
train 4256
vs, vt 1.3922693729400635 1.400928020477295
need align? ->  True 1.2306686639785767
2023-08-28 14:23:17,544 - epoch:4, training loss:6.8874 validation loss:1.3923
Updating learning rate to 9.372737317309997e-05
Updating learning rate to 9.372737317309997e-05
5311 760 1517 0.7 0.2 7588
train 4256
vs, vt 1.3072993755340576 1.4705307483673096
need align? ->  True 1.2306686639785767
2023-08-28 14:24:06,377 - epoch:5, training loss:6.9042 validation loss:1.3073
Updating learning rate to 9.999990166060774e-05
Updating learning rate to 9.999990166060774e-05
5311 760 1517 0.7 0.2 7588
train 4256
vs, vt 1.3020439147949219 1.4425687789916992
need align? ->  True 1.2306686639785767
2023-08-28 14:24:51,362 - epoch:6, training loss:7.4001 validation loss:1.3020
Updating learning rate to 9.955920352476742e-05
Updating learning rate to 9.955920352476742e-05
5311 760 1517 0.7 0.2 7588
train 4256
vs, vt 1.3176883459091187 1.3795623779296875
need align? ->  True 1.2306686639785767
2023-08-28 14:25:37,669 - epoch:7, training loss:7.3163 validation loss:1.3177
Updating learning rate to 9.82705370982667e-05
Updating learning rate to 9.82705370982667e-05
5311 760 1517 0.7 0.2 7588
train 4256
vs, vt 1.2396804094314575 1.3416805267333984
need align? ->  True 1.2306686639785767
2023-08-28 14:26:28,160 - epoch:8, training loss:7.0112 validation loss:1.2397
Updating learning rate to 9.615595182094883e-05
Updating learning rate to 9.615595182094883e-05
5311 760 1517 0.7 0.2 7588
train 4256
vs, vt 1.270227074623108 1.2890150547027588
need align? ->  True 1.2306686639785767
2023-08-28 14:27:12,174 - epoch:9, training loss:6.9481 validation loss:1.2702
Updating learning rate to 9.325162883318251e-05
Updating learning rate to 9.325162883318251e-05
5311 760 1517 0.7 0.2 7588
train 4256
vs, vt 1.3307503461837769 1.2876802682876587
need align? ->  True 1.2306686639785767
2023-08-28 14:27:59,336 - epoch:10, training loss:6.9524 validation loss:1.3308
Updating learning rate to 8.960726190651892e-05
Updating learning rate to 8.960726190651892e-05
5311 760 1517 0.7 0.2 7588
train 4256
vs, vt 1.3031837940216064 1.3223206996917725
need align? ->  True 1.2306686639785767
2023-08-28 14:28:47,765 - epoch:11, training loss:6.9330 validation loss:1.3032
Updating learning rate to 8.528520716948261e-05
Updating learning rate to 8.528520716948261e-05
5311 760 1517 0.7 0.2 7588
train 4256
vs, vt 1.257011890411377 1.257060170173645
need align? ->  True 1.2306686639785767
2023-08-28 14:29:33,061 - epoch:12, training loss:6.8433 validation loss:1.2570
Updating learning rate to 8.035941617692428e-05
Updating learning rate to 8.035941617692428e-05
5311 760 1517 0.7 0.2 7588
train 4256
vs, vt 1.294093370437622 1.1821749210357666
need align? ->  True 1.1821749210357666
2023-08-28 14:30:20,871 - epoch:13, training loss:6.7095 validation loss:1.2941
Updating learning rate to 7.491417057841386e-05
Updating learning rate to 7.491417057841386e-05
5311 760 1517 0.7 0.2 7588
train 4256
vs, vt 1.3278831243515015 1.2261592149734497
need align? ->  True 1.1821749210357666
2023-08-28 14:31:09,767 - epoch:14, training loss:7.0821 validation loss:1.3279
Updating learning rate to 6.904264003584916e-05
Updating learning rate to 6.904264003584916e-05
5311 760 1517 0.7 0.2 7588
train 4256
vs, vt 1.4093605279922485 1.2733550071716309
need align? ->  True 1.1821749210357666
2023-08-28 14:31:55,790 - epoch:15, training loss:6.0903 validation loss:1.4094
Updating learning rate to 6.284528806470928e-05
Updating learning rate to 6.284528806470928e-05
5311 760 1517 0.7 0.2 7588
train 4256
