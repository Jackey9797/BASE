2023-09-02 01:38:18,257 - logger name:exp/ECL-PatchTST2023-09-02-01:38:18.256584/ECL-PatchTST.log
2023-09-02 01:38:18,257 - params : {'loss': 'huber', 'conf': 'ECL-PatchTST', 'data_name': 'ETTm1', 'iteration': 1, 'train': 1, 'mainrs': 0, 'abl': 1, 'load': True, 'build_graph': False, 'same_init': True, 'grad_norm': False, 'refiner_residual': 0, 'root_path': '', 'exp_path': 'exp/', 'val_test_mix': False, 'lr': 0.0001, 'lradj': 'TST', 'dropout': 0.2, 'fc_dropout': 0.2, 'head_dropout': 0.0, 'patch_len': 16, 'stride': 8, 'd_ff': 256, 'd_model': 128, 'n_heads': 16, 'seq_len': 336, 'pred_len': 96, 'noise_rate': 0.5, 'device': device(type='cuda', index=1), 'test_model_path': '/Disk/fhyega/code/BASE/exp/ECL-PatchTST2023-08-26-13:08:31.837686/0/best_model.pkl', 'idx': -1, 'aligner': 1, 'always_align': 1, 'refiner': 1, 'rec_block_num': 1, 'enhance': 1, 'enhance_type': 5, 'seed': 34, 'batch_size': 128, 'share_head': 0, 'add_noise': 1, 'add_norm': 0, 'jitter_sigma': 0.4, 'slope_rate': 0.01, 'slope_range': 0.2, 'alpha': 10.0, 'beta': 1.0, 'gamma': 0.15, 'feature_jittering': 1, 'rec_intra_feature': 0, 'rec_ori': 1, 'mid_dim': 128, 'test_en': 0, 'debugger': 0, 'summary': 0, 'omega': 1.0, 'theta': 1.5, 'mask_border': 1, 'sup_weight': 10.0, 'rec_length_ratio': 0.8, 'ref_dropout': 0.2, 'ref_block_num': 2, 'add_FFN': 1, 'add_residual': 0, 'rec_all': 0, 'e_layers': 3, 'early_break': 0, 'early_stop': 10, '/* model related args*/': '//', 'model_name': 'PatchTST', 'label_len': 48, 'features': 'M', 'target': 'OT', 'graph_input': False, 'individual': False, 'd_layers': 1, 'factor': 1, 'des': 'Exp', 'padding_patch': 'end', 'revin': 1, 'affine': 0, 'subtract_last': 0, 'decomposition': 0, 'kernel_size': 25, 'output_attention': 0, 'embed_type': 0, 'activation': 'gelu', 'distil': 1, 'linear_output': 1, 'pct_start': 0.2, '/*train related args*/': '//', 'epoch': 30, '/*dataset related args*/': '//', 'save_data_path': 'data/ECL/', 'data_process': True, 'embed': 'timeF', 'freq': 'h', 'begin_phase': 0, 'end_phase': 1, 'phase_len': -1, 'val_ratio': 0.33, 'graph_size': 321, '/*strategy related args*/': '//', 'strategy': 'incremental', 'increase': False, 'detect': False, 'detect_strategy': 'feature', 'replay': False, 'replay_strategy': 'random', 'repaly_num_samples': 100, 'ewc': False, 'ewc_strategy': 'ewc', 'ewc_lambda': 0.0001, 'subgraph_train': False, 'num_hops': 2, 'logname': 'ECL-PatchTST', 'time': '2023-09-02-01:38:18.256584', 'path': 'exp/ECL-PatchTST2023-09-02-01:38:18.256584', 'num_workers': 4, 'start_train': 0, 'train_mode': 'pretrain', 'get_score': False, 'use_cm': True, 'logger': <Logger __main__ (INFO)>}
2023-09-02 01:38:18,258 - [*] phase 0 start training
0 69680
train 34129
val 11425
test 11425
2023-09-02 01:38:19,107 - [*] phase 0 Dataset load!
2023-09-02 01:38:20,133 - [*] phase 0 Training start
train 34129
2023-09-02 01:39:45,799 - epoch:0, training loss:0.1831 validation loss:0.1788
train 34129
vs, vt 0.17875255420804023 0.18399998342825308
Updating learning rate to 1.0438661460315324e-05
Updating learning rate to 1.0438661460315324e-05
train 34129
vs, vt 0.16798849138948652 0.16877541525496376
need align? ->  False 0.16877541525496376
2023-09-02 01:43:29,852 - epoch:1, training loss:9.2601 validation loss:0.1680
Updating learning rate to 2.8027297449571736e-05
Updating learning rate to 2.8027297449571736e-05
train 34129
vs, vt 0.16671094670891762 0.16645601900915305
need align? ->  True 0.16645601900915305
2023-09-02 01:46:45,756 - epoch:2, training loss:3.1055 validation loss:0.1667
Updating learning rate to 5.204727160595503e-05
Updating learning rate to 5.204727160595503e-05
train 34129
vs, vt 0.16582099311053752 0.1678106074531873
need align? ->  False 0.16645601900915305
2023-09-02 01:50:04,429 - epoch:3, training loss:2.1450 validation loss:0.1658
Updating learning rate to 7.605456385119542e-05
Updating learning rate to 7.605456385119542e-05
train 34129
vs, vt 0.1662609485288461 0.1647576715383265
need align? ->  True 0.1647576715383265
2023-09-02 01:53:29,611 - epoch:4, training loss:1.7691 validation loss:0.1663
Updating learning rate to 9.360855637921138e-05
Updating learning rate to 9.360855637921138e-05
train 34129
vs, vt 0.16453773064745797 0.16564751830365923
need align? ->  False 0.1647576715383265
2023-09-02 01:56:52,474 - epoch:5, training loss:1.4089 validation loss:0.1645
Updating learning rate to 9.99999939458629e-05
Updating learning rate to 9.99999939458629e-05
train 34129
vs, vt 0.1644740297148625 0.16233376297685836
need align? ->  True 0.16233376297685836
2023-09-02 02:00:12,985 - epoch:6, training loss:1.2291 validation loss:0.1645
Updating learning rate to 9.956902716655286e-05
Updating learning rate to 9.956902716655286e-05
train 34129
vs, vt 0.16315294984314177 0.1665074741674794
need align? ->  True 0.16233376297685836
2023-09-02 02:03:31,099 - epoch:7, training loss:1.1230 validation loss:0.1632
Updating learning rate to 9.828992401134782e-05
Updating learning rate to 9.828992401134782e-05
train 34129
vs, vt 0.15785444656180012 0.16170297484431
need align? ->  False 0.16170297484431
2023-09-02 02:06:49,588 - epoch:8, training loss:1.0289 validation loss:0.1579
Updating learning rate to 9.618457028986775e-05
Updating learning rate to 9.618457028986775e-05
train 34129
vs, vt 0.16025478111373054 0.15897403744359812
need align? ->  True 0.15897403744359812
2023-09-02 02:10:06,498 - epoch:9, training loss:1.0103 validation loss:0.1603
Updating learning rate to 9.32889891880015e-05
Updating learning rate to 9.32889891880015e-05
train 34129
vs, vt 0.15780483509103457 0.16008248378833134
need align? ->  False 0.15897403744359812
2023-09-02 02:13:24,902 - epoch:10, training loss:0.9787 validation loss:0.1578
Updating learning rate to 8.965272490120875e-05
Updating learning rate to 8.965272490120875e-05
train 34129
vs, vt 0.15768052662412327 0.15541682806279924
need align? ->  True 0.15541682806279924
2023-09-02 02:16:44,352 - epoch:11, training loss:0.9358 validation loss:0.1577
Updating learning rate to 8.533799491959945e-05
Updating learning rate to 8.533799491959945e-05
train 34129
vs, vt 0.1572843685332272 0.15598045786221823
need align? ->  True 0.15541682806279924
2023-09-02 02:20:05,749 - epoch:12, training loss:0.9488 validation loss:0.1573
Updating learning rate to 8.041862546942808e-05
Updating learning rate to 8.041862546942808e-05
train 34129
vs, vt 0.15694263693359162 0.1552452702489164
need align? ->  True 0.1552452702489164
2023-09-02 02:23:28,841 - epoch:13, training loss:0.9136 validation loss:0.1569
Updating learning rate to 7.497878832589398e-05
Updating learning rate to 7.497878832589398e-05
train 34129
vs, vt 0.15615366270972622 0.15655669222275417
need align? ->  True 0.1552452702489164
2023-09-02 02:26:50,845 - epoch:14, training loss:0.9315 validation loss:0.1562
Updating learning rate to 6.911156061073078e-05
Updating learning rate to 6.911156061073078e-05
train 34129
vs, vt 0.1565589731352197 0.1551702865709861
need align? ->  True 0.1551702865709861
2023-09-02 02:30:16,977 - epoch:15, training loss:0.9087 validation loss:0.1566
Updating learning rate to 6.291733221684778e-05
Updating learning rate to 6.291733221684778e-05
train 34129
vs, vt 0.15556924459007052 0.15523047749367025
need align? ->  True 0.1551702865709861
2023-09-02 02:33:39,464 - epoch:16, training loss:0.9215 validation loss:0.1556
Updating learning rate to 5.650208810942889e-05
Updating learning rate to 5.650208810942889e-05
train 34129
vs, vt 0.15463820687598653 0.15393025345272487
need align? ->  True 0.15393025345272487
2023-09-02 02:37:02,637 - epoch:17, training loss:0.9063 validation loss:0.1546
Updating learning rate to 4.9975594893793686e-05
Updating learning rate to 4.9975594893793686e-05
train 34129
vs, vt 0.1557823574791352 0.1547129397177034
need align? ->  True 0.15393025345272487
2023-09-02 02:40:24,931 - epoch:18, training loss:0.9214 validation loss:0.1558
Updating learning rate to 4.3449522678347527e-05
Updating learning rate to 4.3449522678347527e-05
train 34129
vs, vt 0.1555168867111206 0.1542852678232723
need align? ->  True 0.15393025345272487
2023-09-02 02:43:48,106 - epoch:19, training loss:0.9106 validation loss:0.1555
Updating learning rate to 3.7035534368065714e-05
Updating learning rate to 3.7035534368065714e-05
train 34129
vs, vt 0.1545559292866124 0.1544484271357457
need align? ->  True 0.15393025345272487
2023-09-02 02:47:18,326 - epoch:20, training loss:0.9029 validation loss:0.1546
Updating learning rate to 3.084337508123067e-05
Updating learning rate to 3.084337508123067e-05
train 34129
vs, vt 0.15509351715445518 0.15393402237031195
need align? ->  True 0.15393025345272487
2023-09-02 02:50:35,478 - epoch:21, training loss:0.8973 validation loss:0.1551
Updating learning rate to 2.497899438003108e-05
Updating learning rate to 2.497899438003108e-05
train 34129
vs, vt 0.154470089243518 0.15337533098128106
need align? ->  True 0.15337533098128106
2023-09-02 02:53:53,477 - epoch:22, training loss:0.8932 validation loss:0.1545
Updating learning rate to 1.9542733444177923e-05
Updating learning rate to 1.9542733444177923e-05
train 34129
vs, vt 0.15423850975930692 0.15400302799211607
need align? ->  True 0.15337533098128106
2023-09-02 02:57:10,242 - epoch:23, training loss:0.9428 validation loss:0.1542
Updating learning rate to 1.4627608205499963e-05
Updating learning rate to 1.4627608205499963e-05
train 34129
vs, vt 0.15476720585591264 0.15379023974140485
need align? ->  True 0.15337533098128106
2023-09-02 03:00:33,901 - epoch:24, training loss:0.9372 validation loss:0.1548
Updating learning rate to 1.0317717819561129e-05
Updating learning rate to 1.0317717819561129e-05
train 34129
vs, vt 0.15429683331814076 0.1536357883363962
need align? ->  True 0.15337533098128106
2023-09-02 03:03:57,101 - epoch:25, training loss:0.9341 validation loss:0.1543
Updating learning rate to 6.686805705792195e-06
Updating learning rate to 6.686805705792195e-06
train 34129
vs, vt 0.15445282409588496 0.15344960490862528
need align? ->  True 0.15337533098128106
2023-09-02 03:07:20,848 - epoch:26, training loss:0.9324 validation loss:0.1545
Updating learning rate to 3.79699777713878e-06
Updating learning rate to 3.79699777713878e-06
train 34129
vs, vt 0.1543610672156016 0.1536913491371605
need align? ->  True 0.15337533098128106
2023-09-02 03:10:45,937 - epoch:27, training loss:0.9313 validation loss:0.1544
Updating learning rate to 1.6977394484662593e-06
Updating learning rate to 1.6977394484662593e-06
train 34129
vs, vt 0.15425228170222707 0.15353177268471982
need align? ->  True 0.15337533098128106
2023-09-02 03:14:11,840 - epoch:28, training loss:0.9305 validation loss:0.1543
Updating learning rate to 4.2494961180259127e-07
Updating learning rate to 4.2494961180259127e-07
train 34129
vs, vt 0.15425818272762828 0.15351440583666165
need align? ->  True 0.15337533098128106
2023-09-02 03:17:54,790 - epoch:29, training loss:0.9308 validation loss:0.1543
Updating learning rate to 4.0605413710007e-10
Updating learning rate to 4.0605413710007e-10
check exp/ECL-PatchTST2023-09-02-01:38:18.256584/0/0.1542_epoch_23.pkl  &  0.15337533098128106
2023-09-02 03:18:25,280 - [*] loss:0.2883
2023-09-02 03:18:25,290 - [*] phase 0, testing
2023-09-02 03:18:25,593 - T:96	MAE	0.337107	RMSE	0.289844	MAPE	215.729570
2023-09-02 03:18:25,607 - 96	mae	0.3371	
2023-09-02 03:18:25,607 - 96	rmse	0.2898	
2023-09-02 03:18:25,608 - 96	mape	215.7296	
----*-----
2023-09-02 03:18:56,462 - [*] loss:0.2883
2023-09-02 03:18:56,472 - [*] phase 0, testing
2023-09-02 03:18:56,806 - T:96	MAE	0.337107	RMSE	0.289844	MAPE	215.729570
2023-09-02 03:19:20,754 - [*] loss:0.3092
2023-09-02 03:19:20,764 - [*] phase 0, testing
2023-09-02 03:19:21,006 - T:96	MAE	0.364495	RMSE	0.310904	MAPE	239.712310
2023-09-02 03:19:44,825 - [*] loss:0.3906
2023-09-02 03:19:44,835 - [*] phase 0, testing
2023-09-02 03:19:45,032 - T:96	MAE	0.414030	RMSE	0.392860	MAPE	281.808376
2023-09-02 03:20:14,395 - [*] loss:0.2954
2023-09-02 03:20:14,406 - [*] phase 0, testing
2023-09-02 03:20:14,591 - T:96	MAE	0.347120	RMSE	0.297089	MAPE	232.673407
2023-09-02 03:20:48,629 - [*] loss:0.3705
2023-09-02 03:20:48,640 - [*] phase 0, testing
2023-09-02 03:20:48,823 - T:96	MAE	0.410647	RMSE	0.372239	MAPE	238.172054
2023-09-02 03:21:17,092 - [*] loss:0.3360
2023-09-02 03:21:17,102 - [*] phase 0, testing
2023-09-02 03:21:17,278 - T:96	MAE	0.380247	RMSE	0.337521	MAPE	204.356885
2023-09-02 03:21:43,209 - [*] loss:0.2939
2023-09-02 03:21:43,219 - [*] phase 0, testing
2023-09-02 03:21:43,405 - T:96	MAE	0.345676	RMSE	0.295519	MAPE	223.837709
2023-09-02 03:22:09,708 - [*] loss:0.3006
2023-09-02 03:22:09,717 - [*] phase 0, testing
2023-09-02 03:22:09,905 - T:96	MAE	0.355540	RMSE	0.302058	MAPE	204.446197
----*-----
2023-09-02 03:22:25,770 - [*] loss:0.2982
2023-09-02 03:22:25,780 - [*] phase 0, testing
2023-09-02 03:22:25,957 - T:96	MAE	0.353309	RMSE	0.298788	MAPE	206.415796
2023-09-02 03:22:51,335 - [*] loss:0.3007
2023-09-02 03:22:51,346 - [*] phase 0, testing
2023-09-02 03:22:51,587 - T:96	MAE	0.350116	RMSE	0.302389	MAPE	198.318505
2023-09-02 03:23:07,263 - [*] loss:0.2981
2023-09-02 03:23:07,272 - [*] phase 0, testing
2023-09-02 03:23:07,452 - T:96	MAE	0.345355	RMSE	0.299194	MAPE	199.778521
2023-09-02 03:23:07,452 - 96	mae	0.3454	
2023-09-02 03:23:07,453 - 96	rmse	0.2992	
2023-09-02 03:23:07,453 - 96	mape	199.7785	
2023-09-02 03:23:09,625 - logger name:exp/ECL-PatchTST2023-09-02-03:23:09.625626/ECL-PatchTST.log
2023-09-02 03:23:09,626 - params : {'loss': 'huber', 'conf': 'ECL-PatchTST', 'data_name': 'ETTm1', 'iteration': 1, 'train': 1, 'mainrs': 0, 'abl': 1, 'load': True, 'build_graph': False, 'same_init': True, 'grad_norm': False, 'refiner_residual': 0, 'root_path': '', 'exp_path': 'exp/', 'val_test_mix': False, 'lr': 0.0001, 'lradj': 'TST', 'dropout': 0.2, 'fc_dropout': 0.2, 'head_dropout': 0.0, 'patch_len': 16, 'stride': 8, 'd_ff': 256, 'd_model': 128, 'n_heads': 16, 'seq_len': 336, 'pred_len': 336, 'noise_rate': 0.5, 'device': device(type='cuda', index=1), 'test_model_path': '/Disk/fhyega/code/BASE/exp/ECL-PatchTST2023-08-26-13:08:31.837686/0/best_model.pkl', 'idx': -1, 'aligner': 1, 'always_align': 1, 'refiner': 1, 'rec_block_num': 1, 'enhance': 1, 'enhance_type': 5, 'seed': 34, 'batch_size': 128, 'share_head': 0, 'add_noise': 1, 'add_norm': 0, 'jitter_sigma': 0.4, 'slope_rate': 0.01, 'slope_range': 0.2, 'alpha': 10.0, 'beta': 1.0, 'gamma': 0.15, 'feature_jittering': 1, 'rec_intra_feature': 0, 'rec_ori': 1, 'mid_dim': 128, 'test_en': 0, 'debugger': 0, 'summary': 0, 'omega': 1.0, 'theta': 1.5, 'mask_border': 1, 'sup_weight': 10.0, 'rec_length_ratio': 0.8, 'ref_dropout': 0.2, 'ref_block_num': 2, 'add_FFN': 1, 'add_residual': 0, 'rec_all': 0, 'e_layers': 3, 'early_break': 0, 'early_stop': 10, '/* model related args*/': '//', 'model_name': 'PatchTST', 'label_len': 48, 'features': 'M', 'target': 'OT', 'graph_input': False, 'individual': False, 'd_layers': 1, 'factor': 1, 'des': 'Exp', 'padding_patch': 'end', 'revin': 1, 'affine': 0, 'subtract_last': 0, 'decomposition': 0, 'kernel_size': 25, 'output_attention': 0, 'embed_type': 0, 'activation': 'gelu', 'distil': 1, 'linear_output': 1, 'pct_start': 0.2, '/*train related args*/': '//', 'epoch': 30, '/*dataset related args*/': '//', 'save_data_path': 'data/ECL/', 'data_process': True, 'embed': 'timeF', 'freq': 'h', 'begin_phase': 0, 'end_phase': 1, 'phase_len': -1, 'val_ratio': 0.33, 'graph_size': 321, '/*strategy related args*/': '//', 'strategy': 'incremental', 'increase': False, 'detect': False, 'detect_strategy': 'feature', 'replay': False, 'replay_strategy': 'random', 'repaly_num_samples': 100, 'ewc': False, 'ewc_strategy': 'ewc', 'ewc_lambda': 0.0001, 'subgraph_train': False, 'num_hops': 2, 'logname': 'ECL-PatchTST', 'time': '2023-09-02-03:23:09.625626', 'path': 'exp/ECL-PatchTST2023-09-02-03:23:09.625626', 'num_workers': 4, 'start_train': 0, 'train_mode': 'pretrain', 'get_score': False, 'use_cm': True, 'logger': <Logger __main__ (INFO)>}
2023-09-02 03:23:09,626 - [*] phase 0 start training
0 69680
train 33889
val 11185
test 11185
2023-09-02 03:23:10,446 - [*] phase 0 Dataset load!
2023-09-02 03:23:11,479 - [*] phase 0 Training start
train 33889
2023-09-02 03:24:44,359 - epoch:0, training loss:0.2074 validation loss:0.2604
train 33889
vs, vt 0.26037318153645506 0.2635187496515838
Updating learning rate to 1.0438721218484657e-05
Updating learning rate to 1.0438721218484657e-05
train 33889
vs, vt 0.2553064812567424 0.25508660141547973
need align? ->  True 0.25508660141547973
2023-09-02 03:28:57,163 - epoch:1, training loss:8.9621 validation loss:0.2553
Updating learning rate to 2.802750441854847e-05
Updating learning rate to 2.802750441854847e-05
train 33889
vs, vt 0.2517156559889289 0.25327644031494856
need align? ->  False 0.25327644031494856
2023-09-02 03:32:18,107 - epoch:2, training loss:3.0735 validation loss:0.2517
Updating learning rate to 5.2047629950292354e-05
Updating learning rate to 5.2047629950292354e-05
train 33889
vs, vt 0.25228000233288517 0.2526288677684285
need align? ->  False 0.2526288677684285
2023-09-02 03:35:40,628 - epoch:3, training loss:2.1680 validation loss:0.2523
Updating learning rate to 7.605497731655361e-05
Updating learning rate to 7.605497731655361e-05
train 33889
vs, vt 0.25216334067623725 0.253106358461082
need align? ->  False 0.2526288677684285
2023-09-02 03:39:01,516 - epoch:4, training loss:1.6905 validation loss:0.2522
Updating learning rate to 9.3608854147054e-05
Updating learning rate to 9.3608854147054e-05
train 33889
vs, vt 0.24993120675737207 0.25259830472482875
need align? ->  False 0.25259830472482875
2023-09-02 03:42:23,352 - epoch:5, training loss:1.4300 validation loss:0.2499
Updating learning rate to 9.99999938537861e-05
Updating learning rate to 9.99999938537861e-05
train 33889
vs, vt 0.24882413908331233 0.2500619757073847
need align? ->  False 0.2500619757073847
2023-09-02 03:45:42,758 - epoch:6, training loss:1.2940 validation loss:0.2488
Updating learning rate to 9.956900274488073e-05
Updating learning rate to 9.956900274488073e-05
train 33889
vs, vt 0.24804797154766592 0.2513234111141752
need align? ->  False 0.2500619757073847
2023-09-02 03:49:02,590 - epoch:7, training loss:1.1703 validation loss:0.2480
Updating learning rate to 9.828987567794199e-05
Updating learning rate to 9.828987567794199e-05
train 33889
vs, vt 0.24632149215110324 0.25066449091007764
need align? ->  False 0.2500619757073847
2023-09-02 03:52:23,995 - epoch:8, training loss:1.0813 validation loss:0.2463
Updating learning rate to 9.618449887172618e-05
Updating learning rate to 9.618449887172618e-05
train 33889
vs, vt 0.24860369888218967 0.25109183809465985
need align? ->  False 0.2500619757073847
2023-09-02 03:55:43,518 - epoch:9, training loss:1.0256 validation loss:0.2486
Updating learning rate to 9.328889590710838e-05
Updating learning rate to 9.328889590710838e-05
train 33889
vs, vt 0.2495378264310685 0.25403390676629817
need align? ->  False 0.2500619757073847
2023-09-02 03:59:02,418 - epoch:10, training loss:0.9873 validation loss:0.2495
Updating learning rate to 8.965261135362604e-05
Updating learning rate to 8.965261135362604e-05
train 33889
vs, vt 0.246532623402097 0.25458926834504714
need align? ->  False 0.2500619757073847
2023-09-02 04:02:19,321 - epoch:11, training loss:0.9596 validation loss:0.2465
Updating learning rate to 8.533786304815776e-05
Updating learning rate to 8.533786304815776e-05
train 33889
vs, vt 0.2471081969243559 0.2529184771278365
need align? ->  False 0.2500619757073847
2023-09-02 04:05:37,676 - epoch:12, training loss:0.9393 validation loss:0.2471
Updating learning rate to 8.041847753048434e-05
Updating learning rate to 8.041847753048434e-05
train 33889
vs, vt 0.24922204597599126 0.2535599854097448
need align? ->  False 0.2500619757073847
2023-09-02 04:08:55,829 - epoch:13, training loss:0.9229 validation loss:0.2492
Updating learning rate to 7.497862685072454e-05
Updating learning rate to 7.497862685072454e-05
train 33889
vs, vt 0.24899860407987778 0.2533142043023624
need align? ->  False 0.2500619757073847
2023-09-02 04:12:14,545 - epoch:14, training loss:0.9090 validation loss:0.2490
Updating learning rate to 6.911138836222055e-05
Updating learning rate to 6.911138836222055e-05
train 33889
vs, vt 0.24898942352526568 0.2542094712314958
need align? ->  False 0.2500619757073847
2023-09-02 04:15:33,517 - epoch:15, training loss:0.8982 validation loss:0.2490
Updating learning rate to 6.291715214221653e-05
Updating learning rate to 6.291715214221653e-05
train 33889
vs, vt 0.24809031150388447 0.25548126095567236
need align? ->  False 0.2500619757073847
2023-09-02 04:18:50,093 - epoch:16, training loss:0.8897 validation loss:0.2481
Updating learning rate to 5.6501903289803477e-05
Updating learning rate to 5.6501903289803477e-05
train 33889
vs, vt 0.2469941882670603 0.2553369675085626
need align? ->  False 0.2500619757073847
2023-09-02 04:22:06,738 - epoch:17, training loss:0.8823 validation loss:0.2470
Updating learning rate to 4.997540849148917e-05
Updating learning rate to 4.997540849148917e-05
train 33889
vs, vt 0.24659311191432856 0.2536447228101844
need align? ->  False 0.2500619757073847
2023-09-02 04:25:22,042 - epoch:18, training loss:0.8768 validation loss:0.2466
Updating learning rate to 4.344933788275899e-05
Updating learning rate to 4.344933788275899e-05
train 33889
vs, vt 0.2490047969093377 0.25450527524067595
need align? ->  False 0.2500619757073847
2023-09-02 04:28:37,850 - epoch:19, training loss:0.8722 validation loss:0.2490
check exp/ECL-PatchTST2023-09-02-03:23:09.625626/0/0.2463_epoch_8.pkl  &  0.2500619757073847
2023-09-02 04:29:01,201 - [*] loss:0.3818
2023-09-02 04:29:01,250 - [*] phase 0, testing
2023-09-02 04:29:03,893 - T:336	MAE	0.391846	RMSE	0.381604	MAPE	239.249349
2023-09-02 04:29:03,894 - 336	mae	0.3918	
2023-09-02 04:29:03,895 - 336	rmse	0.3816	
2023-09-02 04:29:03,895 - 336	mape	239.2493	
----*-----
2023-09-02 04:29:25,313 - [*] loss:0.3818
2023-09-02 04:29:25,354 - [*] phase 0, testing
2023-09-02 04:29:26,531 - T:336	MAE	0.391846	RMSE	0.381604	MAPE	239.249349
2023-09-02 04:29:54,600 - [*] loss:0.3921
2023-09-02 04:29:54,643 - [*] phase 0, testing
2023-09-02 04:29:56,191 - T:336	MAE	0.404956	RMSE	0.391913	MAPE	249.501133
2023-09-02 04:30:25,257 - [*] loss:0.4092
2023-09-02 04:30:25,301 - [*] phase 0, testing
2023-09-02 04:30:26,809 - T:336	MAE	0.415008	RMSE	0.409097	MAPE	262.739825
2023-09-02 04:30:58,404 - [*] loss:0.3881
2023-09-02 04:30:58,447 - [*] phase 0, testing
2023-09-02 04:30:59,726 - T:336	MAE	0.400089	RMSE	0.387926	MAPE	257.320595
2023-09-02 04:31:27,403 - [*] loss:0.4389
2023-09-02 04:31:27,447 - [*] phase 0, testing
2023-09-02 04:31:28,784 - T:336	MAE	0.442391	RMSE	0.438708	MAPE	250.541091
2023-09-02 04:31:52,490 - [*] loss:0.4178
2023-09-02 04:31:52,563 - [*] phase 0, testing
2023-09-02 04:31:53,821 - T:336	MAE	0.424329	RMSE	0.417275	MAPE	214.863205
2023-09-02 04:32:17,594 - [*] loss:0.3847
2023-09-02 04:32:17,646 - [*] phase 0, testing
2023-09-02 04:32:18,814 - T:336	MAE	0.396184	RMSE	0.384489	MAPE	242.727351
2023-09-02 04:32:42,603 - [*] loss:0.3811
2023-09-02 04:32:42,645 - [*] phase 0, testing
2023-09-02 04:32:43,948 - T:336	MAE	0.397817	RMSE	0.380791	MAPE	220.961714
----*-----
2023-09-02 04:33:01,252 - [*] loss:0.3752
2023-09-02 04:33:01,295 - [*] phase 0, testing
2023-09-02 04:33:02,128 - T:336	MAE	0.394841	RMSE	0.374840	MAPE	223.057938
2023-09-02 04:33:31,482 - [*] loss:0.3898
2023-09-02 04:33:31,525 - [*] phase 0, testing
2023-09-02 04:33:32,209 - T:336	MAE	0.400999	RMSE	0.389548	MAPE	222.241044
2023-09-02 04:33:53,064 - [*] loss:0.3846
2023-09-02 04:33:53,105 - [*] phase 0, testing
2023-09-02 04:33:53,788 - T:336	MAE	0.397428	RMSE	0.384451	MAPE	223.952675
2023-09-02 04:33:53,789 - 336	mae	0.3974	
2023-09-02 04:33:53,790 - 336	rmse	0.3845	
2023-09-02 04:33:53,790 - 336	mape	223.9527	
2023-09-02 04:33:56,288 - logger name:exp/ECL-PatchTST2023-09-02-04:33:56.284887/ECL-PatchTST.log
2023-09-02 04:33:56,289 - params : {'loss': 'huber', 'conf': 'ECL-PatchTST', 'data_name': 'ETTm1', 'iteration': 1, 'train': 1, 'mainrs': 0, 'abl': 1, 'load': True, 'build_graph': False, 'same_init': True, 'grad_norm': False, 'refiner_residual': 0, 'root_path': '', 'exp_path': 'exp/', 'val_test_mix': False, 'lr': 0.0001, 'lradj': 'TST', 'dropout': 0.2, 'fc_dropout': 0.2, 'head_dropout': 0.0, 'patch_len': 16, 'stride': 8, 'd_ff': 256, 'd_model': 128, 'n_heads': 16, 'seq_len': 336, 'pred_len': 96, 'noise_rate': 0.5, 'device': device(type='cuda', index=1), 'test_model_path': '/Disk/fhyega/code/BASE/exp/ECL-PatchTST2023-08-26-13:08:31.837686/0/best_model.pkl', 'idx': -1, 'aligner': 1, 'always_align': 1, 'refiner': 1, 'rec_block_num': 1, 'enhance': 1, 'enhance_type': 5, 'seed': 34, 'batch_size': 128, 'share_head': 0, 'add_noise': 1, 'add_norm': 0, 'jitter_sigma': 0.4, 'slope_rate': 0.01, 'slope_range': 0.2, 'alpha': 10.0, 'beta': 1.0, 'gamma': 0.15, 'feature_jittering': 1, 'rec_intra_feature': 0, 'rec_ori': 1, 'mid_dim': 128, 'test_en': 0, 'debugger': 0, 'summary': 0, 'omega': 1.0, 'theta': 1.5, 'mask_border': 1, 'sup_weight': 10.0, 'rec_length_ratio': 0.8, 'ref_dropout': 0.0, 'ref_block_num': 1, 'add_FFN': 1, 'add_residual': 0, 'rec_all': 0, 'e_layers': 3, 'early_break': 0, 'early_stop': 10, '/* model related args*/': '//', 'model_name': 'PatchTST', 'label_len': 48, 'features': 'M', 'target': 'OT', 'graph_input': False, 'individual': False, 'd_layers': 1, 'factor': 1, 'des': 'Exp', 'padding_patch': 'end', 'revin': 1, 'affine': 0, 'subtract_last': 0, 'decomposition': 0, 'kernel_size': 25, 'output_attention': 0, 'embed_type': 0, 'activation': 'gelu', 'distil': 1, 'linear_output': 1, 'pct_start': 0.2, '/*train related args*/': '//', 'epoch': 30, '/*dataset related args*/': '//', 'save_data_path': 'data/ECL/', 'data_process': True, 'embed': 'timeF', 'freq': 'h', 'begin_phase': 0, 'end_phase': 1, 'phase_len': -1, 'val_ratio': 0.33, 'graph_size': 321, '/*strategy related args*/': '//', 'strategy': 'incremental', 'increase': False, 'detect': False, 'detect_strategy': 'feature', 'replay': False, 'replay_strategy': 'random', 'repaly_num_samples': 100, 'ewc': False, 'ewc_strategy': 'ewc', 'ewc_lambda': 0.0001, 'subgraph_train': False, 'num_hops': 2, 'logname': 'ECL-PatchTST', 'time': '2023-09-02-04:33:56.284887', 'path': 'exp/ECL-PatchTST2023-09-02-04:33:56.284887', 'num_workers': 4, 'start_train': 0, 'train_mode': 'pretrain', 'get_score': False, 'use_cm': True, 'logger': <Logger __main__ (INFO)>}
2023-09-02 04:33:56,289 - [*] phase 0 start training
0 69680
train 34129
val 11425
test 11425
2023-09-02 04:33:57,261 - [*] phase 0 Dataset load!
2023-09-02 04:33:58,346 - [*] phase 0 Training start
train 34129
2023-09-02 04:35:25,685 - epoch:0, training loss:0.1861 validation loss:0.1808
train 34129
vs, vt 0.18079212121665478 0.18612667355272505
Updating learning rate to 1.0438661460315324e-05
Updating learning rate to 1.0438661460315324e-05
train 34129
vs, vt 0.16622135821315978 0.1675002078215281
need align? ->  False 0.1675002078215281
2023-09-02 04:39:23,385 - epoch:1, training loss:9.4725 validation loss:0.1662
Updating learning rate to 2.8027297449571736e-05
Updating learning rate to 2.8027297449571736e-05
train 34129
vs, vt 0.16432773859964478 0.1650480969912476
need align? ->  False 0.1650480969912476
2023-09-02 04:42:33,813 - epoch:2, training loss:3.2572 validation loss:0.1643
Updating learning rate to 5.204727160595503e-05
Updating learning rate to 5.204727160595503e-05
train 34129
vs, vt 0.1676397195706765 0.16724420893523428
need align? ->  True 0.1650480969912476
2023-09-02 04:45:42,136 - epoch:3, training loss:2.2454 validation loss:0.1676
Updating learning rate to 7.605456385119542e-05
Updating learning rate to 7.605456385119542e-05
train 34129
vs, vt 0.16458031982183458 0.16612330025268926
need align? ->  False 0.1650480969912476
2023-09-02 04:48:50,000 - epoch:4, training loss:1.8591 validation loss:0.1646
Updating learning rate to 9.360855637921138e-05
Updating learning rate to 9.360855637921138e-05
train 34129
vs, vt 0.1657927312163843 0.16354140647583537
need align? ->  True 0.16354140647583537
2023-09-02 04:52:08,036 - epoch:5, training loss:1.6139 validation loss:0.1658
Updating learning rate to 9.99999939458629e-05
Updating learning rate to 9.99999939458629e-05
train 34129
vs, vt 0.1637834861046738 0.16237166486680507
need align? ->  True 0.16237166486680507
2023-09-02 04:55:27,263 - epoch:6, training loss:1.3245 validation loss:0.1638
Updating learning rate to 9.956902716655286e-05
Updating learning rate to 9.956902716655286e-05
train 34129
vs, vt 0.1590229949603478 0.1602814773718516
need align? ->  False 0.1602814773718516
2023-09-02 04:58:54,720 - epoch:7, training loss:1.1995 validation loss:0.1590
Updating learning rate to 9.828992401134782e-05
Updating learning rate to 9.828992401134782e-05
train 34129
vs, vt 0.16132472165756756 0.15791088032225767
need align? ->  True 0.15791088032225767
2023-09-02 05:02:29,033 - epoch:8, training loss:1.1091 validation loss:0.1613
Updating learning rate to 9.618457028986775e-05
Updating learning rate to 9.618457028986775e-05
train 34129
vs, vt 0.15918761533167627 0.1565937635799249
need align? ->  True 0.1565937635799249
2023-09-02 05:05:41,994 - epoch:9, training loss:1.0666 validation loss:0.1592
Updating learning rate to 9.32889891880015e-05
Updating learning rate to 9.32889891880015e-05
train 34129
vs, vt 0.15961776421301896 0.15597867508315377
need align? ->  True 0.15597867508315377
2023-09-02 05:08:55,582 - epoch:10, training loss:1.0302 validation loss:0.1596
Updating learning rate to 8.965272490120875e-05
Updating learning rate to 8.965272490120875e-05
train 34129
vs, vt 0.1574689116742876 0.1590912395881282
need align? ->  True 0.15597867508315377
2023-09-02 05:12:10,301 - epoch:11, training loss:1.0148 validation loss:0.1575
Updating learning rate to 8.533799491959945e-05
Updating learning rate to 8.533799491959945e-05
train 34129
vs, vt 0.15793683495786454 0.15667045840786564
need align? ->  True 0.15597867508315377
2023-09-02 05:15:24,425 - epoch:12, training loss:0.9837 validation loss:0.1579
Updating learning rate to 8.041862546942808e-05
Updating learning rate to 8.041862546942808e-05
train 34129
vs, vt 0.1567625507712364 0.15568159975939327
need align? ->  True 0.15568159975939327
2023-09-02 05:18:39,694 - epoch:13, training loss:0.9593 validation loss:0.1568
Updating learning rate to 7.497878832589398e-05
Updating learning rate to 7.497878832589398e-05
train 34129
vs, vt 0.15668916246957248 0.1544734938070178
need align? ->  True 0.1544734938070178
2023-09-02 05:21:58,033 - epoch:14, training loss:0.9855 validation loss:0.1567
Updating learning rate to 6.911156061073078e-05
Updating learning rate to 6.911156061073078e-05
train 34129
vs, vt 0.1560164569152726 0.15516294358919064
need align? ->  True 0.1544734938070178
2023-09-02 05:25:13,041 - epoch:15, training loss:0.9653 validation loss:0.1560
Updating learning rate to 6.291733221684778e-05
Updating learning rate to 6.291733221684778e-05
train 34129
vs, vt 0.15528282109234068 0.15511142288645108
need align? ->  True 0.1544734938070178
2023-09-02 05:28:28,059 - epoch:16, training loss:0.9483 validation loss:0.1553
Updating learning rate to 5.650208810942889e-05
Updating learning rate to 5.650208810942889e-05
train 34129
vs, vt 0.15544365296761195 0.15409150136013824
need align? ->  True 0.15409150136013824
2023-09-02 05:31:42,296 - epoch:17, training loss:0.9348 validation loss:0.1554
Updating learning rate to 4.9975594893793686e-05
Updating learning rate to 4.9975594893793686e-05
train 34129
vs, vt 0.1566618077456951 0.15451244426270325
need align? ->  True 0.15409150136013824
2023-09-02 05:34:54,774 - epoch:18, training loss:0.9670 validation loss:0.1567
Updating learning rate to 4.3449522678347527e-05
Updating learning rate to 4.3449522678347527e-05
train 34129
vs, vt 0.1550471937490834 0.1541566020084752
need align? ->  True 0.15409150136013824
2023-09-02 05:38:06,893 - epoch:19, training loss:0.9559 validation loss:0.1550
Updating learning rate to 3.7035534368065714e-05
Updating learning rate to 3.7035534368065714e-05
train 34129
vs, vt 0.1554968455599414 0.15390892210933899
need align? ->  True 0.15390892210933899
2023-09-02 05:41:16,802 - epoch:20, training loss:0.9470 validation loss:0.1555
Updating learning rate to 3.084337508123067e-05
Updating learning rate to 3.084337508123067e-05
train 34129
vs, vt 0.155462829520305 0.1537020674182309
need align? ->  True 0.1537020674182309
2023-09-02 05:44:28,859 - epoch:21, training loss:0.9756 validation loss:0.1555
Updating learning rate to 2.497899438003108e-05
Updating learning rate to 2.497899438003108e-05
train 34129
vs, vt 0.15452247891161178 0.1533406987786293
need align? ->  True 0.1533406987786293
2023-09-02 05:47:39,142 - epoch:22, training loss:0.9744 validation loss:0.1545
Updating learning rate to 1.9542733444177923e-05
Updating learning rate to 1.9542733444177923e-05
train 34129
vs, vt 0.15574747771024705 0.15379581418302324
need align? ->  True 0.1533406987786293
2023-09-02 05:50:49,693 - epoch:23, training loss:0.9793 validation loss:0.1557
Updating learning rate to 1.4627608205499963e-05
Updating learning rate to 1.4627608205499963e-05
train 34129
vs, vt 0.15498998959859211 0.15353095345199108
need align? ->  True 0.1533406987786293
2023-09-02 05:53:58,377 - epoch:24, training loss:0.9753 validation loss:0.1550
Updating learning rate to 1.0317717819561129e-05
Updating learning rate to 1.0317717819561129e-05
train 34129
vs, vt 0.1549866839415497 0.1532335484193431
need align? ->  True 0.1532335484193431
2023-09-02 05:57:09,256 - epoch:25, training loss:0.9724 validation loss:0.1550
Updating learning rate to 6.686805705792195e-06
Updating learning rate to 6.686805705792195e-06
train 34129
vs, vt 0.15491240086654823 0.15325667704972956
need align? ->  True 0.1532335484193431
2023-09-02 06:00:19,522 - epoch:26, training loss:0.9808 validation loss:0.1549
Updating learning rate to 3.79699777713878e-06
Updating learning rate to 3.79699777713878e-06
train 34129
vs, vt 0.15480344738397334 0.1530888884431786
need align? ->  True 0.1530888884431786
2023-09-02 06:03:28,400 - epoch:27, training loss:0.9798 validation loss:0.1548
Updating learning rate to 1.6977394484662593e-06
Updating learning rate to 1.6977394484662593e-06
train 34129
vs, vt 0.15476061482396392 0.15303285871114997
need align? ->  True 0.15303285871114997
2023-09-02 06:06:38,410 - epoch:28, training loss:0.9810 validation loss:0.1548
Updating learning rate to 4.2494961180259127e-07
Updating learning rate to 4.2494961180259127e-07
train 34129
vs, vt 0.15494466957946618 0.15307102327545483
need align? ->  True 0.15303285871114997
2023-09-02 06:10:08,580 - epoch:29, training loss:0.9825 validation loss:0.1549
Updating learning rate to 4.0605413710007e-10
Updating learning rate to 4.0605413710007e-10
check exp/ECL-PatchTST2023-09-02-04:33:56.284887/0/0.1545_epoch_22.pkl  &  0.15303285871114997
2023-09-02 06:10:38,157 - [*] loss:0.2878
2023-09-02 06:10:38,168 - [*] phase 0, testing
2023-09-02 06:10:38,352 - T:96	MAE	0.337074	RMSE	0.289076	MAPE	214.143872
2023-09-02 06:10:38,353 - 96	mae	0.3371	
2023-09-02 06:10:38,354 - 96	rmse	0.2891	
2023-09-02 06:10:38,354 - 96	mape	214.1439	
----*-----
2023-09-02 06:11:08,330 - [*] loss:0.2878
2023-09-02 06:11:08,341 - [*] phase 0, testing
2023-09-02 06:11:08,522 - T:96	MAE	0.337074	RMSE	0.289076	MAPE	214.143872
2023-09-02 06:11:40,696 - [*] loss:0.3057
2023-09-02 06:11:40,707 - [*] phase 0, testing
2023-09-02 06:11:40,892 - T:96	MAE	0.361681	RMSE	0.307114	MAPE	232.759619
2023-09-02 06:12:11,898 - [*] loss:0.3655
2023-09-02 06:12:11,909 - [*] phase 0, testing
2023-09-02 06:12:12,086 - T:96	MAE	0.394040	RMSE	0.367077	MAPE	252.766204
2023-09-02 06:12:43,947 - [*] loss:0.2931
2023-09-02 06:12:43,957 - [*] phase 0, testing
2023-09-02 06:12:44,149 - T:96	MAE	0.344817	RMSE	0.294725	MAPE	228.001428
2023-09-02 06:13:18,447 - [*] loss:0.3578
2023-09-02 06:13:18,457 - [*] phase 0, testing
2023-09-02 06:13:18,642 - T:96	MAE	0.400018	RMSE	0.359343	MAPE	230.824089
2023-09-02 06:13:50,367 - [*] loss:0.3310
2023-09-02 06:13:50,378 - [*] phase 0, testing
2023-09-02 06:13:50,579 - T:96	MAE	0.376128	RMSE	0.332472	MAPE	200.616241
2023-09-02 06:14:15,777 - [*] loss:0.2935
2023-09-02 06:14:15,788 - [*] phase 0, testing
2023-09-02 06:14:15,968 - T:96	MAE	0.345289	RMSE	0.294873	MAPE	220.382977
2023-09-02 06:14:42,439 - [*] loss:0.2998
2023-09-02 06:14:42,449 - [*] phase 0, testing
2023-09-02 06:14:42,627 - T:96	MAE	0.353950	RMSE	0.301145	MAPE	201.712608
----*-----
2023-09-02 06:15:04,369 - [*] loss:0.2987
2023-09-02 06:15:04,379 - [*] phase 0, testing
2023-09-02 06:15:04,566 - T:96	MAE	0.352225	RMSE	0.299056	MAPE	203.218579
2023-09-02 06:15:34,452 - [*] loss:0.3048
2023-09-02 06:15:34,463 - [*] phase 0, testing
2023-09-02 06:15:34,650 - T:96	MAE	0.349929	RMSE	0.306624	MAPE	192.078900
2023-09-02 06:15:52,473 - [*] loss:0.2989
2023-09-02 06:15:52,483 - [*] phase 0, testing
2023-09-02 06:15:52,667 - T:96	MAE	0.345401	RMSE	0.299651	MAPE	198.909283
2023-09-02 06:15:52,668 - 96	mae	0.3454	
2023-09-02 06:15:52,668 - 96	rmse	0.2997	
2023-09-02 06:15:52,668 - 96	mape	198.9093	
2023-09-02 06:15:54,932 - logger name:exp/ECL-PatchTST2023-09-02-06:15:54.932200/ECL-PatchTST.log
2023-09-02 06:15:54,932 - params : {'loss': 'huber', 'conf': 'ECL-PatchTST', 'data_name': 'ETTm1', 'iteration': 1, 'train': 1, 'mainrs': 0, 'abl': 1, 'load': True, 'build_graph': False, 'same_init': True, 'grad_norm': False, 'refiner_residual': 0, 'root_path': '', 'exp_path': 'exp/', 'val_test_mix': False, 'lr': 0.0001, 'lradj': 'TST', 'dropout': 0.2, 'fc_dropout': 0.2, 'head_dropout': 0.0, 'patch_len': 16, 'stride': 8, 'd_ff': 256, 'd_model': 128, 'n_heads': 16, 'seq_len': 336, 'pred_len': 336, 'noise_rate': 0.5, 'device': device(type='cuda', index=1), 'test_model_path': '/Disk/fhyega/code/BASE/exp/ECL-PatchTST2023-08-26-13:08:31.837686/0/best_model.pkl', 'idx': -1, 'aligner': 1, 'always_align': 1, 'refiner': 1, 'rec_block_num': 1, 'enhance': 1, 'enhance_type': 5, 'seed': 34, 'batch_size': 128, 'share_head': 0, 'add_noise': 1, 'add_norm': 0, 'jitter_sigma': 0.4, 'slope_rate': 0.01, 'slope_range': 0.2, 'alpha': 10.0, 'beta': 1.0, 'gamma': 0.15, 'feature_jittering': 1, 'rec_intra_feature': 0, 'rec_ori': 1, 'mid_dim': 128, 'test_en': 0, 'debugger': 0, 'summary': 0, 'omega': 1.0, 'theta': 1.5, 'mask_border': 1, 'sup_weight': 10.0, 'rec_length_ratio': 0.8, 'ref_dropout': 0.0, 'ref_block_num': 1, 'add_FFN': 1, 'add_residual': 0, 'rec_all': 0, 'e_layers': 3, 'early_break': 0, 'early_stop': 10, '/* model related args*/': '//', 'model_name': 'PatchTST', 'label_len': 48, 'features': 'M', 'target': 'OT', 'graph_input': False, 'individual': False, 'd_layers': 1, 'factor': 1, 'des': 'Exp', 'padding_patch': 'end', 'revin': 1, 'affine': 0, 'subtract_last': 0, 'decomposition': 0, 'kernel_size': 25, 'output_attention': 0, 'embed_type': 0, 'activation': 'gelu', 'distil': 1, 'linear_output': 1, 'pct_start': 0.2, '/*train related args*/': '//', 'epoch': 30, '/*dataset related args*/': '//', 'save_data_path': 'data/ECL/', 'data_process': True, 'embed': 'timeF', 'freq': 'h', 'begin_phase': 0, 'end_phase': 1, 'phase_len': -1, 'val_ratio': 0.33, 'graph_size': 321, '/*strategy related args*/': '//', 'strategy': 'incremental', 'increase': False, 'detect': False, 'detect_strategy': 'feature', 'replay': False, 'replay_strategy': 'random', 'repaly_num_samples': 100, 'ewc': False, 'ewc_strategy': 'ewc', 'ewc_lambda': 0.0001, 'subgraph_train': False, 'num_hops': 2, 'logname': 'ECL-PatchTST', 'time': '2023-09-02-06:15:54.932200', 'path': 'exp/ECL-PatchTST2023-09-02-06:15:54.932200', 'num_workers': 4, 'start_train': 0, 'train_mode': 'pretrain', 'get_score': False, 'use_cm': True, 'logger': <Logger __main__ (INFO)>}
2023-09-02 06:15:54,933 - [*] phase 0 start training
0 69680
train 33889
val 11185
test 11185
2023-09-02 06:15:55,773 - [*] phase 0 Dataset load!
2023-09-02 06:15:56,827 - [*] phase 0 Training start
train 33889
2023-09-02 06:17:22,740 - epoch:0, training loss:0.2088 validation loss:0.2610
train 33889
vs, vt 0.2610451753081923 0.2647863778878342
Updating learning rate to 1.0438721218484657e-05
Updating learning rate to 1.0438721218484657e-05
train 33889
vs, vt 0.2546154606494714 0.2539485065181824
need align? ->  True 0.2539485065181824
2023-09-02 06:21:20,468 - epoch:1, training loss:9.1985 validation loss:0.2546
Updating learning rate to 2.802750441854847e-05
Updating learning rate to 2.802750441854847e-05
train 33889
vs, vt 0.2533215269954367 0.2529123420403762
need align? ->  True 0.2529123420403762
2023-09-02 06:24:30,566 - epoch:2, training loss:3.1304 validation loss:0.2533
Updating learning rate to 5.2047629950292354e-05
Updating learning rate to 5.2047629950292354e-05
train 33889
vs, vt 0.2513594502921809 0.25449476458809595
need align? ->  False 0.2529123420403762
2023-09-02 06:27:40,267 - epoch:3, training loss:2.2136 validation loss:0.2514
Updating learning rate to 7.605497731655361e-05
Updating learning rate to 7.605497731655361e-05
train 33889
vs, vt 0.2550808507525785 0.25131288390945306
need align? ->  True 0.25131288390945306
2023-09-02 06:30:50,123 - epoch:4, training loss:1.7852 validation loss:0.2551
Updating learning rate to 9.3608854147054e-05
Updating learning rate to 9.3608854147054e-05
train 33889
vs, vt 0.252345937515863 0.25386704030362045
need align? ->  True 0.25131288390945306
2023-09-02 06:34:00,097 - epoch:5, training loss:1.5122 validation loss:0.2523
Updating learning rate to 9.99999938537861e-05
Updating learning rate to 9.99999938537861e-05
train 33889
vs, vt 0.2511810615489429 0.2511718023822389
need align? ->  True 0.2511718023822389
2023-09-02 06:37:11,596 - epoch:6, training loss:1.3459 validation loss:0.2512
Updating learning rate to 9.956900274488073e-05
Updating learning rate to 9.956900274488073e-05
train 33889
vs, vt 0.24833685312081466 0.25228430466218427
need align? ->  False 0.2511718023822389
2023-09-02 06:40:21,670 - epoch:7, training loss:1.2896 validation loss:0.2483
Updating learning rate to 9.828987567794199e-05
Updating learning rate to 9.828987567794199e-05
train 33889
vs, vt 0.24792622025548058 0.25042191363701766
need align? ->  False 0.25042191363701766
2023-09-02 06:43:32,528 - epoch:8, training loss:1.1971 validation loss:0.2479
Updating learning rate to 9.618449887172618e-05
Updating learning rate to 9.618449887172618e-05
train 33889
vs, vt 0.2514188491146673 0.2524575302377343
need align? ->  True 0.25042191363701766
2023-09-02 06:46:44,725 - epoch:9, training loss:1.1900 validation loss:0.2514
Updating learning rate to 9.328889590710838e-05
Updating learning rate to 9.328889590710838e-05
train 33889
vs, vt 0.25145221543921664 0.25061821154403413
need align? ->  True 0.25042191363701766
2023-09-02 06:49:55,899 - epoch:10, training loss:1.1151 validation loss:0.2515
Updating learning rate to 8.965261135362604e-05
Updating learning rate to 8.965261135362604e-05
train 33889
vs, vt 0.2481229071166705 0.25439427445896645
need align? ->  False 0.25042191363701766
2023-09-02 06:53:09,517 - epoch:11, training loss:1.0680 validation loss:0.2481
Updating learning rate to 8.533786304815776e-05
Updating learning rate to 8.533786304815776e-05
train 33889
vs, vt 0.249209173489362 0.250545782121745
need align? ->  False 0.25042191363701766
2023-09-02 06:56:23,413 - epoch:12, training loss:1.0357 validation loss:0.2492
Updating learning rate to 8.041847753048434e-05
Updating learning rate to 8.041847753048434e-05
train 33889
vs, vt 0.24747533469714902 0.25240740294314246
need align? ->  False 0.25042191363701766
2023-09-02 06:59:43,636 - epoch:13, training loss:1.0112 validation loss:0.2475
Updating learning rate to 7.497862685072454e-05
Updating learning rate to 7.497862685072454e-05
train 33889
vs, vt 0.24744113323024727 0.24975919842042707
need align? ->  False 0.24975919842042707
2023-09-02 07:03:09,624 - epoch:14, training loss:0.9913 validation loss:0.2474
Updating learning rate to 6.911138836222055e-05
Updating learning rate to 6.911138836222055e-05
train 33889
vs, vt 0.24892440713434058 0.252145920837806
need align? ->  False 0.24975919842042707
2023-09-02 07:06:23,112 - epoch:15, training loss:1.2095 validation loss:0.2489
Updating learning rate to 6.291715214221653e-05
Updating learning rate to 6.291715214221653e-05
train 33889
vs, vt 0.2490431915291331 0.2529297000305219
need align? ->  False 0.24975919842042707
2023-09-02 07:09:38,130 - epoch:16, training loss:1.1159 validation loss:0.2490
Updating learning rate to 5.6501903289803477e-05
Updating learning rate to 5.6501903289803477e-05
train 33889
vs, vt 0.248373678970066 0.25297731372781773
need align? ->  False 0.24975919842042707
2023-09-02 07:12:55,346 - epoch:17, training loss:1.0854 validation loss:0.2484
Updating learning rate to 4.997540849148917e-05
Updating learning rate to 4.997540849148917e-05
train 33889
vs, vt 0.2496484164148569 0.25208282381804153
need align? ->  False 0.24975919842042707
2023-09-02 07:16:13,424 - epoch:18, training loss:1.0664 validation loss:0.2496
Updating learning rate to 4.344933788275899e-05
Updating learning rate to 4.344933788275899e-05
train 33889
vs, vt 0.24840579791502518 0.2531395177356899
need align? ->  False 0.24975919842042707
2023-09-02 07:19:30,859 - epoch:19, training loss:1.0513 validation loss:0.2484
Updating learning rate to 3.703535434109692e-05
Updating learning rate to 3.703535434109692e-05
train 33889
vs, vt 0.2474161095663228 0.25218613517724653
need align? ->  False 0.24975919842042707
2023-09-02 07:22:45,260 - epoch:20, training loss:1.0422 validation loss:0.2474
Updating learning rate to 3.084320290319299e-05
Updating learning rate to 3.084320290319299e-05
train 33889
vs, vt 0.24700262253596025 0.2520186983641576
need align? ->  False 0.24975919842042707
2023-09-02 07:25:58,698 - epoch:21, training loss:1.0331 validation loss:0.2470
Updating learning rate to 2.4978832996938436e-05
Updating learning rate to 2.4978832996938436e-05
train 33889
vs, vt 0.2477277533828535 0.251685306429863
need align? ->  False 0.24975919842042707
2023-09-02 07:29:12,065 - epoch:22, training loss:1.0293 validation loss:0.2477
Updating learning rate to 1.954258561733979e-05
Updating learning rate to 1.954258561733979e-05
train 33889
vs, vt 0.24797511735761707 0.2520147025246512
need align? ->  False 0.24975919842042707
2023-09-02 07:32:28,201 - epoch:23, training loss:1.0231 validation loss:0.2480
Updating learning rate to 1.4627476464274535e-05
Updating learning rate to 1.4627476464274535e-05
train 33889
vs, vt 0.2476322938772765 0.2524503526616503
need align? ->  False 0.24975919842042707
2023-09-02 07:35:40,942 - epoch:24, training loss:1.0187 validation loss:0.2476
Updating learning rate to 1.0317604418077296e-05
Updating learning rate to 1.0317604418077296e-05
train 33889
vs, vt 0.2479753105223856 0.2521586083299057
need align? ->  False 0.24975919842042707
2023-09-02 07:38:51,443 - epoch:25, training loss:1.0169 validation loss:0.2480
Updating learning rate to 6.686712584380782e-06
Updating learning rate to 6.686712584380782e-06
train 33889
vs, vt 0.24775705931030892 0.2518109514124014
need align? ->  False 0.24975919842042707
2023-09-02 07:42:03,098 - epoch:26, training loss:1.0140 validation loss:0.2478
Updating learning rate to 3.7969265291329562e-06
Updating learning rate to 3.7969265291329562e-06
train 33889
vs, vt 0.24758379529653626 0.25183917103673925
need align? ->  False 0.24975919842042707
2023-09-02 07:45:12,371 - epoch:27, training loss:1.0130 validation loss:0.2476
Updating learning rate to 1.6976912929391648e-06
Updating learning rate to 1.6976912929391648e-06
train 33889
vs, vt 0.24755726022307167 0.2518179705789821
need align? ->  False 0.24975919842042707
2023-09-02 07:48:21,507 - epoch:28, training loss:1.0128 validation loss:0.2476
Updating learning rate to 4.2492537270863806e-07
Updating learning rate to 4.2492537270863806e-07
train 33889
vs, vt 0.24775296242230319 0.2517652923495255
need align? ->  False 0.24975919842042707
2023-09-02 07:51:32,858 - epoch:29, training loss:1.0128 validation loss:0.2478
Updating learning rate to 4.0614621390542476e-10
Updating learning rate to 4.0614621390542476e-10
check exp/ECL-PatchTST2023-09-02-06:15:54.932200/0/0.247_epoch_21.pkl  &  0.24975919842042707
2023-09-02 07:52:02,635 - [*] loss:0.3722
2023-09-02 07:52:02,670 - [*] phase 0, testing
2023-09-02 07:52:04,148 - T:336	MAE	0.387684	RMSE	0.372181	MAPE	233.159089
2023-09-02 07:52:04,149 - 336	mae	0.3877	
2023-09-02 07:52:04,149 - 336	rmse	0.3722	
2023-09-02 07:52:04,150 - 336	mape	233.1591	
----*-----
2023-09-02 07:52:33,902 - [*] loss:0.3722
2023-09-02 07:52:33,937 - [*] phase 0, testing
2023-09-02 07:52:34,745 - T:336	MAE	0.387684	RMSE	0.372181	MAPE	233.159089
2023-09-02 07:53:05,635 - [*] loss:0.3822
2023-09-02 07:53:05,671 - [*] phase 0, testing
2023-09-02 07:53:06,508 - T:336	MAE	0.400181	RMSE	0.382032	MAPE	246.659255
2023-09-02 07:53:37,222 - [*] loss:0.4360
2023-09-02 07:53:37,256 - [*] phase 0, testing
2023-09-02 07:53:38,683 - T:336	MAE	0.433198	RMSE	0.436139	MAPE	276.908755
2023-09-02 07:54:11,755 - [*] loss:0.3778
2023-09-02 07:54:11,810 - [*] phase 0, testing
2023-09-02 07:54:12,868 - T:336	MAE	0.396069	RMSE	0.377702	MAPE	247.531748
2023-09-02 07:54:46,704 - [*] loss:0.4451
2023-09-02 07:54:46,742 - [*] phase 0, testing
2023-09-02 07:54:47,757 - T:336	MAE	0.453636	RMSE	0.444961	MAPE	248.372006
2023-09-02 07:55:19,066 - [*] loss:0.4103
2023-09-02 07:55:19,134 - [*] phase 0, testing
2023-09-02 07:55:20,226 - T:336	MAE	0.422363	RMSE	0.410096	MAPE	211.081529
2023-09-02 07:55:49,882 - [*] loss:0.3751
2023-09-02 07:55:49,924 - [*] phase 0, testing
2023-09-02 07:55:51,124 - T:336	MAE	0.391604	RMSE	0.375010	MAPE	237.811041
2023-09-02 07:56:21,950 - [*] loss:0.3741
2023-09-02 07:56:21,984 - [*] phase 0, testing
2023-09-02 07:56:23,060 - T:336	MAE	0.394708	RMSE	0.373861	MAPE	219.795060
----*-----
2023-09-02 07:56:44,550 - [*] loss:0.3717
2023-09-02 07:56:44,584 - [*] phase 0, testing
2023-09-02 07:56:45,274 - T:336	MAE	0.393737	RMSE	0.371416	MAPE	222.718048
2023-09-02 07:57:15,968 - [*] loss:0.3951
2023-09-02 07:57:16,003 - [*] phase 0, testing
2023-09-02 07:57:16,622 - T:336	MAE	0.403109	RMSE	0.395150	MAPE	216.364598
2023-09-02 07:57:38,281 - [*] loss:0.3943
2023-09-02 07:57:38,317 - [*] phase 0, testing
2023-09-02 07:57:39,365 - T:336	MAE	0.399452	RMSE	0.394467	MAPE	225.762844
2023-09-02 07:57:39,366 - 336	mae	0.3995	
2023-09-02 07:57:39,366 - 336	rmse	0.3945	
2023-09-02 07:57:39,366 - 336	mape	225.7628	
2023-09-02 07:57:41,914 - logger name:exp/ECL-PatchTST2023-09-02-07:57:41.913621/ECL-PatchTST.log
2023-09-02 07:57:41,915 - params : {'loss': 'huber', 'conf': 'ECL-PatchTST', 'data_name': 'ETTm1', 'iteration': 1, 'train': 1, 'mainrs': 0, 'abl': 1, 'load': True, 'build_graph': False, 'same_init': True, 'grad_norm': False, 'refiner_residual': 0, 'root_path': '', 'exp_path': 'exp/', 'val_test_mix': False, 'lr': 0.0001, 'lradj': 'TST', 'dropout': 0.2, 'fc_dropout': 0.2, 'head_dropout': 0.0, 'patch_len': 16, 'stride': 8, 'd_ff': 256, 'd_model': 128, 'n_heads': 16, 'seq_len': 336, 'pred_len': 96, 'noise_rate': 0.5, 'device': device(type='cuda', index=1), 'test_model_path': '/Disk/fhyega/code/BASE/exp/ECL-PatchTST2023-08-26-13:08:31.837686/0/best_model.pkl', 'idx': -1, 'aligner': 1, 'always_align': 1, 'refiner': 1, 'rec_block_num': 1, 'enhance': 1, 'enhance_type': 5, 'seed': 34, 'batch_size': 128, 'share_head': 0, 'add_noise': 1, 'add_norm': 1, 'jitter_sigma': 0.4, 'slope_rate': 0.01, 'slope_range': 0.2, 'alpha': 10.0, 'beta': 1.0, 'gamma': 0.15, 'feature_jittering': 1, 'rec_intra_feature': 0, 'rec_ori': 1, 'mid_dim': 128, 'test_en': 0, 'debugger': 0, 'summary': 0, 'omega': 1.0, 'theta': 1.5, 'mask_border': 1, 'sup_weight': 10.0, 'rec_length_ratio': 0.8, 'ref_dropout': 0.0, 'ref_block_num': 2, 'add_FFN': 1, 'add_residual': 0, 'rec_all': 0, 'e_layers': 3, 'early_break': 0, 'early_stop': 10, '/* model related args*/': '//', 'model_name': 'PatchTST', 'label_len': 48, 'features': 'M', 'target': 'OT', 'graph_input': False, 'individual': False, 'd_layers': 1, 'factor': 1, 'des': 'Exp', 'padding_patch': 'end', 'revin': 1, 'affine': 0, 'subtract_last': 0, 'decomposition': 0, 'kernel_size': 25, 'output_attention': 0, 'embed_type': 0, 'activation': 'gelu', 'distil': 1, 'linear_output': 1, 'pct_start': 0.2, '/*train related args*/': '//', 'epoch': 30, '/*dataset related args*/': '//', 'save_data_path': 'data/ECL/', 'data_process': True, 'embed': 'timeF', 'freq': 'h', 'begin_phase': 0, 'end_phase': 1, 'phase_len': -1, 'val_ratio': 0.33, 'graph_size': 321, '/*strategy related args*/': '//', 'strategy': 'incremental', 'increase': False, 'detect': False, 'detect_strategy': 'feature', 'replay': False, 'replay_strategy': 'random', 'repaly_num_samples': 100, 'ewc': False, 'ewc_strategy': 'ewc', 'ewc_lambda': 0.0001, 'subgraph_train': False, 'num_hops': 2, 'logname': 'ECL-PatchTST', 'time': '2023-09-02-07:57:41.913621', 'path': 'exp/ECL-PatchTST2023-09-02-07:57:41.913621', 'num_workers': 4, 'start_train': 0, 'train_mode': 'pretrain', 'get_score': False, 'use_cm': True, 'logger': <Logger __main__ (INFO)>}
2023-09-02 07:57:41,915 - [*] phase 0 start training
0 69680
train 34129
val 11425
test 11425
2023-09-02 07:57:42,955 - [*] phase 0 Dataset load!
2023-09-02 07:57:44,081 - [*] phase 0 Training start
train 34129
2023-09-02 07:59:17,151 - epoch:0, training loss:0.1831 validation loss:0.1788
train 34129
vs, vt 0.17875255420804023 0.18399998342825308
Updating learning rate to 1.0438661460315324e-05
Updating learning rate to 1.0438661460315324e-05
train 34129
vs, vt 0.16786289173695776 0.16891605162786114
need align? ->  False 0.16891605162786114
2023-09-02 08:03:29,303 - epoch:1, training loss:9.2597 validation loss:0.1679
Updating learning rate to 2.8027297449571736e-05
Updating learning rate to 2.8027297449571736e-05
train 34129
vs, vt 0.16727419267925953 0.16666474868026043
need align? ->  True 0.16666474868026043
2023-09-02 08:06:48,952 - epoch:2, training loss:3.1051 validation loss:0.1673
Updating learning rate to 5.204727160595503e-05
Updating learning rate to 5.204727160595503e-05
train 34129
vs, vt 0.1658199754026201 0.16718198561833963
need align? ->  False 0.16666474868026043
2023-09-02 08:10:07,972 - epoch:3, training loss:2.1311 validation loss:0.1658
Updating learning rate to 7.605456385119542e-05
Updating learning rate to 7.605456385119542e-05
train 34129
vs, vt 0.16540867073668375 0.16487470443050067
need align? ->  True 0.16487470443050067
2023-09-02 08:13:27,998 - epoch:4, training loss:1.7385 validation loss:0.1654
Updating learning rate to 9.360855637921138e-05
Updating learning rate to 9.360855637921138e-05
train 34129
vs, vt 0.16421012584533956 0.16525541452897918
need align? ->  False 0.16487470443050067
2023-09-02 08:16:49,530 - epoch:5, training loss:1.3881 validation loss:0.1642
Updating learning rate to 9.99999939458629e-05
Updating learning rate to 9.99999939458629e-05
train 34129
vs, vt 0.16420223340392112 0.16214806501650147
need align? ->  True 0.16214806501650147
2023-09-02 08:20:12,488 - epoch:6, training loss:1.2109 validation loss:0.1642
Updating learning rate to 9.956902716655286e-05
Updating learning rate to 9.956902716655286e-05
train 34129
vs, vt 0.16334855573044882 0.16641229656007556
need align? ->  True 0.16214806501650147
2023-09-02 08:23:33,488 - epoch:7, training loss:1.1055 validation loss:0.1633
Updating learning rate to 9.828992401134782e-05
Updating learning rate to 9.828992401134782e-05
train 34129
vs, vt 0.15747192824880282 0.16105920068091817
need align? ->  False 0.16105920068091817
2023-09-02 08:26:56,161 - epoch:8, training loss:1.0140 validation loss:0.1575
Updating learning rate to 9.618457028986775e-05
Updating learning rate to 9.618457028986775e-05
train 34129
vs, vt 0.15994668478767077 0.15864923217644294
need align? ->  True 0.15864923217644294
2023-09-02 08:30:17,286 - epoch:9, training loss:1.0038 validation loss:0.1599
Updating learning rate to 9.32889891880015e-05
Updating learning rate to 9.32889891880015e-05
train 34129
vs, vt 0.15755778147528568 0.16122475131932232
need align? ->  False 0.15864923217644294
2023-09-02 08:33:40,546 - epoch:10, training loss:0.9661 validation loss:0.1576
Updating learning rate to 8.965272490120875e-05
Updating learning rate to 8.965272490120875e-05
train 34129
vs, vt 0.1576801550057199 0.1555116678070691
need align? ->  True 0.1555116678070691
2023-09-02 08:37:03,534 - epoch:11, training loss:0.9258 validation loss:0.1577
Updating learning rate to 8.533799491959945e-05
Updating learning rate to 8.533799491959945e-05
train 34129
vs, vt 0.15733326230612066 0.15564772805405988
need align? ->  True 0.1555116678070691
2023-09-02 08:40:31,260 - epoch:12, training loss:0.9497 validation loss:0.1573
Updating learning rate to 8.041862546942808e-05
Updating learning rate to 8.041862546942808e-05
train 34129
vs, vt 0.1566484241435925 0.1554794286688169
need align? ->  True 0.1554794286688169
2023-09-02 08:43:55,942 - epoch:13, training loss:0.9129 validation loss:0.1566
Updating learning rate to 7.497878832589398e-05
Updating learning rate to 7.497878832589398e-05
train 34129
vs, vt 0.1558178264233801 0.1560388320022159
need align? ->  True 0.1554794286688169
2023-09-02 08:47:19,918 - epoch:14, training loss:0.9333 validation loss:0.1558
Updating learning rate to 6.911156061073078e-05
Updating learning rate to 6.911156061073078e-05
train 34129
vs, vt 0.15737335131400162 0.15386734253002537
need align? ->  True 0.15386734253002537
2023-09-02 08:50:46,019 - epoch:15, training loss:0.9102 validation loss:0.1574
Updating learning rate to 6.291733221684778e-05
Updating learning rate to 6.291733221684778e-05
train 34129
vs, vt 0.15554690187176068 0.15584498420357704
need align? ->  True 0.15386734253002537
2023-09-02 08:54:14,098 - epoch:16, training loss:0.9159 validation loss:0.1555
Updating learning rate to 5.650208810942889e-05
Updating learning rate to 5.650208810942889e-05
train 34129
vs, vt 0.15456586960289215 0.1540828066981501
need align? ->  True 0.15386734253002537
2023-09-02 08:57:37,440 - epoch:17, training loss:0.9008 validation loss:0.1546
Updating learning rate to 4.9975594893793686e-05
Updating learning rate to 4.9975594893793686e-05
train 34129
vs, vt 0.1555272128019068 0.15488175989853012
need align? ->  True 0.15386734253002537
2023-09-02 09:01:02,196 - epoch:18, training loss:0.8905 validation loss:0.1555
Updating learning rate to 4.3449522678347527e-05
Updating learning rate to 4.3449522678347527e-05
train 34129
vs, vt 0.15512241700457202 0.15401709833078914
need align? ->  True 0.15386734253002537
2023-09-02 09:04:33,861 - epoch:19, training loss:0.8826 validation loss:0.1551
Updating learning rate to 3.7035534368065714e-05
Updating learning rate to 3.7035534368065714e-05
train 34129
vs, vt 0.15418264468510945 0.15407636053860188
need align? ->  True 0.15386734253002537
2023-09-02 09:08:26,781 - epoch:20, training loss:0.8759 validation loss:0.1542
Updating learning rate to 3.084337508123067e-05
Updating learning rate to 3.084337508123067e-05
train 34129
vs, vt 0.15465664925674596 0.1535412362880177
need align? ->  True 0.1535412362880177
2023-09-02 09:12:01,208 - epoch:21, training loss:0.8709 validation loss:0.1547
Updating learning rate to 2.497899438003108e-05
Updating learning rate to 2.497899438003108e-05
train 34129
vs, vt 0.15420860081083246 0.1529001594417625
need align? ->  True 0.1529001594417625
2023-09-02 09:15:23,286 - epoch:22, training loss:0.9355 validation loss:0.1542
Updating learning rate to 1.9542733444177923e-05
Updating learning rate to 1.9542733444177923e-05
train 34129
vs, vt 0.15394240108629068 0.1531591809458203
need align? ->  True 0.1529001594417625
2023-09-02 09:18:50,787 - epoch:23, training loss:0.9327 validation loss:0.1539
Updating learning rate to 1.4627608205499963e-05
Updating learning rate to 1.4627608205499963e-05
train 34129
vs, vt 0.15411252967185443 0.15366470701992513
need align? ->  True 0.1529001594417625
2023-09-02 09:22:14,901 - epoch:24, training loss:0.9285 validation loss:0.1541
Updating learning rate to 1.0317717819561129e-05
Updating learning rate to 1.0317717819561129e-05
train 34129
vs, vt 0.15365862945715586 0.15291261999971337
need align? ->  True 0.1529001594417625
2023-09-02 09:25:40,385 - epoch:25, training loss:0.9253 validation loss:0.1537
Updating learning rate to 6.686805705792195e-06
Updating learning rate to 6.686805705792195e-06
train 34129
vs, vt 0.15369292178915606 0.1530768796801567
need align? ->  True 0.1529001594417625
2023-09-02 09:29:05,757 - epoch:26, training loss:0.9236 validation loss:0.1537
Updating learning rate to 3.79699777713878e-06
Updating learning rate to 3.79699777713878e-06
train 34129
vs, vt 0.15361206146577994 0.15316164038247532
need align? ->  True 0.1529001594417625
2023-09-02 09:32:29,304 - epoch:27, training loss:0.9225 validation loss:0.1536
Updating learning rate to 1.6977394484662593e-06
Updating learning rate to 1.6977394484662593e-06
train 34129
vs, vt 0.15350112741192182 0.15300097602109114
need align? ->  True 0.1529001594417625
2023-09-02 09:35:54,637 - epoch:28, training loss:0.9225 validation loss:0.1535
Updating learning rate to 4.2494961180259127e-07
Updating learning rate to 4.2494961180259127e-07
train 34129
vs, vt 0.15353857580986288 0.15296660802430576
need align? ->  True 0.1529001594417625
2023-09-02 09:39:17,612 - epoch:29, training loss:0.9217 validation loss:0.1535
Updating learning rate to 4.0605413710007e-10
Updating learning rate to 4.0605413710007e-10
check exp/ECL-PatchTST2023-09-02-07:57:41.913621/0/0.1535_epoch_28.pkl  &  0.1529001594417625
2023-09-02 09:39:40,414 - [*] loss:0.2887
2023-09-02 09:39:40,424 - [*] phase 0, testing
2023-09-02 09:39:40,613 - T:96	MAE	0.336155	RMSE	0.290269	MAPE	213.640451
2023-09-02 09:39:40,614 - 96	mae	0.3362	
2023-09-02 09:39:40,614 - 96	rmse	0.2903	
2023-09-02 09:39:40,614 - 96	mape	213.6405	
----*-----
2023-09-02 09:40:04,760 - [*] loss:0.2887
2023-09-02 09:40:04,770 - [*] phase 0, testing
2023-09-02 09:40:04,948 - T:96	MAE	0.336155	RMSE	0.290269	MAPE	213.640451
2023-09-02 09:40:28,230 - [*] loss:0.3094
2023-09-02 09:40:28,241 - [*] phase 0, testing
2023-09-02 09:40:28,422 - T:96	MAE	0.363922	RMSE	0.311102	MAPE	238.698244
2023-09-02 09:40:53,059 - [*] loss:0.3832
2023-09-02 09:40:53,069 - [*] phase 0, testing
2023-09-02 09:40:53,247 - T:96	MAE	0.408304	RMSE	0.385361	MAPE	273.230743
2023-09-02 09:41:17,242 - [*] loss:0.2948
2023-09-02 09:41:17,252 - [*] phase 0, testing
2023-09-02 09:41:17,431 - T:96	MAE	0.345124	RMSE	0.296517	MAPE	229.606128
2023-09-02 09:41:49,972 - [*] loss:0.3674
2023-09-02 09:41:49,982 - [*] phase 0, testing
2023-09-02 09:41:50,158 - T:96	MAE	0.408699	RMSE	0.369244	MAPE	236.201715
2023-09-02 09:42:21,664 - [*] loss:0.3363
2023-09-02 09:42:21,675 - [*] phase 0, testing
2023-09-02 09:42:21,857 - T:96	MAE	0.378783	RMSE	0.337800	MAPE	202.222228
2023-09-02 09:42:52,737 - [*] loss:0.2942
2023-09-02 09:42:52,748 - [*] phase 0, testing
2023-09-02 09:42:52,937 - T:96	MAE	0.344888	RMSE	0.295814	MAPE	222.323871
2023-09-02 09:43:18,171 - [*] loss:0.3008
2023-09-02 09:43:18,181 - [*] phase 0, testing
2023-09-02 09:43:18,369 - T:96	MAE	0.355274	RMSE	0.302277	MAPE	202.850556
----*-----
2023-09-02 09:43:35,214 - [*] loss:0.2978
2023-09-02 09:43:35,223 - [*] phase 0, testing
2023-09-02 09:43:35,404 - T:96	MAE	0.352832	RMSE	0.298285	MAPE	204.908705
2023-09-02 09:43:59,639 - [*] loss:0.3029
2023-09-02 09:43:59,651 - [*] phase 0, testing
2023-09-02 09:43:59,828 - T:96	MAE	0.351979	RMSE	0.304644	MAPE	199.386990
2023-09-02 09:44:16,608 - [*] loss:0.3005
2023-09-02 09:44:16,617 - [*] phase 0, testing
2023-09-02 09:44:16,792 - T:96	MAE	0.346662	RMSE	0.301617	MAPE	201.269031
2023-09-02 09:44:16,793 - 96	mae	0.3467	
2023-09-02 09:44:16,793 - 96	rmse	0.3016	
2023-09-02 09:44:16,793 - 96	mape	201.2690	
2023-09-02 09:44:18,960 - logger name:exp/ECL-PatchTST2023-09-02-09:44:18.955974/ECL-PatchTST.log
2023-09-02 09:44:18,960 - params : {'loss': 'huber', 'conf': 'ECL-PatchTST', 'data_name': 'ETTm1', 'iteration': 1, 'train': 1, 'mainrs': 0, 'abl': 1, 'load': True, 'build_graph': False, 'same_init': True, 'grad_norm': False, 'refiner_residual': 0, 'root_path': '', 'exp_path': 'exp/', 'val_test_mix': False, 'lr': 0.0001, 'lradj': 'TST', 'dropout': 0.2, 'fc_dropout': 0.2, 'head_dropout': 0.0, 'patch_len': 16, 'stride': 8, 'd_ff': 256, 'd_model': 128, 'n_heads': 16, 'seq_len': 336, 'pred_len': 336, 'noise_rate': 0.5, 'device': device(type='cuda', index=1), 'test_model_path': '/Disk/fhyega/code/BASE/exp/ECL-PatchTST2023-08-26-13:08:31.837686/0/best_model.pkl', 'idx': -1, 'aligner': 1, 'always_align': 1, 'refiner': 1, 'rec_block_num': 1, 'enhance': 1, 'enhance_type': 5, 'seed': 34, 'batch_size': 128, 'share_head': 0, 'add_noise': 1, 'add_norm': 1, 'jitter_sigma': 0.4, 'slope_rate': 0.01, 'slope_range': 0.2, 'alpha': 10.0, 'beta': 1.0, 'gamma': 0.15, 'feature_jittering': 1, 'rec_intra_feature': 0, 'rec_ori': 1, 'mid_dim': 128, 'test_en': 0, 'debugger': 0, 'summary': 0, 'omega': 1.0, 'theta': 1.5, 'mask_border': 1, 'sup_weight': 10.0, 'rec_length_ratio': 0.8, 'ref_dropout': 0.0, 'ref_block_num': 2, 'add_FFN': 1, 'add_residual': 0, 'rec_all': 0, 'e_layers': 3, 'early_break': 0, 'early_stop': 10, '/* model related args*/': '//', 'model_name': 'PatchTST', 'label_len': 48, 'features': 'M', 'target': 'OT', 'graph_input': False, 'individual': False, 'd_layers': 1, 'factor': 1, 'des': 'Exp', 'padding_patch': 'end', 'revin': 1, 'affine': 0, 'subtract_last': 0, 'decomposition': 0, 'kernel_size': 25, 'output_attention': 0, 'embed_type': 0, 'activation': 'gelu', 'distil': 1, 'linear_output': 1, 'pct_start': 0.2, '/*train related args*/': '//', 'epoch': 30, '/*dataset related args*/': '//', 'save_data_path': 'data/ECL/', 'data_process': True, 'embed': 'timeF', 'freq': 'h', 'begin_phase': 0, 'end_phase': 1, 'phase_len': -1, 'val_ratio': 0.33, 'graph_size': 321, '/*strategy related args*/': '//', 'strategy': 'incremental', 'increase': False, 'detect': False, 'detect_strategy': 'feature', 'replay': False, 'replay_strategy': 'random', 'repaly_num_samples': 100, 'ewc': False, 'ewc_strategy': 'ewc', 'ewc_lambda': 0.0001, 'subgraph_train': False, 'num_hops': 2, 'logname': 'ECL-PatchTST', 'time': '2023-09-02-09:44:18.955974', 'path': 'exp/ECL-PatchTST2023-09-02-09:44:18.955974', 'num_workers': 4, 'start_train': 0, 'train_mode': 'pretrain', 'get_score': False, 'use_cm': True, 'logger': <Logger __main__ (INFO)>}
2023-09-02 09:44:18,961 - [*] phase 0 start training
0 69680
train 33889
val 11185
test 11185
2023-09-02 09:44:19,794 - [*] phase 0 Dataset load!
2023-09-02 09:44:20,848 - [*] phase 0 Training start
train 33889
2023-09-02 09:45:55,920 - epoch:0, training loss:0.2074 validation loss:0.2604
train 33889
vs, vt 0.26037318153645506 0.2635187496515838
Updating learning rate to 1.0438721218484657e-05
Updating learning rate to 1.0438721218484657e-05
train 33889
vs, vt 0.2552970733324235 0.255028753795407
need align? ->  True 0.255028753795407
2023-09-02 09:50:10,164 - epoch:1, training loss:8.9611 validation loss:0.2553
Updating learning rate to 2.802750441854847e-05
Updating learning rate to 2.802750441854847e-05
train 33889
vs, vt 0.2517539606090974 0.2532173475165936
need align? ->  False 0.2532173475165936
2023-09-02 09:53:32,662 - epoch:2, training loss:3.0743 validation loss:0.2518
Updating learning rate to 5.2047629950292354e-05
Updating learning rate to 5.2047629950292354e-05
train 33889
vs, vt 0.252129579809579 0.2527900416488675
need align? ->  False 0.2527900416488675
2023-09-02 09:56:52,883 - epoch:3, training loss:2.1339 validation loss:0.2521
Updating learning rate to 7.605497731655361e-05
Updating learning rate to 7.605497731655361e-05
train 33889
vs, vt 0.2524407195689326 0.2526665948416022
need align? ->  False 0.2526665948416022
2023-09-02 10:00:14,938 - epoch:4, training loss:1.6827 validation loss:0.2524
Updating learning rate to 9.3608854147054e-05
Updating learning rate to 9.3608854147054e-05
train 33889
vs, vt 0.24870479669929904 0.2529312626628036
need align? ->  False 0.2526665948416022
2023-09-02 10:03:36,771 - epoch:5, training loss:1.3893 validation loss:0.2487
Updating learning rate to 9.99999938537861e-05
Updating learning rate to 9.99999938537861e-05
train 33889
vs, vt 0.2491042418828742 0.2496945486319336
need align? ->  False 0.2496945486319336
2023-09-02 10:06:57,813 - epoch:6, training loss:1.2234 validation loss:0.2491
Updating learning rate to 9.956900274488073e-05
Updating learning rate to 9.956900274488073e-05
train 33889
vs, vt 0.2478008068759333 0.25121227596801793
need align? ->  False 0.2496945486319336
2023-09-02 10:10:20,037 - epoch:7, training loss:1.1798 validation loss:0.2478
Updating learning rate to 9.828987567794199e-05
Updating learning rate to 9.828987567794199e-05
train 33889
vs, vt 0.24575939122587442 0.25032055492258887
need align? ->  False 0.2496945486319336
2023-09-02 10:13:39,755 - epoch:8, training loss:1.0759 validation loss:0.2458
Updating learning rate to 9.618449887172618e-05
Updating learning rate to 9.618449887172618e-05
train 33889
vs, vt 0.24845703763209961 0.2505583510818807
need align? ->  False 0.2496945486319336
2023-09-02 10:17:00,478 - epoch:9, training loss:1.0209 validation loss:0.2485
Updating learning rate to 9.328889590710838e-05
Updating learning rate to 9.328889590710838e-05
train 33889
vs, vt 0.2490529352799058 0.25369724529710685
need align? ->  False 0.2496945486319336
2023-09-02 10:20:20,972 - epoch:10, training loss:0.9845 validation loss:0.2491
Updating learning rate to 8.965261135362604e-05
Updating learning rate to 8.965261135362604e-05
train 33889
vs, vt 0.2458940980193967 0.2548006877557121
need align? ->  False 0.2496945486319336
2023-09-02 10:23:40,706 - epoch:11, training loss:0.9582 validation loss:0.2459
Updating learning rate to 8.533786304815776e-05
Updating learning rate to 8.533786304815776e-05
train 33889
vs, vt 0.24676837226037274 0.2530603652227331
need align? ->  False 0.2496945486319336
2023-09-02 10:26:58,319 - epoch:12, training loss:0.9391 validation loss:0.2468
Updating learning rate to 8.041847753048434e-05
Updating learning rate to 8.041847753048434e-05
train 33889
vs, vt 0.24927303250032393 0.2541783235713162
need align? ->  False 0.2496945486319336
2023-09-02 10:30:16,970 - epoch:13, training loss:0.9222 validation loss:0.2493
Updating learning rate to 7.497862685072454e-05
Updating learning rate to 7.497862685072454e-05
train 33889
vs, vt 0.24874006148258393 0.2550908230583776
need align? ->  False 0.2496945486319336
2023-09-02 10:33:33,884 - epoch:14, training loss:0.9090 validation loss:0.2487
Updating learning rate to 6.911138836222055e-05
Updating learning rate to 6.911138836222055e-05
train 33889
vs, vt 0.2485954946076328 0.25472980813885276
need align? ->  False 0.2496945486319336
2023-09-02 10:36:52,458 - epoch:15, training loss:0.8978 validation loss:0.2486
Updating learning rate to 6.291715214221653e-05
Updating learning rate to 6.291715214221653e-05
train 33889
vs, vt 0.24785319190811028 0.25600229521197354
need align? ->  False 0.2496945486319336
2023-09-02 10:40:09,800 - epoch:16, training loss:0.8891 validation loss:0.2479
Updating learning rate to 5.6501903289803477e-05
Updating learning rate to 5.6501903289803477e-05
train 33889
vs, vt 0.2470130124129355 0.2550759131766178
need align? ->  False 0.2496945486319336
2023-09-02 10:43:25,620 - epoch:17, training loss:0.8826 validation loss:0.2470
Updating learning rate to 4.997540849148917e-05
Updating learning rate to 4.997540849148917e-05
train 33889
vs, vt 0.24640726323493503 0.2537518525919454
need align? ->  False 0.2496945486319336
2023-09-02 10:46:42,991 - epoch:18, training loss:0.8757 validation loss:0.2464
Updating learning rate to 4.344933788275899e-05
Updating learning rate to 4.344933788275899e-05
train 33889
vs, vt 0.24860479504886 0.2547564074312421
need align? ->  False 0.2496945486319336
2023-09-02 10:50:19,763 - epoch:19, training loss:0.8715 validation loss:0.2486
check exp/ECL-PatchTST2023-09-02-09:44:18.955974/0/0.2458_epoch_8.pkl  &  0.2496945486319336
2023-09-02 10:50:51,752 - [*] loss:0.3799
2023-09-02 10:50:51,798 - [*] phase 0, testing
2023-09-02 10:50:52,414 - T:336	MAE	0.390853	RMSE	0.379720	MAPE	238.780022
2023-09-02 10:50:52,415 - 336	mae	0.3909	
2023-09-02 10:50:52,416 - 336	rmse	0.3797	
2023-09-02 10:50:52,416 - 336	mape	238.7800	
----*-----
2023-09-02 10:51:22,617 - [*] loss:0.3799
2023-09-02 10:51:22,659 - [*] phase 0, testing
2023-09-02 10:51:23,352 - T:336	MAE	0.390853	RMSE	0.379720	MAPE	238.780022
2023-09-02 10:51:54,524 - [*] loss:0.3897
2023-09-02 10:51:54,568 - [*] phase 0, testing
2023-09-02 10:51:55,191 - T:336	MAE	0.403666	RMSE	0.389487	MAPE	249.664116
2023-09-02 10:52:26,503 - [*] loss:0.4088
2023-09-02 10:52:26,545 - [*] phase 0, testing
2023-09-02 10:52:27,179 - T:336	MAE	0.415673	RMSE	0.408679	MAPE	266.298342
2023-09-02 10:52:59,502 - [*] loss:0.3868
2023-09-02 10:52:59,546 - [*] phase 0, testing
2023-09-02 10:53:00,171 - T:336	MAE	0.399789	RMSE	0.386622	MAPE	257.532930
2023-09-02 10:53:35,569 - [*] loss:0.4373
2023-09-02 10:53:35,612 - [*] phase 0, testing
2023-09-02 10:53:36,230 - T:336	MAE	0.441542	RMSE	0.437063	MAPE	249.801064
2023-09-02 10:54:08,030 - [*] loss:0.4163
2023-09-02 10:54:08,075 - [*] phase 0, testing
2023-09-02 10:54:08,720 - T:336	MAE	0.423713	RMSE	0.415859	MAPE	214.877725
2023-09-02 10:54:37,938 - [*] loss:0.3826
2023-09-02 10:54:37,990 - [*] phase 0, testing
2023-09-02 10:54:38,591 - T:336	MAE	0.394946	RMSE	0.382371	MAPE	242.382455
2023-09-02 10:55:02,635 - [*] loss:0.3803
2023-09-02 10:55:02,680 - [*] phase 0, testing
2023-09-02 10:55:03,339 - T:336	MAE	0.397536	RMSE	0.379954	MAPE	221.033359
----*-----
2023-09-02 10:55:22,444 - [*] loss:0.3751
2023-09-02 10:55:22,497 - [*] phase 0, testing
2023-09-02 10:55:23,117 - T:336	MAE	0.395072	RMSE	0.374786	MAPE	223.214316
2023-09-02 10:55:54,236 - [*] loss:0.3894
2023-09-02 10:55:54,278 - [*] phase 0, testing
2023-09-02 10:55:54,879 - T:336	MAE	0.400937	RMSE	0.389148	MAPE	222.345924
2023-09-02 10:56:15,510 - [*] loss:0.3863
2023-09-02 10:56:15,551 - [*] phase 0, testing
2023-09-02 10:56:16,211 - T:336	MAE	0.398780	RMSE	0.386107	MAPE	224.876118
2023-09-02 10:56:16,213 - 336	mae	0.3988	
2023-09-02 10:56:16,213 - 336	rmse	0.3861	
2023-09-02 10:56:16,214 - 336	mape	224.8761	
2023-09-02 10:56:18,439 - logger name:exp/ECL-Informer2023-09-02-10:56:18.439395/ECL-Informer.log
2023-09-02 10:56:18,440 - params : {'loss': 'mse', 'conf': 'ECL-Informer', 'data_name': 'ETTh2', 'iteration': 1, 'train': 1, 'mainrs': 0, 'abl': 0, 'load': True, 'build_graph': False, 'same_init': True, 'grad_norm': False, 'refiner_residual': 0, 'root_path': '', 'exp_path': 'exp/', 'val_test_mix': False, 'lr': 0.0001, 'lradj': 'TST', 'dropout': 0.05, 'fc_dropout': 0.05, 'head_dropout': 0.0, 'patch_len': 16, 'stride': 8, 'd_ff': 2048, 'd_model': 512, 'n_heads': 8, 'seq_len': 96, 'pred_len': 96, 'noise_rate': 0.5, 'device': device(type='cuda', index=1), 'test_model_path': '/Disk/fhyega/code/BASE/exp/ECL-PatchTST2023-08-26-13:08:31.837686/0/best_model.pkl', 'idx': -1, 'aligner': 0, 'always_align': 1, 'refiner': 0, 'rec_block_num': 1, 'enhance': 0, 'enhance_type': 5, 'seed': 34, 'batch_size': 64, 'share_head': 0, 'add_noise': 1, 'add_norm': 0, 'jitter_sigma': 0.4, 'slope_rate': 0.01, 'slope_range': 0.2, 'alpha': 10.0, 'beta': 1.0, 'gamma': 0.15, 'feature_jittering': 1, 'rec_intra_feature': 0, 'rec_ori': 1, 'mid_dim': 128, 'test_en': 0, 'debugger': 0, 'summary': 0, 'omega': 1.0, 'theta': 1.5, 'mask_border': 1, 'sup_weight': 10.0, 'rec_length_ratio': 0.8, 'ref_dropout': 0.0, 'ref_block_num': 2, 'add_FFN': 0, 'add_residual': 0, 'rec_all': 0, 'e_layers': 2, 'early_break': 0, 'early_stop': 10, '/* model related args*/': '//', 'model_name': 'informer', 'label_len': 48, 'features': 'M', 'target': 'OT', 'graph_input': False, 'individual': False, 'd_layers': 1, 'factor': 3, 'des': 'Exp', 'padding_patch': 'end', 'revin': 1, 'affine': 0, 'subtract_last': 0, 'decomposition': 0, 'kernel_size': 25, 'output_attention': 0, 'embed_type': 0, 'activation': 'gelu', 'distil': 1, 'linear_output': 0, 'pct_start': 0.3, '/*train related args*/': '//', 'epoch': 30, '/*dataset related args*/': '//', 'save_data_path': 'data/ECL/', 'data_process': False, 'embed': 'timeF', 'freq': 'h', 'begin_phase': 0, 'end_phase': 1, 'phase_len': 26304, 'val_ratio': 0.33, 'graph_size': 321, '/*strategy related args*/': '//', 'strategy': 'incremental', 'increase': False, 'detect': False, 'detect_strategy': 'feature', 'replay': False, 'replay_strategy': 'random', 'repaly_num_samples': 100, 'ewc': False, 'ewc_strategy': 'ewc', 'ewc_lambda': 0.0001, 'subgraph_train': False, 'num_hops': 2, 'logname': 'ECL-Informer', 'time': '2023-09-02-10:56:18.439395', 'path': 'exp/ECL-Informer2023-09-02-10:56:18.439395', 'num_workers': 4, 'start_train': 0, 'train_mode': 'pretrain', 'get_score': False, 'use_cm': True, 'logger': <Logger __main__ (INFO)>}
2023-09-02 10:56:18,440 - [*] phase 0 start training
train 8449
val 2785
test 2785
2023-09-02 10:56:18,515 - [*] phase 0 Dataset load!
dropout 0.05
dropout 0.05
2023-09-02 10:56:20,024 - [*] phase 0 Training start
train 8449
2023-09-02 10:57:18,650 - epoch:0, training loss:0.7375 validation loss:0.6771
train 8449
vs, vt 0.6771121228283102 0.9801671003753488
Updating learning rate to 6.899583955836529e-06
Updating learning rate to 6.899583955836529e-06
train 8449
vs, vt 0.9045236588201739 0.8034525838765231
need align? ->  True 0.8034525838765231
2023-09-02 10:59:14,893 - epoch:1, training loss:0.5206 validation loss:0.9045
Updating learning rate to 1.5248019693473428e-05
Updating learning rate to 1.5248019693473428e-05
train 8449
vs, vt 1.130583875558593 0.802021035077897
need align? ->  True 0.802021035077897
2023-09-02 11:00:42,761 - epoch:2, training loss:0.4447 validation loss:1.1306
Updating learning rate to 2.8036682616194676e-05
Updating learning rate to 2.8036682616194676e-05
train 8449
vs, vt 1.1808704869313673 0.8843700811266899
need align? ->  True 0.802021035077897
2023-09-02 11:02:07,190 - epoch:3, training loss:0.3852 validation loss:1.1809
Updating learning rate to 4.3720497647861784e-05
Updating learning rate to 4.3720497647861784e-05
train 8449
vs, vt 1.3046811426227742 0.8676885247907855
need align? ->  True 0.802021035077897
2023-09-02 11:03:40,116 - epoch:4, training loss:0.3412 validation loss:1.3047
Updating learning rate to 6.040460902046933e-05
Updating learning rate to 6.040460902046933e-05
train 8449
vs, vt 1.1686235876245932 0.8595960075882348
need align? ->  True 0.802021035077897
2023-09-02 11:05:02,524 - epoch:5, training loss:0.3113 validation loss:1.1686
Updating learning rate to 7.607330916512556e-05
Updating learning rate to 7.607330916512556e-05
train 8449
vs, vt 1.4240434267981485 0.7221174348484386
need align? ->  True 0.7221174348484386
2023-09-02 11:06:37,232 - epoch:6, training loss:0.2881 validation loss:1.4240
Updating learning rate to 8.883356843398634e-05
Updating learning rate to 8.883356843398634e-05
train 8449
vs, vt 1.294931642033837 0.7967825020578775
need align? ->  True 0.7221174348484386
2023-09-02 11:08:01,549 - epoch:7, training loss:0.2636 validation loss:1.2949
Updating learning rate to 9.714374336670574e-05
Updating learning rate to 9.714374336670574e-05
train 8449
vs, vt 1.0977222347124056 0.6773290945725008
need align? ->  True 0.6773290945725008
2023-09-02 11:09:36,302 - epoch:8, training loss:0.2479 validation loss:1.0977
Updating learning rate to 9.999996788917095e-05
Updating learning rate to 9.999996788917095e-05
train 8449
vs, vt 1.3426509601148693 0.7260546013712883
need align? ->  True 0.6773290945725008
2023-09-02 11:11:02,910 - epoch:9, training loss:0.2365 validation loss:1.3427
Updating learning rate to 9.943306611983748e-05
Updating learning rate to 9.943306611983748e-05
train 8449
vs, vt 1.3726105077022857 0.7564601681449197
need align? ->  True 0.6773290945725008
2023-09-02 11:12:36,932 - epoch:10, training loss:0.2204 validation loss:1.3726
Updating learning rate to 9.776191580673917e-05
Updating learning rate to 9.776191580673917e-05
train 8449
vs, vt 1.2526109144091606 0.6804880614985119
need align? ->  True 0.6773290945725008
2023-09-02 11:14:11,613 - epoch:11, training loss:0.2113 validation loss:1.2526
dropout 0.05
dropout 0.05
check exp/ECL-Informer2023-09-02-10:56:18.439395/0/0.6771_epoch_0.pkl  &  0.6773290945725008
2023-09-02 11:14:19,879 - [*] loss:1.6356
2023-09-02 11:14:19,883 - [*] phase 0, testing
2023-09-02 11:14:19,918 - T:96	MAE	1.055340	RMSE	1.643738	MAPE	497.491980
2023-09-02 11:14:19,919 - 96	mae	1.0553	
2023-09-02 11:14:19,919 - 96	rmse	1.6437	
2023-09-02 11:14:19,919 - 96	mape	497.4920	
2023-09-02 11:14:28,355 - [*] loss:1.6357
2023-09-02 11:14:28,360 - [*] phase 0, testing
2023-09-02 11:14:28,399 - T:96	MAE	1.055122	RMSE	1.643880	MAPE	496.516037
2023-09-02 11:14:30,787 - logger name:exp/ECL-Informer2023-09-02-11:14:30.787187/ECL-Informer.log
2023-09-02 11:14:30,787 - params : {'loss': 'mse', 'conf': 'ECL-Informer', 'data_name': 'ETTh2', 'iteration': 1, 'train': 1, 'mainrs': 0, 'abl': 0, 'load': True, 'build_graph': False, 'same_init': True, 'grad_norm': False, 'refiner_residual': 0, 'root_path': '', 'exp_path': 'exp/', 'val_test_mix': False, 'lr': 0.0001, 'lradj': 'TST', 'dropout': 0.05, 'fc_dropout': 0.05, 'head_dropout': 0.0, 'patch_len': 16, 'stride': 8, 'd_ff': 2048, 'd_model': 512, 'n_heads': 8, 'seq_len': 96, 'pred_len': 192, 'noise_rate': 0.5, 'device': device(type='cuda', index=1), 'test_model_path': '/Disk/fhyega/code/BASE/exp/ECL-PatchTST2023-08-26-13:08:31.837686/0/best_model.pkl', 'idx': -1, 'aligner': 0, 'always_align': 1, 'refiner': 0, 'rec_block_num': 1, 'enhance': 0, 'enhance_type': 5, 'seed': 34, 'batch_size': 64, 'share_head': 0, 'add_noise': 1, 'add_norm': 0, 'jitter_sigma': 0.4, 'slope_rate': 0.01, 'slope_range': 0.2, 'alpha': 10.0, 'beta': 1.0, 'gamma': 0.15, 'feature_jittering': 1, 'rec_intra_feature': 0, 'rec_ori': 1, 'mid_dim': 128, 'test_en': 0, 'debugger': 0, 'summary': 0, 'omega': 1.0, 'theta': 1.5, 'mask_border': 1, 'sup_weight': 10.0, 'rec_length_ratio': 0.8, 'ref_dropout': 0.0, 'ref_block_num': 2, 'add_FFN': 0, 'add_residual': 0, 'rec_all': 0, 'e_layers': 2, 'early_break': 0, 'early_stop': 10, '/* model related args*/': '//', 'model_name': 'informer', 'label_len': 48, 'features': 'M', 'target': 'OT', 'graph_input': False, 'individual': False, 'd_layers': 1, 'factor': 3, 'des': 'Exp', 'padding_patch': 'end', 'revin': 1, 'affine': 0, 'subtract_last': 0, 'decomposition': 0, 'kernel_size': 25, 'output_attention': 0, 'embed_type': 0, 'activation': 'gelu', 'distil': 1, 'linear_output': 0, 'pct_start': 0.3, '/*train related args*/': '//', 'epoch': 30, '/*dataset related args*/': '//', 'save_data_path': 'data/ECL/', 'data_process': False, 'embed': 'timeF', 'freq': 'h', 'begin_phase': 0, 'end_phase': 1, 'phase_len': 26304, 'val_ratio': 0.33, 'graph_size': 321, '/*strategy related args*/': '//', 'strategy': 'incremental', 'increase': False, 'detect': False, 'detect_strategy': 'feature', 'replay': False, 'replay_strategy': 'random', 'repaly_num_samples': 100, 'ewc': False, 'ewc_strategy': 'ewc', 'ewc_lambda': 0.0001, 'subgraph_train': False, 'num_hops': 2, 'logname': 'ECL-Informer', 'time': '2023-09-02-11:14:30.787187', 'path': 'exp/ECL-Informer2023-09-02-11:14:30.787187', 'num_workers': 4, 'start_train': 0, 'train_mode': 'pretrain', 'get_score': False, 'use_cm': True, 'logger': <Logger __main__ (INFO)>}
2023-09-02 11:14:30,788 - [*] phase 0 start training
train 8353
val 2689
test 2689
2023-09-02 11:14:30,859 - [*] phase 0 Dataset load!
dropout 0.05
dropout 0.05
2023-09-02 11:14:32,314 - [*] phase 0 Training start
train 8353
2023-09-02 11:15:44,893 - epoch:0, training loss:0.7777 validation loss:0.8207
train 8353
vs, vt 0.8207085188045058 1.1112887498944304
Updating learning rate to 6.899658353790513e-06
Updating learning rate to 6.899658353790513e-06
train 8353
vs, vt 1.2526877664549405 0.9430792498034101
need align? ->  True 0.9430792498034101
2023-09-02 11:18:04,862 - epoch:1, training loss:0.5610 validation loss:1.2527
Updating learning rate to 1.5248299308132546e-05
Updating learning rate to 1.5248299308132546e-05
train 8353
vs, vt 1.5029382449249888 1.0148403287626977
need align? ->  True 0.9430792498034101
2023-09-02 11:19:49,920 - epoch:2, training loss:0.4831 validation loss:1.5029
Updating learning rate to 2.803724759277384e-05
Updating learning rate to 2.803724759277384e-05
train 8353
vs, vt 1.4919476370478786 1.045979623877725
need align? ->  True 0.9430792498034101
2023-09-02 11:21:24,812 - epoch:3, training loss:0.4246 validation loss:1.4919
Updating learning rate to 4.372135401064124e-05
Updating learning rate to 4.372135401064124e-05
train 8353
vs, vt 1.1738733354696007 1.023481400900109
need align? ->  True 0.9430792498034101
2023-09-02 11:23:09,619 - epoch:4, training loss:0.3815 validation loss:1.1739
Updating learning rate to 6.0405678970221905e-05
Updating learning rate to 6.0405678970221905e-05
train 8353
vs, vt 1.1367132081541904 0.954389049563297
need align? ->  True 0.9430792498034101
2023-09-02 11:24:44,596 - epoch:5, training loss:0.3412 validation loss:1.1367
Updating learning rate to 7.60744373779157e-05
Updating learning rate to 7.60744373779157e-05
train 8353
vs, vt 1.401980927170709 1.064640336951544
need align? ->  True 0.9430792498034101
2023-09-02 11:26:27,010 - epoch:6, training loss:0.3136 validation loss:1.4020
Updating learning rate to 8.883454397495618e-05
Updating learning rate to 8.883454397495618e-05
train 8353
vs, vt 1.4079712896152985 1.0685478819664134
need align? ->  True 0.9430792498034101
2023-09-02 11:28:04,158 - epoch:7, training loss:0.2916 validation loss:1.4080
Updating learning rate to 9.714433419095309e-05
Updating learning rate to 9.714433419095309e-05
train 8353
vs, vt 1.5405270557763964 1.0943996934003608
need align? ->  True 0.9430792498034101
2023-09-02 11:29:47,439 - epoch:8, training loss:0.2688 validation loss:1.5405
Updating learning rate to 9.999996689354536e-05
Updating learning rate to 9.999996689354536e-05
train 8353
vs, vt 1.571611679917158 1.1649252190146335
need align? ->  True 0.9430792498034101
2023-09-02 11:31:21,842 - epoch:9, training loss:0.2553 validation loss:1.5716
Updating learning rate to 9.943293520195718e-05
Updating learning rate to 9.943293520195718e-05
train 8353
vs, vt 1.3929446495549624 1.0982196119635603
need align? ->  True 0.9430792498034101
2023-09-02 11:33:03,164 - epoch:10, training loss:0.2444 validation loss:1.3929
Updating learning rate to 9.776165789109328e-05
Updating learning rate to 9.776165789109328e-05
train 8353
vs, vt 1.7485388642133668 1.0010338429101677
need align? ->  True 0.9430792498034101
2023-09-02 11:34:38,910 - epoch:11, training loss:0.2407 validation loss:1.7485
dropout 0.05
dropout 0.05
check exp/ECL-Informer2023-09-02-11:14:30.787187/0/0.8207_epoch_0.pkl  &  0.9430792498034101
2023-09-02 11:34:49,081 - [*] loss:2.0185
2023-09-02 11:34:49,090 - [*] phase 0, testing
2023-09-02 11:34:49,169 - T:192	MAE	1.183130	RMSE	2.034308	MAPE	578.793764
2023-09-02 11:34:49,169 - 192	mae	1.1831	
2023-09-02 11:34:49,170 - 192	rmse	2.0343	
2023-09-02 11:34:49,170 - 192	mape	578.7938	
2023-09-02 11:35:00,036 - [*] loss:2.0201
2023-09-02 11:35:00,045 - [*] phase 0, testing
2023-09-02 11:35:00,120 - T:192	MAE	1.183403	RMSE	2.036209	MAPE	579.150105
2023-09-02 11:35:02,579 - logger name:exp/ECL-Informer2023-09-02-11:35:02.578074/ECL-Informer.log
2023-09-02 11:35:02,579 - params : {'loss': 'mse', 'conf': 'ECL-Informer', 'data_name': 'ETTh2', 'iteration': 1, 'train': 1, 'mainrs': 0, 'abl': 0, 'load': True, 'build_graph': False, 'same_init': True, 'grad_norm': False, 'refiner_residual': 0, 'root_path': '', 'exp_path': 'exp/', 'val_test_mix': False, 'lr': 0.0001, 'lradj': 'TST', 'dropout': 0.05, 'fc_dropout': 0.05, 'head_dropout': 0.0, 'patch_len': 16, 'stride': 8, 'd_ff': 2048, 'd_model': 512, 'n_heads': 8, 'seq_len': 96, 'pred_len': 336, 'noise_rate': 0.5, 'device': device(type='cuda', index=1), 'test_model_path': '/Disk/fhyega/code/BASE/exp/ECL-PatchTST2023-08-26-13:08:31.837686/0/best_model.pkl', 'idx': -1, 'aligner': 0, 'always_align': 1, 'refiner': 0, 'rec_block_num': 1, 'enhance': 0, 'enhance_type': 5, 'seed': 34, 'batch_size': 64, 'share_head': 0, 'add_noise': 1, 'add_norm': 0, 'jitter_sigma': 0.4, 'slope_rate': 0.01, 'slope_range': 0.2, 'alpha': 10.0, 'beta': 1.0, 'gamma': 0.15, 'feature_jittering': 1, 'rec_intra_feature': 0, 'rec_ori': 1, 'mid_dim': 128, 'test_en': 0, 'debugger': 0, 'summary': 0, 'omega': 1.0, 'theta': 1.5, 'mask_border': 1, 'sup_weight': 10.0, 'rec_length_ratio': 0.8, 'ref_dropout': 0.0, 'ref_block_num': 2, 'add_FFN': 0, 'add_residual': 0, 'rec_all': 0, 'e_layers': 2, 'early_break': 0, 'early_stop': 10, '/* model related args*/': '//', 'model_name': 'informer', 'label_len': 48, 'features': 'M', 'target': 'OT', 'graph_input': False, 'individual': False, 'd_layers': 1, 'factor': 3, 'des': 'Exp', 'padding_patch': 'end', 'revin': 1, 'affine': 0, 'subtract_last': 0, 'decomposition': 0, 'kernel_size': 25, 'output_attention': 0, 'embed_type': 0, 'activation': 'gelu', 'distil': 1, 'linear_output': 0, 'pct_start': 0.3, '/*train related args*/': '//', 'epoch': 30, '/*dataset related args*/': '//', 'save_data_path': 'data/ECL/', 'data_process': False, 'embed': 'timeF', 'freq': 'h', 'begin_phase': 0, 'end_phase': 1, 'phase_len': 26304, 'val_ratio': 0.33, 'graph_size': 321, '/*strategy related args*/': '//', 'strategy': 'incremental', 'increase': False, 'detect': False, 'detect_strategy': 'feature', 'replay': False, 'replay_strategy': 'random', 'repaly_num_samples': 100, 'ewc': False, 'ewc_strategy': 'ewc', 'ewc_lambda': 0.0001, 'subgraph_train': False, 'num_hops': 2, 'logname': 'ECL-Informer', 'time': '2023-09-02-11:35:02.578074', 'path': 'exp/ECL-Informer2023-09-02-11:35:02.578074', 'num_workers': 4, 'start_train': 0, 'train_mode': 'pretrain', 'get_score': False, 'use_cm': True, 'logger': <Logger __main__ (INFO)>}
2023-09-02 11:35:02,580 - [*] phase 0 start training
train 8209
val 2545
test 2545
2023-09-02 11:35:02,654 - [*] phase 0 Dataset load!
dropout 0.05
dropout 0.05
2023-09-02 11:35:04,159 - [*] phase 0 Training start
train 8209
2023-09-02 11:36:19,788 - epoch:0, training loss:0.8033 validation loss:0.8742
train 8209
vs, vt 0.8742229998111725 1.1090059861540795
Updating learning rate to 6.899735079669026e-06
Updating learning rate to 6.899735079669026e-06
train 8209
vs, vt 1.0544296354055405 0.9844464108347892
need align? ->  True 0.9844464108347892
2023-09-02 11:39:03,720 - epoch:1, training loss:0.6018 validation loss:1.0544
Updating learning rate to 1.5248587671498447e-05
Updating learning rate to 1.5248587671498447e-05
train 8209
vs, vt 1.2195355996489525 1.0024412747472524
need align? ->  True 0.9844464108347892
2023-09-02 11:40:54,687 - epoch:2, training loss:0.5207 validation loss:1.2195
Updating learning rate to 2.80378302448419e-05
Updating learning rate to 2.80378302448419e-05
train 8209
vs, vt 1.198349029570818 1.0940910004079343
need align? ->  True 0.9844464108347892
2023-09-02 11:42:52,027 - epoch:3, training loss:0.4564 validation loss:1.1983
Updating learning rate to 4.3722237160852676e-05
Updating learning rate to 4.3722237160852676e-05
train 8209
vs, vt 1.0619576916098594 1.014008253067732
need align? ->  True 0.9844464108347892
2023-09-02 11:44:50,716 - epoch:4, training loss:0.4087 validation loss:1.0620
Updating learning rate to 6.040678238044081e-05
Updating learning rate to 6.040678238044081e-05
train 8209
vs, vt 1.041674169525504 1.1312120638787746
need align? ->  True 0.9844464108347892
2023-09-02 11:46:44,545 - epoch:5, training loss:0.3646 validation loss:1.0417
Updating learning rate to 7.607560085937446e-05
Updating learning rate to 7.607560085937446e-05
train 8209
vs, vt 1.0819820299744607 1.2047042176127434
need align? ->  True 0.9844464108347892
2023-09-02 11:48:44,371 - epoch:6, training loss:0.3360 validation loss:1.0820
Updating learning rate to 8.883554998930651e-05
Updating learning rate to 8.883554998930651e-05
train 8209
vs, vt 0.9560966104269027 1.2016295425593853
need align? ->  False 0.9844464108347892
2023-09-02 11:50:37,986 - epoch:7, training loss:0.3128 validation loss:0.9561
Updating learning rate to 9.714494343245132e-05
Updating learning rate to 9.714494343245132e-05
train 8209
vs, vt 1.055945460870862 1.0975894249975682
need align? ->  True 0.9844464108347892
2023-09-02 11:52:37,841 - epoch:8, training loss:0.2930 validation loss:1.0559
Updating learning rate to 9.999996585088614e-05
Updating learning rate to 9.999996585088614e-05
train 8209
vs, vt 1.12154380120337 1.1340142257511616
need align? ->  True 0.9844464108347892
2023-09-02 11:54:37,994 - epoch:9, training loss:0.2788 validation loss:1.1215
Updating learning rate to 9.943280017715336e-05
Updating learning rate to 9.943280017715336e-05
train 8209
vs, vt 1.1165852479636669 1.0851231075823307
need align? ->  True 0.9844464108347892
2023-09-02 11:56:31,100 - epoch:10, training loss:0.2657 validation loss:1.1166
Updating learning rate to 9.776139190037583e-05
Updating learning rate to 9.776139190037583e-05
train 8209
vs, vt 1.1213218048214912 1.117451597377658
need align? ->  True 0.9844464108347892
2023-09-02 11:58:35,600 - epoch:11, training loss:0.2531 validation loss:1.1213
dropout 0.05
dropout 0.05
check exp/ECL-Informer2023-09-02-11:35:02.578074/0/0.8742_epoch_0.pkl  &  0.9844464108347892
2023-09-02 11:58:44,645 - [*] loss:2.1783
2023-09-02 11:58:44,659 - [*] phase 0, testing
2023-09-02 11:58:45,149 - T:336	MAE	1.234415	RMSE	2.175215	MAPE	655.687284
2023-09-02 11:58:45,149 - 336	mae	1.2344	
2023-09-02 11:58:45,149 - 336	rmse	2.1752	
2023-09-02 11:58:45,149 - 336	mape	655.6873	
2023-09-02 11:58:55,365 - [*] loss:2.1779
2023-09-02 11:58:55,378 - [*] phase 0, testing
2023-09-02 11:58:55,508 - T:336	MAE	1.234454	RMSE	2.174805	MAPE	655.749750
2023-09-02 11:58:58,144 - logger name:exp/ECL-Informer2023-09-02-11:58:58.143633/ECL-Informer.log
2023-09-02 11:58:58,144 - params : {'loss': 'mse', 'conf': 'ECL-Informer', 'data_name': 'ETTh2', 'iteration': 1, 'train': 1, 'mainrs': 0, 'abl': 0, 'load': True, 'build_graph': False, 'same_init': True, 'grad_norm': False, 'refiner_residual': 0, 'root_path': '', 'exp_path': 'exp/', 'val_test_mix': False, 'lr': 0.0001, 'lradj': 'TST', 'dropout': 0.05, 'fc_dropout': 0.05, 'head_dropout': 0.0, 'patch_len': 16, 'stride': 8, 'd_ff': 2048, 'd_model': 512, 'n_heads': 8, 'seq_len': 96, 'pred_len': 720, 'noise_rate': 0.5, 'device': device(type='cuda', index=1), 'test_model_path': '/Disk/fhyega/code/BASE/exp/ECL-PatchTST2023-08-26-13:08:31.837686/0/best_model.pkl', 'idx': -1, 'aligner': 0, 'always_align': 1, 'refiner': 0, 'rec_block_num': 1, 'enhance': 0, 'enhance_type': 5, 'seed': 34, 'batch_size': 64, 'share_head': 0, 'add_noise': 1, 'add_norm': 0, 'jitter_sigma': 0.4, 'slope_rate': 0.01, 'slope_range': 0.2, 'alpha': 10.0, 'beta': 1.0, 'gamma': 0.15, 'feature_jittering': 1, 'rec_intra_feature': 0, 'rec_ori': 1, 'mid_dim': 128, 'test_en': 0, 'debugger': 0, 'summary': 0, 'omega': 1.0, 'theta': 1.5, 'mask_border': 1, 'sup_weight': 10.0, 'rec_length_ratio': 0.8, 'ref_dropout': 0.0, 'ref_block_num': 2, 'add_FFN': 0, 'add_residual': 0, 'rec_all': 0, 'e_layers': 2, 'early_break': 0, 'early_stop': 10, '/* model related args*/': '//', 'model_name': 'informer', 'label_len': 48, 'features': 'M', 'target': 'OT', 'graph_input': False, 'individual': False, 'd_layers': 1, 'factor': 3, 'des': 'Exp', 'padding_patch': 'end', 'revin': 1, 'affine': 0, 'subtract_last': 0, 'decomposition': 0, 'kernel_size': 25, 'output_attention': 0, 'embed_type': 0, 'activation': 'gelu', 'distil': 1, 'linear_output': 0, 'pct_start': 0.3, '/*train related args*/': '//', 'epoch': 30, '/*dataset related args*/': '//', 'save_data_path': 'data/ECL/', 'data_process': False, 'embed': 'timeF', 'freq': 'h', 'begin_phase': 0, 'end_phase': 1, 'phase_len': 26304, 'val_ratio': 0.33, 'graph_size': 321, '/*strategy related args*/': '//', 'strategy': 'incremental', 'increase': False, 'detect': False, 'detect_strategy': 'feature', 'replay': False, 'replay_strategy': 'random', 'repaly_num_samples': 100, 'ewc': False, 'ewc_strategy': 'ewc', 'ewc_lambda': 0.0001, 'subgraph_train': False, 'num_hops': 2, 'logname': 'ECL-Informer', 'time': '2023-09-02-11:58:58.143633', 'path': 'exp/ECL-Informer2023-09-02-11:58:58.143633', 'num_workers': 4, 'start_train': 0, 'train_mode': 'pretrain', 'get_score': False, 'use_cm': True, 'logger': <Logger __main__ (INFO)>}
2023-09-02 11:58:58,144 - [*] phase 0 start training
train 7825
val 2161
test 2161
2023-09-02 11:58:58,215 - [*] phase 0 Dataset load!
dropout 0.05
dropout 0.05
2023-09-02 11:58:59,825 - [*] phase 0 Training start
train 7825
2023-09-02 12:00:46,580 - epoch:0, training loss:0.8655 validation loss:1.0976
train 7825
vs, vt 1.0976150053388931 1.2119556893320644
Updating learning rate to 6.8999803712766215e-06
Updating learning rate to 6.8999803712766215e-06
train 7825
vs, vt 1.2414101186920614 1.1374379598042543
need align? ->  True 1.1374379598042543
2023-09-02 12:04:33,618 - epoch:1, training loss:0.6787 validation loss:1.2414
Updating learning rate to 1.5249509562031895e-05
Updating learning rate to 1.5249509562031895e-05
train 7825
vs, vt 1.3223538644173567 1.2316012882134493
need align? ->  True 1.1374379598042543
2023-09-02 12:07:17,865 - epoch:2, training loss:0.5742 validation loss:1.3224
Updating learning rate to 2.8039692957157876e-05
Updating learning rate to 2.8039692957157876e-05
train 7825
vs, vt 1.2921197212794249 1.2785518116810743
need align? ->  True 1.1374379598042543
2023-09-02 12:09:53,179 - epoch:3, training loss:0.5135 validation loss:1.2921
Updating learning rate to 4.372506052370064e-05
Updating learning rate to 4.372506052370064e-05
train 7825
vs, vt 1.4056278467178345 1.2852556670413298
need align? ->  True 1.1374379598042543
2023-09-02 12:12:27,721 - epoch:4, training loss:0.4631 validation loss:1.4056
Updating learning rate to 6.0410309842525476e-05
Updating learning rate to 6.0410309842525476e-05
train 7825
vs, vt 1.4931918803383322 1.3408679892035091
need align? ->  True 1.1374379598042543
2023-09-02 12:15:09,891 - epoch:5, training loss:0.4250 validation loss:1.4932
Updating learning rate to 7.607932026719707e-05
Updating learning rate to 7.607932026719707e-05
train 7825
vs, vt 1.4592786571558785 1.4135117145145641
need align? ->  True 1.1374379598042543
2023-09-02 12:17:45,788 - epoch:6, training loss:0.3917 validation loss:1.4593
Updating learning rate to 8.883876585317888e-05
Updating learning rate to 8.883876585317888e-05
train 7825
vs, vt 1.590067998451345 1.378616147181567
need align? ->  True 1.1374379598042543
2023-09-02 12:20:30,790 - epoch:7, training loss:0.3618 validation loss:1.5901
Updating learning rate to 9.714689069431593e-05
Updating learning rate to 9.714689069431593e-05
train 7825
vs, vt 1.5562275209847618 1.3284426366581636
need align? ->  True 1.1374379598042543
2023-09-02 12:23:08,368 - epoch:8, training loss:0.3406 validation loss:1.5562
Updating learning rate to 9.99999624093607e-05
Updating learning rate to 9.99999624093607e-05
train 7825
vs, vt 1.5256257758421057 1.337885676061406
need align? ->  True 1.1374379598042543
2023-09-02 12:25:53,926 - epoch:9, training loss:0.3233 validation loss:1.5256
Updating learning rate to 9.943236843328111e-05
Updating learning rate to 9.943236843328111e-05
train 7825
vs, vt 1.6269079692223494 1.3403557872070986
need align? ->  True 1.1374379598042543
2023-09-02 12:28:29,839 - epoch:10, training loss:0.3066 validation loss:1.6269
Updating learning rate to 9.776054149860142e-05
Updating learning rate to 9.776054149860142e-05
train 7825
vs, vt 1.5623547575053047 1.3210942263112349
need align? ->  True 1.1374379598042543
2023-09-02 12:31:15,744 - epoch:11, training loss:0.2906 validation loss:1.5624
dropout 0.05
dropout 0.05
check exp/ECL-Informer2023-09-02-11:58:58.143633/0/1.0976_epoch_0.pkl  &  1.1374379598042543
2023-09-02 12:31:25,496 - [*] loss:2.4817
2023-09-02 12:31:25,511 - [*] phase 0, testing
2023-09-02 12:31:25,738 - T:720	MAE	1.345516	RMSE	2.479489	MAPE	790.438652
2023-09-02 12:31:25,738 - 720	mae	1.3455	
2023-09-02 12:31:25,739 - 720	rmse	2.4795	
2023-09-02 12:31:25,739 - 720	mape	790.4387	
2023-09-02 12:31:35,544 - [*] loss:2.4811
2023-09-02 12:31:35,559 - [*] phase 0, testing
2023-09-02 12:31:35,786 - T:720	MAE	1.345254	RMSE	2.478865	MAPE	790.412712
2023-09-02 12:31:38,039 - logger name:exp/ECL-Informer2023-09-02-12:31:38.039106/ECL-Informer.log
2023-09-02 12:31:38,039 - params : {'loss': 'huber', 'conf': 'ECL-Informer', 'data_name': 'ETTh2', 'iteration': 1, 'train': 1, 'mainrs': 0, 'abl': 0, 'load': True, 'build_graph': False, 'same_init': True, 'grad_norm': False, 'refiner_residual': 0, 'root_path': '', 'exp_path': 'exp/', 'val_test_mix': False, 'lr': 0.0001, 'lradj': 'TST', 'dropout': 0.05, 'fc_dropout': 0.05, 'head_dropout': 0.0, 'patch_len': 16, 'stride': 8, 'd_ff': 2048, 'd_model': 512, 'n_heads': 8, 'seq_len': 96, 'pred_len': 96, 'noise_rate': 0.5, 'device': device(type='cuda', index=1), 'test_model_path': '/Disk/fhyega/code/BASE/exp/ECL-PatchTST2023-08-26-13:08:31.837686/0/best_model.pkl', 'idx': -1, 'aligner': 1, 'always_align': 1, 'refiner': 1, 'rec_block_num': 1, 'enhance': 1, 'enhance_type': 5, 'seed': 34, 'batch_size': 64, 'share_head': 0, 'add_noise': 1, 'add_norm': 0, 'jitter_sigma': 0.4, 'slope_rate': 0.01, 'slope_range': 0.2, 'alpha': 10.0, 'beta': 1.0, 'gamma': 0.15, 'feature_jittering': 1, 'rec_intra_feature': 0, 'rec_ori': 1, 'mid_dim': 128, 'test_en': 0, 'debugger': 0, 'summary': 0, 'omega': 1.0, 'theta': 1.5, 'mask_border': 1, 'sup_weight': 10.0, 'rec_length_ratio': 0.8, 'ref_dropout': 0.0, 'ref_block_num': 2, 'add_FFN': 0, 'add_residual': 0, 'rec_all': 0, 'e_layers': 2, 'early_break': 0, 'early_stop': 10, '/* model related args*/': '//', 'model_name': 'informer', 'label_len': 48, 'features': 'M', 'target': 'OT', 'graph_input': False, 'individual': False, 'd_layers': 1, 'factor': 3, 'des': 'Exp', 'padding_patch': 'end', 'revin': 1, 'affine': 0, 'subtract_last': 0, 'decomposition': 0, 'kernel_size': 25, 'output_attention': 0, 'embed_type': 0, 'activation': 'gelu', 'distil': 1, 'linear_output': 0, 'pct_start': 0.3, '/*train related args*/': '//', 'epoch': 30, '/*dataset related args*/': '//', 'save_data_path': 'data/ECL/', 'data_process': False, 'embed': 'timeF', 'freq': 'h', 'begin_phase': 0, 'end_phase': 1, 'phase_len': 26304, 'val_ratio': 0.33, 'graph_size': 321, '/*strategy related args*/': '//', 'strategy': 'incremental', 'increase': False, 'detect': False, 'detect_strategy': 'feature', 'replay': False, 'replay_strategy': 'random', 'repaly_num_samples': 100, 'ewc': False, 'ewc_strategy': 'ewc', 'ewc_lambda': 0.0001, 'subgraph_train': False, 'num_hops': 2, 'logname': 'ECL-Informer', 'time': '2023-09-02-12:31:38.039106', 'path': 'exp/ECL-Informer2023-09-02-12:31:38.039106', 'num_workers': 4, 'start_train': 0, 'train_mode': 'pretrain', 'get_score': False, 'use_cm': True, 'logger': <Logger __main__ (INFO)>}
2023-09-02 12:31:38,039 - [*] phase 0 start training
train 8449
val 2785
test 2785
2023-09-02 12:31:38,108 - [*] phase 0 Dataset load!
dropout 0.05
dropout 0.05
2023-09-02 12:31:39,462 - [*] phase 0 Training start
train 8449
2023-09-02 12:32:34,247 - epoch:0, training loss:0.2847 validation loss:0.2763
train 8449
vs, vt 0.2763449498875575 0.40706750615076587
Updating learning rate to 6.899583955836529e-06
Updating learning rate to 6.899583955836529e-06
train 8449
2023-09-02 12:33:08,155 - logger name:exp/ECL-Informer2023-09-02-12:33:08.155106/ECL-Informer.log
2023-09-02 12:33:08,155 - params : {'loss': 'huber', 'conf': 'ECL-Informer', 'data_name': 'ETTh2', 'iteration': 1, 'train': 1, 'mainrs': 0, 'abl': 0, 'load': True, 'build_graph': False, 'same_init': True, 'grad_norm': False, 'refiner_residual': 0, 'root_path': '', 'exp_path': 'exp/', 'val_test_mix': False, 'lr': 0.0001, 'lradj': 'TST', 'dropout': 0.05, 'fc_dropout': 0.05, 'head_dropout': 0.0, 'patch_len': 16, 'stride': 8, 'd_ff': 2048, 'd_model': 512, 'n_heads': 8, 'seq_len': 96, 'pred_len': 192, 'noise_rate': 0.5, 'device': device(type='cuda', index=1), 'test_model_path': '/Disk/fhyega/code/BASE/exp/ECL-PatchTST2023-08-26-13:08:31.837686/0/best_model.pkl', 'idx': -1, 'aligner': 1, 'always_align': 1, 'refiner': 1, 'rec_block_num': 1, 'enhance': 1, 'enhance_type': 5, 'seed': 34, 'batch_size': 64, 'share_head': 0, 'add_noise': 1, 'add_norm': 0, 'jitter_sigma': 0.4, 'slope_rate': 0.01, 'slope_range': 0.2, 'alpha': 10.0, 'beta': 1.0, 'gamma': 0.15, 'feature_jittering': 1, 'rec_intra_feature': 0, 'rec_ori': 1, 'mid_dim': 128, 'test_en': 0, 'debugger': 0, 'summary': 0, 'omega': 1.0, 'theta': 1.5, 'mask_border': 1, 'sup_weight': 10.0, 'rec_length_ratio': 0.8, 'ref_dropout': 0.0, 'ref_block_num': 2, 'add_FFN': 0, 'add_residual': 0, 'rec_all': 0, 'e_layers': 2, 'early_break': 0, 'early_stop': 10, '/* model related args*/': '//', 'model_name': 'informer', 'label_len': 48, 'features': 'M', 'target': 'OT', 'graph_input': False, 'individual': False, 'd_layers': 1, 'factor': 3, 'des': 'Exp', 'padding_patch': 'end', 'revin': 1, 'affine': 0, 'subtract_last': 0, 'decomposition': 0, 'kernel_size': 25, 'output_attention': 0, 'embed_type': 0, 'activation': 'gelu', 'distil': 1, 'linear_output': 0, 'pct_start': 0.3, '/*train related args*/': '//', 'epoch': 30, '/*dataset related args*/': '//', 'save_data_path': 'data/ECL/', 'data_process': False, 'embed': 'timeF', 'freq': 'h', 'begin_phase': 0, 'end_phase': 1, 'phase_len': 26304, 'val_ratio': 0.33, 'graph_size': 321, '/*strategy related args*/': '//', 'strategy': 'incremental', 'increase': False, 'detect': False, 'detect_strategy': 'feature', 'replay': False, 'replay_strategy': 'random', 'repaly_num_samples': 100, 'ewc': False, 'ewc_strategy': 'ewc', 'ewc_lambda': 0.0001, 'subgraph_train': False, 'num_hops': 2, 'logname': 'ECL-Informer', 'time': '2023-09-02-12:33:08.155106', 'path': 'exp/ECL-Informer2023-09-02-12:33:08.155106', 'num_workers': 4, 'start_train': 0, 'train_mode': 'pretrain', 'get_score': False, 'use_cm': True, 'logger': <Logger __main__ (INFO)>}
2023-09-02 12:33:08,155 - [*] phase 0 start training
train 8353
val 2689
test 2689
2023-09-02 12:33:08,225 - [*] phase 0 Dataset load!
dropout 0.05
dropout 0.05
2023-09-02 12:33:09,659 - [*] phase 0 Training start
train 8353
2023-09-02 12:34:11,958 - epoch:0, training loss:0.2981 validation loss:0.3206
train 8353
vs, vt 0.32059072928373206 0.44811369478702545
Updating learning rate to 6.899658353790513e-06
Updating learning rate to 6.899658353790513e-06
train 8353
2023-09-02 12:34:57,722 - logger name:exp/ECL-Informer2023-09-02-12:34:57.721842/ECL-Informer.log
2023-09-02 12:34:57,723 - params : {'loss': 'huber', 'conf': 'ECL-Informer', 'data_name': 'ETTh2', 'iteration': 1, 'train': 1, 'mainrs': 0, 'abl': 0, 'load': True, 'build_graph': False, 'same_init': True, 'grad_norm': False, 'refiner_residual': 0, 'root_path': '', 'exp_path': 'exp/', 'val_test_mix': False, 'lr': 0.0001, 'lradj': 'TST', 'dropout': 0.05, 'fc_dropout': 0.05, 'head_dropout': 0.0, 'patch_len': 16, 'stride': 8, 'd_ff': 2048, 'd_model': 512, 'n_heads': 8, 'seq_len': 96, 'pred_len': 336, 'noise_rate': 0.5, 'device': device(type='cuda', index=1), 'test_model_path': '/Disk/fhyega/code/BASE/exp/ECL-PatchTST2023-08-26-13:08:31.837686/0/best_model.pkl', 'idx': -1, 'aligner': 1, 'always_align': 1, 'refiner': 1, 'rec_block_num': 1, 'enhance': 1, 'enhance_type': 5, 'seed': 34, 'batch_size': 64, 'share_head': 0, 'add_noise': 1, 'add_norm': 0, 'jitter_sigma': 0.4, 'slope_rate': 0.01, 'slope_range': 0.2, 'alpha': 10.0, 'beta': 1.0, 'gamma': 0.15, 'feature_jittering': 1, 'rec_intra_feature': 0, 'rec_ori': 1, 'mid_dim': 128, 'test_en': 0, 'debugger': 0, 'summary': 0, 'omega': 1.0, 'theta': 1.5, 'mask_border': 1, 'sup_weight': 10.0, 'rec_length_ratio': 0.8, 'ref_dropout': 0.0, 'ref_block_num': 2, 'add_FFN': 0, 'add_residual': 0, 'rec_all': 0, 'e_layers': 2, 'early_break': 0, 'early_stop': 10, '/* model related args*/': '//', 'model_name': 'informer', 'label_len': 48, 'features': 'M', 'target': 'OT', 'graph_input': False, 'individual': False, 'd_layers': 1, 'factor': 3, 'des': 'Exp', 'padding_patch': 'end', 'revin': 1, 'affine': 0, 'subtract_last': 0, 'decomposition': 0, 'kernel_size': 25, 'output_attention': 0, 'embed_type': 0, 'activation': 'gelu', 'distil': 1, 'linear_output': 0, 'pct_start': 0.3, '/*train related args*/': '//', 'epoch': 30, '/*dataset related args*/': '//', 'save_data_path': 'data/ECL/', 'data_process': False, 'embed': 'timeF', 'freq': 'h', 'begin_phase': 0, 'end_phase': 1, 'phase_len': 26304, 'val_ratio': 0.33, 'graph_size': 321, '/*strategy related args*/': '//', 'strategy': 'incremental', 'increase': False, 'detect': False, 'detect_strategy': 'feature', 'replay': False, 'replay_strategy': 'random', 'repaly_num_samples': 100, 'ewc': False, 'ewc_strategy': 'ewc', 'ewc_lambda': 0.0001, 'subgraph_train': False, 'num_hops': 2, 'logname': 'ECL-Informer', 'time': '2023-09-02-12:34:57.721842', 'path': 'exp/ECL-Informer2023-09-02-12:34:57.721842', 'num_workers': 4, 'start_train': 0, 'train_mode': 'pretrain', 'get_score': False, 'use_cm': True, 'logger': <Logger __main__ (INFO)>}
2023-09-02 12:34:57,723 - [*] phase 0 start training
train 8209
val 2545
test 2545
2023-09-02 12:34:57,796 - [*] phase 0 Dataset load!
dropout 0.05
dropout 0.05
2023-09-02 12:34:59,402 - [*] phase 0 Training start
train 8209
2023-09-02 12:36:21,832 - epoch:0, training loss:0.3050 validation loss:0.3370
train 8209
vs, vt 0.33697256781160834 0.45162901245057585
Updating learning rate to 6.899735079669026e-06
Updating learning rate to 6.899735079669026e-06
train 8209
2023-09-02 12:37:08,435 - logger name:exp/ECL-Informer2023-09-02-12:37:08.434249/ECL-Informer.log
2023-09-02 12:37:08,435 - params : {'loss': 'huber', 'conf': 'ECL-Informer', 'data_name': 'ETTh2', 'iteration': 1, 'train': 1, 'mainrs': 0, 'abl': 0, 'load': True, 'build_graph': False, 'same_init': True, 'grad_norm': False, 'refiner_residual': 0, 'root_path': '', 'exp_path': 'exp/', 'val_test_mix': False, 'lr': 0.0001, 'lradj': 'TST', 'dropout': 0.05, 'fc_dropout': 0.05, 'head_dropout': 0.0, 'patch_len': 16, 'stride': 8, 'd_ff': 2048, 'd_model': 512, 'n_heads': 8, 'seq_len': 96, 'pred_len': 720, 'noise_rate': 0.5, 'device': device(type='cuda', index=1), 'test_model_path': '/Disk/fhyega/code/BASE/exp/ECL-PatchTST2023-08-26-13:08:31.837686/0/best_model.pkl', 'idx': -1, 'aligner': 1, 'always_align': 1, 'refiner': 1, 'rec_block_num': 1, 'enhance': 1, 'enhance_type': 5, 'seed': 34, 'batch_size': 64, 'share_head': 0, 'add_noise': 1, 'add_norm': 0, 'jitter_sigma': 0.4, 'slope_rate': 0.01, 'slope_range': 0.2, 'alpha': 10.0, 'beta': 1.0, 'gamma': 0.15, 'feature_jittering': 1, 'rec_intra_feature': 0, 'rec_ori': 1, 'mid_dim': 128, 'test_en': 0, 'debugger': 0, 'summary': 0, 'omega': 1.0, 'theta': 1.5, 'mask_border': 1, 'sup_weight': 10.0, 'rec_length_ratio': 0.8, 'ref_dropout': 0.0, 'ref_block_num': 2, 'add_FFN': 0, 'add_residual': 0, 'rec_all': 0, 'e_layers': 2, 'early_break': 0, 'early_stop': 10, '/* model related args*/': '//', 'model_name': 'informer', 'label_len': 48, 'features': 'M', 'target': 'OT', 'graph_input': False, 'individual': False, 'd_layers': 1, 'factor': 3, 'des': 'Exp', 'padding_patch': 'end', 'revin': 1, 'affine': 0, 'subtract_last': 0, 'decomposition': 0, 'kernel_size': 25, 'output_attention': 0, 'embed_type': 0, 'activation': 'gelu', 'distil': 1, 'linear_output': 0, 'pct_start': 0.3, '/*train related args*/': '//', 'epoch': 30, '/*dataset related args*/': '//', 'save_data_path': 'data/ECL/', 'data_process': False, 'embed': 'timeF', 'freq': 'h', 'begin_phase': 0, 'end_phase': 1, 'phase_len': 26304, 'val_ratio': 0.33, 'graph_size': 321, '/*strategy related args*/': '//', 'strategy': 'incremental', 'increase': False, 'detect': False, 'detect_strategy': 'feature', 'replay': False, 'replay_strategy': 'random', 'repaly_num_samples': 100, 'ewc': False, 'ewc_strategy': 'ewc', 'ewc_lambda': 0.0001, 'subgraph_train': False, 'num_hops': 2, 'logname': 'ECL-Informer', 'time': '2023-09-02-12:37:08.434249', 'path': 'exp/ECL-Informer2023-09-02-12:37:08.434249', 'num_workers': 4, 'start_train': 0, 'train_mode': 'pretrain', 'get_score': False, 'use_cm': True, 'logger': <Logger __main__ (INFO)>}
2023-09-02 12:37:08,435 - [*] phase 0 start training
train 7825
val 2161
test 2161
2023-09-02 12:37:08,504 - [*] phase 0 Dataset load!
dropout 0.05
dropout 0.05
2023-09-02 12:37:09,857 - [*] phase 0 Training start
train 7825
2023-09-02 12:38:46,196 - epoch:0, training loss:0.3225 validation loss:0.4052
train 7825
vs, vt 0.40517350987476464 0.44286366332979765
Updating learning rate to 6.8999803712766215e-06
Updating learning rate to 6.8999803712766215e-06
train 7825
2023-09-02 12:39:56,247 - logger name:exp/ECL-Informer2023-09-02-12:39:56.246249/ECL-Informer.log
2023-09-02 12:39:56,247 - params : {'loss': 'mse', 'conf': 'ECL-Informer', 'data_name': 'ETTm1', 'iteration': 1, 'train': 1, 'mainrs': 0, 'abl': 0, 'load': True, 'build_graph': False, 'same_init': True, 'grad_norm': False, 'refiner_residual': 0, 'root_path': '', 'exp_path': 'exp/', 'val_test_mix': False, 'lr': 0.0001, 'lradj': 'TST', 'dropout': 0.05, 'fc_dropout': 0.05, 'head_dropout': 0.0, 'patch_len': 16, 'stride': 8, 'd_ff': 2048, 'd_model': 512, 'n_heads': 8, 'seq_len': 96, 'pred_len': 96, 'noise_rate': 0.5, 'device': device(type='cuda', index=1), 'test_model_path': '/Disk/fhyega/code/BASE/exp/ECL-PatchTST2023-08-26-13:08:31.837686/0/best_model.pkl', 'idx': -1, 'aligner': 0, 'always_align': 1, 'refiner': 0, 'rec_block_num': 1, 'enhance': 0, 'enhance_type': 5, 'seed': 34, 'batch_size': 64, 'share_head': 0, 'add_noise': 1, 'add_norm': 0, 'jitter_sigma': 0.4, 'slope_rate': 0.01, 'slope_range': 0.2, 'alpha': 10.0, 'beta': 1.0, 'gamma': 0.15, 'feature_jittering': 1, 'rec_intra_feature': 0, 'rec_ori': 1, 'mid_dim': 128, 'test_en': 0, 'debugger': 0, 'summary': 0, 'omega': 1.0, 'theta': 1.5, 'mask_border': 1, 'sup_weight': 10.0, 'rec_length_ratio': 0.8, 'ref_dropout': 0.0, 'ref_block_num': 2, 'add_FFN': 0, 'add_residual': 0, 'rec_all': 0, 'e_layers': 2, 'early_break': 0, 'early_stop': 10, '/* model related args*/': '//', 'model_name': 'informer', 'label_len': 48, 'features': 'M', 'target': 'OT', 'graph_input': False, 'individual': False, 'd_layers': 1, 'factor': 3, 'des': 'Exp', 'padding_patch': 'end', 'revin': 1, 'affine': 0, 'subtract_last': 0, 'decomposition': 0, 'kernel_size': 25, 'output_attention': 0, 'embed_type': 0, 'activation': 'gelu', 'distil': 1, 'linear_output': 0, 'pct_start': 0.3, '/*train related args*/': '//', 'epoch': 30, '/*dataset related args*/': '//', 'save_data_path': 'data/ECL/', 'data_process': False, 'embed': 'timeF', 'freq': 'h', 'begin_phase': 0, 'end_phase': 1, 'phase_len': 26304, 'val_ratio': 0.33, 'graph_size': 321, '/*strategy related args*/': '//', 'strategy': 'incremental', 'increase': False, 'detect': False, 'detect_strategy': 'feature', 'replay': False, 'replay_strategy': 'random', 'repaly_num_samples': 100, 'ewc': False, 'ewc_strategy': 'ewc', 'ewc_lambda': 0.0001, 'subgraph_train': False, 'num_hops': 2, 'logname': 'ECL-Informer', 'time': '2023-09-02-12:39:56.246249', 'path': 'exp/ECL-Informer2023-09-02-12:39:56.246249', 'num_workers': 4, 'start_train': 0, 'train_mode': 'pretrain', 'get_score': False, 'use_cm': True, 'logger': <Logger __main__ (INFO)>}
2023-09-02 12:39:56,247 - [*] phase 0 start training
train 34369
val 11425
test 11425
2023-09-02 12:39:56,535 - [*] phase 0 Dataset load!
dropout 0.05
dropout 0.05
2023-09-02 12:39:58,095 - [*] phase 0 Training start
train 34369
2023-09-02 12:43:45,822 - epoch:0, training loss:0.5292 validation loss:0.7971
train 34369
vs, vt 0.7971437115576014 0.9872184820348324
Updating learning rate to 6.895940289031784e-06
Updating learning rate to 6.895940289031784e-06
train 34369
vs, vt 0.6909483224985986 0.9095056681742881
need align? ->  False 0.9095056681742881
2023-09-02 12:52:07,321 - epoch:1, training loss:0.4349 validation loss:0.6909
Updating learning rate to 1.523432489955886e-05
Updating learning rate to 1.523432489955886e-05
train 34369
vs, vt 0.6493493741451029 0.8179194260825658
need align? ->  False 0.8179194260825658
2023-09-02 12:58:13,021 - epoch:2, training loss:0.3671 validation loss:0.6493
Updating learning rate to 2.8009009500786763e-05
Updating learning rate to 2.8009009500786763e-05
train 34369
vs, vt 0.6886303227540501 0.7155543587394266
need align? ->  False 0.7155543587394266
2023-09-02 13:04:18,884 - epoch:3, training loss:0.3280 validation loss:0.6886
Updating learning rate to 4.367854726703342e-05
Updating learning rate to 4.367854726703342e-05
train 34369
vs, vt 0.6815038765442438 0.6968052732295165
need align? ->  False 0.6968052732295165
2023-09-02 13:10:21,269 - epoch:4, training loss:0.2967 validation loss:0.6815
Updating learning rate to 6.035218629297471e-05
Updating learning rate to 6.035218629297471e-05
train 34369
vs, vt 0.698323357538138 0.6478517359778202
need align? ->  True 0.6478517359778202
2023-09-02 13:16:18,680 - epoch:5, training loss:0.2712 validation loss:0.6983
Updating learning rate to 7.601801561944418e-05
Updating learning rate to 7.601801561944418e-05
train 34369
vs, vt 0.7400909415836441 0.654352130753368
need align? ->  True 0.6478517359778202
2023-09-02 13:22:28,030 - epoch:6, training loss:0.2495 validation loss:0.7401
Updating learning rate to 8.878573081695768e-05
Updating learning rate to 8.878573081695768e-05
train 34369
vs, vt 0.7669766457054202 0.6533301106794587
need align? ->  True 0.6478517359778202
2023-09-02 13:28:16,861 - epoch:7, training loss:0.2283 validation loss:0.7670
Updating learning rate to 9.711472601720846e-05
Updating learning rate to 9.711472601720846e-05
train 34369
vs, vt 0.8425174194840745 0.6902766625225211
need align? ->  True 0.6478517359778202
2023-09-02 13:33:59,397 - epoch:8, training loss:0.2046 validation loss:0.8425
Updating learning rate to 9.999999805978056e-05
Updating learning rate to 9.999999805978056e-05
train 34369
vs, vt 0.8291873258418877 0.6782303771326662
need align? ->  True 0.6478517359778202
2023-09-02 13:39:39,286 - epoch:9, training loss:0.1867 validation loss:0.8292
Updating learning rate to 9.943946559475415e-05
Updating learning rate to 9.943946559475415e-05
train 34369
vs, vt 0.8730121830988197 0.7225301400576224
need align? ->  True 0.6478517359778202
2023-09-02 13:45:15,693 - epoch:10, training loss:0.1661 validation loss:0.8730
Updating learning rate to 9.77745416322681e-05
Updating learning rate to 9.77745416322681e-05
train 34369
vs, vt 0.837242195975847 0.708617029659575
need align? ->  True 0.6478517359778202
2023-09-02 13:50:53,880 - epoch:11, training loss:0.1498 validation loss:0.8372
Updating learning rate to 9.504241782244028e-05
Updating learning rate to 9.504241782244028e-05
train 34369
vs, vt 0.8560526087963382 0.7462835721047231
need align? ->  True 0.6478517359778202
2023-09-02 13:56:31,102 - epoch:12, training loss:0.1362 validation loss:0.8561
Updating learning rate to 9.130412529648356e-05
Updating learning rate to 9.130412529648356e-05
train 34369
vs, vt 0.8872256042154808 0.7847317480091942
need align? ->  True 0.6478517359778202
2023-09-02 14:02:18,712 - epoch:13, training loss:0.1237 validation loss:0.8872
dropout 0.05
dropout 0.05
check exp/ECL-Informer2023-09-02-12:39:56.246249/0/0.6493_epoch_2.pkl  &  0.6478517359778202
2023-09-02 14:02:55,248 - [*] loss:0.6033
2023-09-02 14:02:55,261 - [*] phase 0, testing
2023-09-02 14:02:55,430 - T:96	MAE	0.546744	RMSE	0.603581	MAPE	243.277502
2023-09-02 14:02:55,431 - 96	mae	0.5467	
2023-09-02 14:02:55,431 - 96	rmse	0.6036	
2023-09-02 14:02:55,432 - 96	mape	243.2775	
2023-09-02 14:03:32,593 - [*] loss:0.6033
2023-09-02 14:03:32,607 - [*] phase 0, testing
2023-09-02 14:03:32,791 - T:96	MAE	0.546762	RMSE	0.603536	MAPE	243.101859
2023-09-02 14:03:35,303 - logger name:exp/ECL-Informer2023-09-02-14:03:35.298368/ECL-Informer.log
2023-09-02 14:03:35,304 - params : {'loss': 'mse', 'conf': 'ECL-Informer', 'data_name': 'ETTm1', 'iteration': 1, 'train': 1, 'mainrs': 0, 'abl': 0, 'load': True, 'build_graph': False, 'same_init': True, 'grad_norm': False, 'refiner_residual': 0, 'root_path': '', 'exp_path': 'exp/', 'val_test_mix': False, 'lr': 0.0001, 'lradj': 'TST', 'dropout': 0.05, 'fc_dropout': 0.05, 'head_dropout': 0.0, 'patch_len': 16, 'stride': 8, 'd_ff': 2048, 'd_model': 512, 'n_heads': 8, 'seq_len': 96, 'pred_len': 192, 'noise_rate': 0.5, 'device': device(type='cuda', index=1), 'test_model_path': '/Disk/fhyega/code/BASE/exp/ECL-PatchTST2023-08-26-13:08:31.837686/0/best_model.pkl', 'idx': -1, 'aligner': 0, 'always_align': 1, 'refiner': 0, 'rec_block_num': 1, 'enhance': 0, 'enhance_type': 5, 'seed': 34, 'batch_size': 64, 'share_head': 0, 'add_noise': 1, 'add_norm': 0, 'jitter_sigma': 0.4, 'slope_rate': 0.01, 'slope_range': 0.2, 'alpha': 10.0, 'beta': 1.0, 'gamma': 0.15, 'feature_jittering': 1, 'rec_intra_feature': 0, 'rec_ori': 1, 'mid_dim': 128, 'test_en': 0, 'debugger': 0, 'summary': 0, 'omega': 1.0, 'theta': 1.5, 'mask_border': 1, 'sup_weight': 10.0, 'rec_length_ratio': 0.8, 'ref_dropout': 0.0, 'ref_block_num': 2, 'add_FFN': 0, 'add_residual': 0, 'rec_all': 0, 'e_layers': 2, 'early_break': 0, 'early_stop': 10, '/* model related args*/': '//', 'model_name': 'informer', 'label_len': 48, 'features': 'M', 'target': 'OT', 'graph_input': False, 'individual': False, 'd_layers': 1, 'factor': 3, 'des': 'Exp', 'padding_patch': 'end', 'revin': 1, 'affine': 0, 'subtract_last': 0, 'decomposition': 0, 'kernel_size': 25, 'output_attention': 0, 'embed_type': 0, 'activation': 'gelu', 'distil': 1, 'linear_output': 0, 'pct_start': 0.3, '/*train related args*/': '//', 'epoch': 30, '/*dataset related args*/': '//', 'save_data_path': 'data/ECL/', 'data_process': False, 'embed': 'timeF', 'freq': 'h', 'begin_phase': 0, 'end_phase': 1, 'phase_len': 26304, 'val_ratio': 0.33, 'graph_size': 321, '/*strategy related args*/': '//', 'strategy': 'incremental', 'increase': False, 'detect': False, 'detect_strategy': 'feature', 'replay': False, 'replay_strategy': 'random', 'repaly_num_samples': 100, 'ewc': False, 'ewc_strategy': 'ewc', 'ewc_lambda': 0.0001, 'subgraph_train': False, 'num_hops': 2, 'logname': 'ECL-Informer', 'time': '2023-09-02-14:03:35.298368', 'path': 'exp/ECL-Informer2023-09-02-14:03:35.298368', 'num_workers': 4, 'start_train': 0, 'train_mode': 'pretrain', 'get_score': False, 'use_cm': True, 'logger': <Logger __main__ (INFO)>}
2023-09-02 14:03:35,304 - [*] phase 0 start training
train 34273
val 11329
test 11329
2023-09-02 14:03:35,606 - [*] phase 0 Dataset load!
dropout 0.05
dropout 0.05
2023-09-02 14:03:37,251 - [*] phase 0 Training start
train 34273
2023-09-02 14:08:02,046 - epoch:0, training loss:0.5598 validation loss:0.8759
train 34273
vs, vt 0.8758559646398834 1.0881457128718999
Updating learning rate to 6.895944724363715e-06
Updating learning rate to 6.895944724363715e-06
train 34273
vs, vt 0.8079290081945698 0.9919333323166611
need align? ->  False 0.9919333323166611
2023-09-02 14:17:16,026 - epoch:1, training loss:0.4964 validation loss:0.8079
Updating learning rate to 1.523434157051445e-05
Updating learning rate to 1.523434157051445e-05
train 34273
vs, vt 0.8062787672107139 0.937753597253494
need align? ->  False 0.937753597253494
2023-09-02 14:23:56,869 - epoch:2, training loss:0.4376 validation loss:0.8063
Updating learning rate to 2.800904319027465e-05
Updating learning rate to 2.800904319027465e-05
train 34273
vs, vt 0.8515969392623794 0.8861156858587533
need align? ->  False 0.8861156858587533
2023-09-02 14:30:44,682 - epoch:3, training loss:0.3978 validation loss:0.8516
Updating learning rate to 4.367859834359992e-05
Updating learning rate to 4.367859834359992e-05
train 34273
vs, vt 0.8132826341839319 0.8904663075724345
need align? ->  False 0.8861156858587533
2023-09-02 14:37:32,190 - epoch:4, training loss:0.3593 validation loss:0.8133
Updating learning rate to 6.035225013134865e-05
Updating learning rate to 6.035225013134865e-05
train 34273
vs, vt 0.8709560451882609 0.868598122610135
need align? ->  True 0.868598122610135
2023-09-02 14:44:24,381 - epoch:5, training loss:0.3225 validation loss:0.8710
Updating learning rate to 7.601808297307885e-05
Updating learning rate to 7.601808297307885e-05
train 34273
vs, vt 0.9085255473684729 0.920194321971261
need align? ->  True 0.868598122610135
2023-09-02 14:51:23,066 - epoch:6, training loss:0.2913 validation loss:0.9085
Updating learning rate to 8.87857891200083e-05
Updating learning rate to 8.87857891200083e-05
train 34273
vs, vt 0.9742293850926871 0.8565511582942491
need align? ->  True 0.8565511582942491
2023-09-02 14:58:15,474 - epoch:7, training loss:0.2631 validation loss:0.9742
Updating learning rate to 9.711476143636924e-05
Updating learning rate to 9.711476143636924e-05
train 34273
vs, vt 0.9748184776373123 0.8582529265726551
need align? ->  True 0.8565511582942491
2023-09-02 15:05:11,131 - epoch:8, training loss:0.2347 validation loss:0.9748
Updating learning rate to 9.999999804524713e-05
Updating learning rate to 9.999999804524713e-05
train 34273
vs, vt 0.9787362680843706 0.9023142606857117
need align? ->  True 0.8565511582942491
2023-09-02 15:11:59,686 - epoch:9, training loss:0.2071 validation loss:0.9787
Updating learning rate to 9.943945781951676e-05
Updating learning rate to 9.943945781951676e-05
train 34273
vs, vt 0.982264568924569 0.8955737325582611
need align? ->  True 0.8565511582942491
2023-09-02 15:18:50,240 - epoch:10, training loss:0.1866 validation loss:0.9823
Updating learning rate to 9.777452627001269e-05
Updating learning rate to 9.777452627001269e-05
train 34273
vs, vt 0.9921983900699722 0.9239134173212427
need align? ->  True 0.8565511582942491
2023-09-02 15:25:43,716 - epoch:11, training loss:0.1666 validation loss:0.9922
Updating learning rate to 9.504239521633426e-05
Updating learning rate to 9.504239521633426e-05
train 34273
vs, vt 0.9945846078603455 0.9718031932631236
need align? ->  True 0.8565511582942491
2023-09-02 15:32:46,157 - epoch:12, training loss:0.1511 validation loss:0.9946
Updating learning rate to 9.130409595150998e-05
Updating learning rate to 9.130409595150998e-05
train 34273
vs, vt 0.9668366261914875 0.9877603244915437
need align? ->  True 0.8565511582942491
2023-09-02 15:39:33,559 - epoch:13, training loss:0.1373 validation loss:0.9668
dropout 0.05
dropout 0.05
check exp/ECL-Informer2023-09-02-14:03:35.298368/0/0.8063_epoch_2.pkl  &  0.8565511582942491
2023-09-02 15:40:07,801 - [*] loss:0.7279
2023-09-02 15:40:07,909 - [*] phase 0, testing
2023-09-02 15:40:09,504 - T:192	MAE	0.626391	RMSE	0.728989	MAPE	244.437003
2023-09-02 15:40:09,508 - 192	mae	0.6264	
2023-09-02 15:40:09,508 - 192	rmse	0.7290	
2023-09-02 15:40:09,508 - 192	mape	244.4370	
2023-09-02 15:40:43,384 - [*] loss:0.7281
2023-09-02 15:40:43,403 - [*] phase 0, testing
2023-09-02 15:40:45,080 - T:192	MAE	0.626497	RMSE	0.729149	MAPE	244.568086
2023-09-02 15:40:47,338 - logger name:exp/ECL-Informer2023-09-02-15:40:47.338620/ECL-Informer.log
2023-09-02 15:40:47,339 - params : {'loss': 'mse', 'conf': 'ECL-Informer', 'data_name': 'ETTm1', 'iteration': 1, 'train': 1, 'mainrs': 0, 'abl': 0, 'load': True, 'build_graph': False, 'same_init': True, 'grad_norm': False, 'refiner_residual': 0, 'root_path': '', 'exp_path': 'exp/', 'val_test_mix': False, 'lr': 0.0001, 'lradj': 'TST', 'dropout': 0.05, 'fc_dropout': 0.05, 'head_dropout': 0.0, 'patch_len': 16, 'stride': 8, 'd_ff': 2048, 'd_model': 512, 'n_heads': 8, 'seq_len': 96, 'pred_len': 336, 'noise_rate': 0.5, 'device': device(type='cuda', index=1), 'test_model_path': '/Disk/fhyega/code/BASE/exp/ECL-PatchTST2023-08-26-13:08:31.837686/0/best_model.pkl', 'idx': -1, 'aligner': 0, 'always_align': 1, 'refiner': 0, 'rec_block_num': 1, 'enhance': 0, 'enhance_type': 5, 'seed': 34, 'batch_size': 64, 'share_head': 0, 'add_noise': 1, 'add_norm': 0, 'jitter_sigma': 0.4, 'slope_rate': 0.01, 'slope_range': 0.2, 'alpha': 10.0, 'beta': 1.0, 'gamma': 0.15, 'feature_jittering': 1, 'rec_intra_feature': 0, 'rec_ori': 1, 'mid_dim': 128, 'test_en': 0, 'debugger': 0, 'summary': 0, 'omega': 1.0, 'theta': 1.5, 'mask_border': 1, 'sup_weight': 10.0, 'rec_length_ratio': 0.8, 'ref_dropout': 0.0, 'ref_block_num': 2, 'add_FFN': 0, 'add_residual': 0, 'rec_all': 0, 'e_layers': 2, 'early_break': 0, 'early_stop': 10, '/* model related args*/': '//', 'model_name': 'informer', 'label_len': 48, 'features': 'M', 'target': 'OT', 'graph_input': False, 'individual': False, 'd_layers': 1, 'factor': 3, 'des': 'Exp', 'padding_patch': 'end', 'revin': 1, 'affine': 0, 'subtract_last': 0, 'decomposition': 0, 'kernel_size': 25, 'output_attention': 0, 'embed_type': 0, 'activation': 'gelu', 'distil': 1, 'linear_output': 0, 'pct_start': 0.3, '/*train related args*/': '//', 'epoch': 30, '/*dataset related args*/': '//', 'save_data_path': 'data/ECL/', 'data_process': False, 'embed': 'timeF', 'freq': 'h', 'begin_phase': 0, 'end_phase': 1, 'phase_len': 26304, 'val_ratio': 0.33, 'graph_size': 321, '/*strategy related args*/': '//', 'strategy': 'incremental', 'increase': False, 'detect': False, 'detect_strategy': 'feature', 'replay': False, 'replay_strategy': 'random', 'repaly_num_samples': 100, 'ewc': False, 'ewc_strategy': 'ewc', 'ewc_lambda': 0.0001, 'subgraph_train': False, 'num_hops': 2, 'logname': 'ECL-Informer', 'time': '2023-09-02-15:40:47.338620', 'path': 'exp/ECL-Informer2023-09-02-15:40:47.338620', 'num_workers': 4, 'start_train': 0, 'train_mode': 'pretrain', 'get_score': False, 'use_cm': True, 'logger': <Logger __main__ (INFO)>}
2023-09-02 15:40:47,339 - [*] phase 0 start training
train 34129
val 11185
test 11185
2023-09-02 15:40:47,606 - [*] phase 0 Dataset load!
dropout 0.05
dropout 0.05
2023-09-02 15:40:49,016 - [*] phase 0 Training start
train 34129
2023-09-02 15:46:03,914 - epoch:0, training loss:0.5874 validation loss:0.9859
train 34129
vs, vt 0.9859021709646497 1.233745139156069
Updating learning rate to 6.895949192991724e-06
Updating learning rate to 6.895949192991724e-06
train 34129
vs, vt 0.9526386214154107 1.1668713576453074
need align? ->  False 1.1668713576453074
2023-09-02 15:57:38,135 - epoch:1, training loss:0.5608 validation loss:0.9526
Updating learning rate to 1.5234358366617343e-05
Updating learning rate to 1.5234358366617343e-05
train 34129
vs, vt 0.9983416136673519 1.191397122485297
need align? ->  False 1.1668713576453074
2023-09-02 16:05:34,660 - epoch:2, training loss:0.5105 validation loss:0.9983
Updating learning rate to 2.8009077132660348e-05
Updating learning rate to 2.8009077132660348e-05
train 34129
vs, vt 0.9862591144868306 1.2026274657249452
need align? ->  False 1.1668713576453074
2023-09-02 16:13:22,616 - epoch:3, training loss:0.4658 validation loss:0.9863
Updating learning rate to 4.367864980356998e-05
Updating learning rate to 4.367864980356998e-05
train 34129
vs, vt 1.056422489455768 1.2094098844698498
need align? ->  False 1.1668713576453074
2023-09-02 16:21:40,608 - epoch:4, training loss:0.4028 validation loss:1.0564
Updating learning rate to 6.035231444889432e-05
Updating learning rate to 6.035231444889432e-05
train 34129
vs, vt 1.142347269313676 1.1657962145975658
need align? ->  False 1.1657962145975658
2023-09-02 16:29:24,719 - epoch:5, training loss:0.3582 validation loss:1.1423
Updating learning rate to 7.601815083222329e-05
Updating learning rate to 7.601815083222329e-05
train 34129
vs, vt 1.1518314730269568 1.1280746589388166
need align? ->  True 1.1280746589388166
2023-09-02 16:37:14,322 - epoch:6, training loss:0.3209 validation loss:1.1518
Updating learning rate to 8.878584786056352e-05
Updating learning rate to 8.878584786056352e-05
train 34129
vs, vt 1.1389676155362811 1.0434601029327937
need align? ->  True 1.0434601029327937
2023-09-02 16:45:12,159 - epoch:7, training loss:0.2866 validation loss:1.1390
Updating learning rate to 9.711479712118226e-05
Updating learning rate to 9.711479712118226e-05
train 34129
vs, vt 1.1918219648088728 1.1202388507127763
need align? ->  True 1.0434601029327937
2023-09-02 16:53:19,774 - epoch:8, training loss:0.2496 validation loss:1.1918
Updating learning rate to 9.99999980305498e-05
Updating learning rate to 9.99999980305498e-05
train 34129
vs, vt 1.2193878000974656 1.148584697331701
need align? ->  True 1.0434601029327937
2023-09-02 17:01:29,207 - epoch:9, training loss:0.2214 validation loss:1.2194
Updating learning rate to 9.943944998587439e-05
Updating learning rate to 9.943944998587439e-05
train 34129
vs, vt 1.1699357142618725 1.165969528726169
need align? ->  True 1.0434601029327937
2023-09-02 17:09:44,800 - epoch:10, training loss:0.1962 validation loss:1.1699
Updating learning rate to 9.777451079241591e-05
Updating learning rate to 9.777451079241591e-05
train 34129
vs, vt 1.1617223223618098 1.1647568616696766
need align? ->  True 1.0434601029327937
2023-09-02 17:17:55,290 - epoch:11, training loss:0.1752 validation loss:1.1617
Updating learning rate to 9.504237244052699e-05
Updating learning rate to 9.504237244052699e-05
train 34129
vs, vt 1.1725861463376455 1.1847657407181604
need align? ->  True 1.0434601029327937
2023-09-02 17:26:01,908 - epoch:12, training loss:0.1578 validation loss:1.1726
dropout 0.05
dropout 0.05
check exp/ECL-Informer2023-09-02-15:40:47.338620/0/0.9526_epoch_1.pkl  &  1.0434601029327937
2023-09-02 17:26:38,871 - [*] loss:0.8337
2023-09-02 17:26:38,905 - [*] phase 0, testing
2023-09-02 17:26:39,810 - T:336	MAE	0.677566	RMSE	0.833670	MAPE	247.799611
2023-09-02 17:26:39,811 - 336	mae	0.6776	
2023-09-02 17:26:39,811 - 336	rmse	0.8337	
2023-09-02 17:26:39,811 - 336	mape	247.7996	
2023-09-02 17:27:16,697 - [*] loss:0.8337
2023-09-02 17:27:16,727 - [*] phase 0, testing
2023-09-02 17:27:17,480 - T:336	MAE	0.677570	RMSE	0.833684	MAPE	247.785568
2023-09-02 17:27:19,671 - logger name:exp/ECL-Informer2023-09-02-17:27:19.670980/ECL-Informer.log
2023-09-02 17:27:19,671 - params : {'loss': 'mse', 'conf': 'ECL-Informer', 'data_name': 'ETTm1', 'iteration': 1, 'train': 1, 'mainrs': 0, 'abl': 0, 'load': True, 'build_graph': False, 'same_init': True, 'grad_norm': False, 'refiner_residual': 0, 'root_path': '', 'exp_path': 'exp/', 'val_test_mix': False, 'lr': 0.0001, 'lradj': 'TST', 'dropout': 0.05, 'fc_dropout': 0.05, 'head_dropout': 0.0, 'patch_len': 16, 'stride': 8, 'd_ff': 2048, 'd_model': 512, 'n_heads': 8, 'seq_len': 96, 'pred_len': 720, 'noise_rate': 0.5, 'device': device(type='cuda', index=1), 'test_model_path': '/Disk/fhyega/code/BASE/exp/ECL-PatchTST2023-08-26-13:08:31.837686/0/best_model.pkl', 'idx': -1, 'aligner': 0, 'always_align': 1, 'refiner': 0, 'rec_block_num': 1, 'enhance': 0, 'enhance_type': 5, 'seed': 34, 'batch_size': 64, 'share_head': 0, 'add_noise': 1, 'add_norm': 0, 'jitter_sigma': 0.4, 'slope_rate': 0.01, 'slope_range': 0.2, 'alpha': 10.0, 'beta': 1.0, 'gamma': 0.15, 'feature_jittering': 1, 'rec_intra_feature': 0, 'rec_ori': 1, 'mid_dim': 128, 'test_en': 0, 'debugger': 0, 'summary': 0, 'omega': 1.0, 'theta': 1.5, 'mask_border': 1, 'sup_weight': 10.0, 'rec_length_ratio': 0.8, 'ref_dropout': 0.0, 'ref_block_num': 2, 'add_FFN': 0, 'add_residual': 0, 'rec_all': 0, 'e_layers': 2, 'early_break': 0, 'early_stop': 10, '/* model related args*/': '//', 'model_name': 'informer', 'label_len': 48, 'features': 'M', 'target': 'OT', 'graph_input': False, 'individual': False, 'd_layers': 1, 'factor': 3, 'des': 'Exp', 'padding_patch': 'end', 'revin': 1, 'affine': 0, 'subtract_last': 0, 'decomposition': 0, 'kernel_size': 25, 'output_attention': 0, 'embed_type': 0, 'activation': 'gelu', 'distil': 1, 'linear_output': 0, 'pct_start': 0.3, '/*train related args*/': '//', 'epoch': 30, '/*dataset related args*/': '//', 'save_data_path': 'data/ECL/', 'data_process': False, 'embed': 'timeF', 'freq': 'h', 'begin_phase': 0, 'end_phase': 1, 'phase_len': 26304, 'val_ratio': 0.33, 'graph_size': 321, '/*strategy related args*/': '//', 'strategy': 'incremental', 'increase': False, 'detect': False, 'detect_strategy': 'feature', 'replay': False, 'replay_strategy': 'random', 'repaly_num_samples': 100, 'ewc': False, 'ewc_strategy': 'ewc', 'ewc_lambda': 0.0001, 'subgraph_train': False, 'num_hops': 2, 'logname': 'ECL-Informer', 'time': '2023-09-02-17:27:19.670980', 'path': 'exp/ECL-Informer2023-09-02-17:27:19.670980', 'num_workers': 4, 'start_train': 0, 'train_mode': 'pretrain', 'get_score': False, 'use_cm': True, 'logger': <Logger __main__ (INFO)>}
2023-09-02 17:27:19,672 - [*] phase 0 start training
train 33745
val 10801
test 10801
2023-09-02 17:27:19,934 - [*] phase 0 Dataset load!
dropout 0.05
dropout 0.05
2023-09-02 17:27:21,217 - [*] phase 0 Training start
train 33745
2023-09-02 17:34:37,990 - epoch:0, training loss:0.6345 validation loss:1.2702
train 33745
vs, vt 1.27020405047744 1.4699575135693748
Updating learning rate to 6.8959628024441156e-06
Updating learning rate to 6.8959628024441156e-06
train 33745
vs, vt 1.2966114361963328 1.4263224822176983
need align? ->  False 1.4263224822176983
2023-09-02 17:51:22,616 - epoch:1, training loss:0.6454 validation loss:1.2966
Updating learning rate to 1.5234409520062321e-05
Updating learning rate to 1.5234409520062321e-05
train 33745
vs, vt 1.344916071412126 1.4461472410069416
need align? ->  False 1.4263224822176983
2023-09-02 18:03:01,035 - epoch:2, training loss:0.5969 validation loss:1.3449
Updating learning rate to 2.8009180506005253e-05
Updating learning rate to 2.8009180506005253e-05
train 33745
vs, vt 1.3766854063293639 1.4565919895143904
need align? ->  False 1.4263224822176983
2023-09-02 18:14:30,141 - epoch:3, training loss:0.5451 validation loss:1.3767
Updating learning rate to 4.367880652756318e-05
Updating learning rate to 4.367880652756318e-05
train 33745
vs, vt 1.3114986433785343 1.4883892292807088
need align? ->  False 1.4263224822176983
2023-09-02 18:25:58,609 - epoch:4, training loss:0.4852 validation loss:1.3115
Updating learning rate to 6.0352510331126026e-05
Updating learning rate to 6.0352510331126026e-05
train 33745
vs, vt 1.2791705639404658 1.48076027402511
need align? ->  False 1.4263224822176983
2023-09-02 18:37:30,800 - epoch:5, training loss:0.4140 validation loss:1.2792
Updating learning rate to 7.601835750027339e-05
Updating learning rate to 7.601835750027339e-05
train 33745
vs, vt 1.2965019532209316 1.4775984703436407
need align? ->  False 1.4263224822176983
2023-09-02 18:49:00,902 - epoch:6, training loss:0.3646 validation loss:1.2965
Updating learning rate to 8.878602675706259e-05
Updating learning rate to 8.878602675706259e-05
train 33745
vs, vt 1.305535396527962 1.48009420887253
need align? ->  False 1.4263224822176983
2023-09-02 19:00:39,966 - epoch:7, training loss:0.3283 validation loss:1.3055
Updating learning rate to 9.711490579976146e-05
Updating learning rate to 9.711490579976146e-05
train 33745
vs, vt 1.311639692303697 1.4277915935191883
need align? ->  False 1.4263224822176983
2023-09-02 19:12:32,209 - epoch:8, training loss:0.2941 validation loss:1.3116
Updating learning rate to 9.999999798544934e-05
Updating learning rate to 9.999999798544934e-05
train 33745
vs, vt 1.359463618175518 1.413324037952536
need align? ->  False 1.413324037952536
2023-09-02 19:24:33,310 - epoch:9, training loss:0.2660 validation loss:1.3595
Updating learning rate to 9.943942612786164e-05
Updating learning rate to 9.943942612786164e-05
train 33745
vs, vt 1.347394801279497 1.3900620381860338
need align? ->  False 1.3900620381860338
2023-09-02 19:36:37,172 - epoch:10, training loss:0.2396 validation loss:1.3474
Updating learning rate to 9.777446365443946e-05
Updating learning rate to 9.777446365443946e-05
train 33745
vs, vt 1.3188337091158127 1.3842554319892408
need align? ->  False 1.3842554319892408
2023-09-02 19:48:27,904 - epoch:11, training loss:0.2158 validation loss:1.3188
dropout 0.05
dropout 0.05
check exp/ECL-Informer2023-09-02-17:27:19.670980/0/1.2702_epoch_0.pkl  &  1.3842554319892408
2023-09-02 19:49:15,657 - [*] loss:0.9333
2023-09-02 19:49:16,287 - [*] phase 0, testing
2023-09-02 19:49:21,181 - T:720	MAE	0.723118	RMSE	0.933511	MAPE	228.365993
2023-09-02 19:49:21,203 - 720	mae	0.7231	
2023-09-02 19:49:21,203 - 720	rmse	0.9335	
2023-09-02 19:49:21,204 - 720	mape	228.3660	
2023-09-02 19:50:08,412 - [*] loss:0.9334
2023-09-02 19:50:08,700 - [*] phase 0, testing
2023-09-02 19:50:14,883 - T:720	MAE	0.723161	RMSE	0.933614	MAPE	228.354120
2023-09-02 19:50:17,251 - logger name:exp/ECL-Informer2023-09-02-19:50:17.251054/ECL-Informer.log
2023-09-02 19:50:17,251 - params : {'loss': 'huber', 'conf': 'ECL-Informer', 'data_name': 'ETTm1', 'iteration': 1, 'train': 1, 'mainrs': 0, 'abl': 0, 'load': True, 'build_graph': False, 'same_init': True, 'grad_norm': False, 'refiner_residual': 0, 'root_path': '', 'exp_path': 'exp/', 'val_test_mix': False, 'lr': 0.0001, 'lradj': 'TST', 'dropout': 0.05, 'fc_dropout': 0.05, 'head_dropout': 0.0, 'patch_len': 16, 'stride': 8, 'd_ff': 2048, 'd_model': 512, 'n_heads': 8, 'seq_len': 96, 'pred_len': 96, 'noise_rate': 0.5, 'device': device(type='cuda', index=1), 'test_model_path': '/Disk/fhyega/code/BASE/exp/ECL-PatchTST2023-08-26-13:08:31.837686/0/best_model.pkl', 'idx': -1, 'aligner': 1, 'always_align': 1, 'refiner': 1, 'rec_block_num': 1, 'enhance': 1, 'enhance_type': 5, 'seed': 34, 'batch_size': 64, 'share_head': 0, 'add_noise': 1, 'add_norm': 0, 'jitter_sigma': 0.4, 'slope_rate': 0.01, 'slope_range': 0.2, 'alpha': 10.0, 'beta': 1.0, 'gamma': 0.15, 'feature_jittering': 1, 'rec_intra_feature': 0, 'rec_ori': 1, 'mid_dim': 128, 'test_en': 0, 'debugger': 0, 'summary': 0, 'omega': 1.0, 'theta': 1.5, 'mask_border': 1, 'sup_weight': 10.0, 'rec_length_ratio': 0.8, 'ref_dropout': 0.0, 'ref_block_num': 2, 'add_FFN': 0, 'add_residual': 0, 'rec_all': 0, 'e_layers': 2, 'early_break': 0, 'early_stop': 10, '/* model related args*/': '//', 'model_name': 'informer', 'label_len': 48, 'features': 'M', 'target': 'OT', 'graph_input': False, 'individual': False, 'd_layers': 1, 'factor': 3, 'des': 'Exp', 'padding_patch': 'end', 'revin': 1, 'affine': 0, 'subtract_last': 0, 'decomposition': 0, 'kernel_size': 25, 'output_attention': 0, 'embed_type': 0, 'activation': 'gelu', 'distil': 1, 'linear_output': 0, 'pct_start': 0.3, '/*train related args*/': '//', 'epoch': 30, '/*dataset related args*/': '//', 'save_data_path': 'data/ECL/', 'data_process': False, 'embed': 'timeF', 'freq': 'h', 'begin_phase': 0, 'end_phase': 1, 'phase_len': 26304, 'val_ratio': 0.33, 'graph_size': 321, '/*strategy related args*/': '//', 'strategy': 'incremental', 'increase': False, 'detect': False, 'detect_strategy': 'feature', 'replay': False, 'replay_strategy': 'random', 'repaly_num_samples': 100, 'ewc': False, 'ewc_strategy': 'ewc', 'ewc_lambda': 0.0001, 'subgraph_train': False, 'num_hops': 2, 'logname': 'ECL-Informer', 'time': '2023-09-02-19:50:17.251054', 'path': 'exp/ECL-Informer2023-09-02-19:50:17.251054', 'num_workers': 4, 'start_train': 0, 'train_mode': 'pretrain', 'get_score': False, 'use_cm': True, 'logger': <Logger __main__ (INFO)>}
2023-09-02 19:50:17,251 - [*] phase 0 start training
train 34369
val 11425
test 11425
2023-09-02 19:50:17,525 - [*] phase 0 Dataset load!
dropout 0.05
dropout 0.05
2023-09-02 19:50:18,949 - [*] phase 0 Training start
train 34369
2023-09-02 19:53:58,466 - epoch:0, training loss:0.2237 validation loss:0.3004
train 34369
vs, vt 0.3004356430812255 0.33429240056589327
Updating learning rate to 6.895940289031784e-06
Updating learning rate to 6.895940289031784e-06
train 34369
2023-09-02 19:56:28,132 - logger name:exp/ECL-Informer2023-09-02-19:56:28.131817/ECL-Informer.log
2023-09-02 19:56:28,132 - params : {'loss': 'huber', 'conf': 'ECL-Informer', 'data_name': 'ETTm1', 'iteration': 1, 'train': 1, 'mainrs': 0, 'abl': 0, 'load': True, 'build_graph': False, 'same_init': True, 'grad_norm': False, 'refiner_residual': 0, 'root_path': '', 'exp_path': 'exp/', 'val_test_mix': False, 'lr': 0.0001, 'lradj': 'TST', 'dropout': 0.05, 'fc_dropout': 0.05, 'head_dropout': 0.0, 'patch_len': 16, 'stride': 8, 'd_ff': 2048, 'd_model': 512, 'n_heads': 8, 'seq_len': 96, 'pred_len': 192, 'noise_rate': 0.5, 'device': device(type='cuda', index=1), 'test_model_path': '/Disk/fhyega/code/BASE/exp/ECL-PatchTST2023-08-26-13:08:31.837686/0/best_model.pkl', 'idx': -1, 'aligner': 1, 'always_align': 1, 'refiner': 1, 'rec_block_num': 1, 'enhance': 1, 'enhance_type': 5, 'seed': 34, 'batch_size': 64, 'share_head': 0, 'add_noise': 1, 'add_norm': 0, 'jitter_sigma': 0.4, 'slope_rate': 0.01, 'slope_range': 0.2, 'alpha': 10.0, 'beta': 1.0, 'gamma': 0.15, 'feature_jittering': 1, 'rec_intra_feature': 0, 'rec_ori': 1, 'mid_dim': 128, 'test_en': 0, 'debugger': 0, 'summary': 0, 'omega': 1.0, 'theta': 1.5, 'mask_border': 1, 'sup_weight': 10.0, 'rec_length_ratio': 0.8, 'ref_dropout': 0.0, 'ref_block_num': 2, 'add_FFN': 0, 'add_residual': 0, 'rec_all': 0, 'e_layers': 2, 'early_break': 0, 'early_stop': 10, '/* model related args*/': '//', 'model_name': 'informer', 'label_len': 48, 'features': 'M', 'target': 'OT', 'graph_input': False, 'individual': False, 'd_layers': 1, 'factor': 3, 'des': 'Exp', 'padding_patch': 'end', 'revin': 1, 'affine': 0, 'subtract_last': 0, 'decomposition': 0, 'kernel_size': 25, 'output_attention': 0, 'embed_type': 0, 'activation': 'gelu', 'distil': 1, 'linear_output': 0, 'pct_start': 0.3, '/*train related args*/': '//', 'epoch': 30, '/*dataset related args*/': '//', 'save_data_path': 'data/ECL/', 'data_process': False, 'embed': 'timeF', 'freq': 'h', 'begin_phase': 0, 'end_phase': 1, 'phase_len': 26304, 'val_ratio': 0.33, 'graph_size': 321, '/*strategy related args*/': '//', 'strategy': 'incremental', 'increase': False, 'detect': False, 'detect_strategy': 'feature', 'replay': False, 'replay_strategy': 'random', 'repaly_num_samples': 100, 'ewc': False, 'ewc_strategy': 'ewc', 'ewc_lambda': 0.0001, 'subgraph_train': False, 'num_hops': 2, 'logname': 'ECL-Informer', 'time': '2023-09-02-19:56:28.131817', 'path': 'exp/ECL-Informer2023-09-02-19:56:28.131817', 'num_workers': 4, 'start_train': 0, 'train_mode': 'pretrain', 'get_score': False, 'use_cm': True, 'logger': <Logger __main__ (INFO)>}
2023-09-02 19:56:28,132 - [*] phase 0 start training
train 34273
val 11329
test 11329
2023-09-02 19:56:28,410 - [*] phase 0 Dataset load!
dropout 0.05
dropout 0.05
2023-09-02 19:56:30,295 - [*] phase 0 Training start
train 34273
2023-09-02 20:00:54,880 - epoch:0, training loss:0.2345 validation loss:0.3280
train 34273
vs, vt 0.32803636287035565 0.36476725888218775
Updating learning rate to 6.895944724363715e-06
Updating learning rate to 6.895944724363715e-06
train 34273
2023-09-02 20:03:57,705 - logger name:exp/ECL-Informer2023-09-02-20:03:57.704713/ECL-Informer.log
2023-09-02 20:03:57,706 - params : {'loss': 'huber', 'conf': 'ECL-Informer', 'data_name': 'ETTm1', 'iteration': 1, 'train': 1, 'mainrs': 0, 'abl': 0, 'load': True, 'build_graph': False, 'same_init': True, 'grad_norm': False, 'refiner_residual': 0, 'root_path': '', 'exp_path': 'exp/', 'val_test_mix': False, 'lr': 0.0001, 'lradj': 'TST', 'dropout': 0.05, 'fc_dropout': 0.05, 'head_dropout': 0.0, 'patch_len': 16, 'stride': 8, 'd_ff': 2048, 'd_model': 512, 'n_heads': 8, 'seq_len': 96, 'pred_len': 336, 'noise_rate': 0.5, 'device': device(type='cuda', index=1), 'test_model_path': '/Disk/fhyega/code/BASE/exp/ECL-PatchTST2023-08-26-13:08:31.837686/0/best_model.pkl', 'idx': -1, 'aligner': 1, 'always_align': 1, 'refiner': 1, 'rec_block_num': 1, 'enhance': 1, 'enhance_type': 5, 'seed': 34, 'batch_size': 64, 'share_head': 0, 'add_noise': 1, 'add_norm': 0, 'jitter_sigma': 0.4, 'slope_rate': 0.01, 'slope_range': 0.2, 'alpha': 10.0, 'beta': 1.0, 'gamma': 0.15, 'feature_jittering': 1, 'rec_intra_feature': 0, 'rec_ori': 1, 'mid_dim': 128, 'test_en': 0, 'debugger': 0, 'summary': 0, 'omega': 1.0, 'theta': 1.5, 'mask_border': 1, 'sup_weight': 10.0, 'rec_length_ratio': 0.8, 'ref_dropout': 0.0, 'ref_block_num': 2, 'add_FFN': 0, 'add_residual': 0, 'rec_all': 0, 'e_layers': 2, 'early_break': 0, 'early_stop': 10, '/* model related args*/': '//', 'model_name': 'informer', 'label_len': 48, 'features': 'M', 'target': 'OT', 'graph_input': False, 'individual': False, 'd_layers': 1, 'factor': 3, 'des': 'Exp', 'padding_patch': 'end', 'revin': 1, 'affine': 0, 'subtract_last': 0, 'decomposition': 0, 'kernel_size': 25, 'output_attention': 0, 'embed_type': 0, 'activation': 'gelu', 'distil': 1, 'linear_output': 0, 'pct_start': 0.3, '/*train related args*/': '//', 'epoch': 30, '/*dataset related args*/': '//', 'save_data_path': 'data/ECL/', 'data_process': False, 'embed': 'timeF', 'freq': 'h', 'begin_phase': 0, 'end_phase': 1, 'phase_len': 26304, 'val_ratio': 0.33, 'graph_size': 321, '/*strategy related args*/': '//', 'strategy': 'incremental', 'increase': False, 'detect': False, 'detect_strategy': 'feature', 'replay': False, 'replay_strategy': 'random', 'repaly_num_samples': 100, 'ewc': False, 'ewc_strategy': 'ewc', 'ewc_lambda': 0.0001, 'subgraph_train': False, 'num_hops': 2, 'logname': 'ECL-Informer', 'time': '2023-09-02-20:03:57.704713', 'path': 'exp/ECL-Informer2023-09-02-20:03:57.704713', 'num_workers': 4, 'start_train': 0, 'train_mode': 'pretrain', 'get_score': False, 'use_cm': True, 'logger': <Logger __main__ (INFO)>}
2023-09-02 20:03:57,706 - [*] phase 0 start training
train 34129
val 11185
test 11185
2023-09-02 20:03:57,995 - [*] phase 0 Dataset load!
dropout 0.05
dropout 0.05
2023-09-02 20:03:59,649 - [*] phase 0 Training start
train 34129
2023-09-02 20:09:08,739 - epoch:0, training loss:0.2445 validation loss:0.3612
train 34129
vs, vt 0.3611915481516293 0.4013469009740012
Updating learning rate to 6.895949192991724e-06
Updating learning rate to 6.895949192991724e-06
train 34129
2023-09-02 20:12:28,706 - logger name:exp/ECL-Informer2023-09-02-20:12:28.705896/ECL-Informer.log
2023-09-02 20:12:28,706 - params : {'loss': 'huber', 'conf': 'ECL-Informer', 'data_name': 'ETTm1', 'iteration': 1, 'train': 1, 'mainrs': 0, 'abl': 0, 'load': True, 'build_graph': False, 'same_init': True, 'grad_norm': False, 'refiner_residual': 0, 'root_path': '', 'exp_path': 'exp/', 'val_test_mix': False, 'lr': 0.0001, 'lradj': 'TST', 'dropout': 0.05, 'fc_dropout': 0.05, 'head_dropout': 0.0, 'patch_len': 16, 'stride': 8, 'd_ff': 2048, 'd_model': 512, 'n_heads': 8, 'seq_len': 96, 'pred_len': 720, 'noise_rate': 0.5, 'device': device(type='cuda', index=1), 'test_model_path': '/Disk/fhyega/code/BASE/exp/ECL-PatchTST2023-08-26-13:08:31.837686/0/best_model.pkl', 'idx': -1, 'aligner': 1, 'always_align': 1, 'refiner': 1, 'rec_block_num': 1, 'enhance': 1, 'enhance_type': 5, 'seed': 34, 'batch_size': 64, 'share_head': 0, 'add_noise': 1, 'add_norm': 0, 'jitter_sigma': 0.4, 'slope_rate': 0.01, 'slope_range': 0.2, 'alpha': 10.0, 'beta': 1.0, 'gamma': 0.15, 'feature_jittering': 1, 'rec_intra_feature': 0, 'rec_ori': 1, 'mid_dim': 128, 'test_en': 0, 'debugger': 0, 'summary': 0, 'omega': 1.0, 'theta': 1.5, 'mask_border': 1, 'sup_weight': 10.0, 'rec_length_ratio': 0.8, 'ref_dropout': 0.0, 'ref_block_num': 2, 'add_FFN': 0, 'add_residual': 0, 'rec_all': 0, 'e_layers': 2, 'early_break': 0, 'early_stop': 10, '/* model related args*/': '//', 'model_name': 'informer', 'label_len': 48, 'features': 'M', 'target': 'OT', 'graph_input': False, 'individual': False, 'd_layers': 1, 'factor': 3, 'des': 'Exp', 'padding_patch': 'end', 'revin': 1, 'affine': 0, 'subtract_last': 0, 'decomposition': 0, 'kernel_size': 25, 'output_attention': 0, 'embed_type': 0, 'activation': 'gelu', 'distil': 1, 'linear_output': 0, 'pct_start': 0.3, '/*train related args*/': '//', 'epoch': 30, '/*dataset related args*/': '//', 'save_data_path': 'data/ECL/', 'data_process': False, 'embed': 'timeF', 'freq': 'h', 'begin_phase': 0, 'end_phase': 1, 'phase_len': 26304, 'val_ratio': 0.33, 'graph_size': 321, '/*strategy related args*/': '//', 'strategy': 'incremental', 'increase': False, 'detect': False, 'detect_strategy': 'feature', 'replay': False, 'replay_strategy': 'random', 'repaly_num_samples': 100, 'ewc': False, 'ewc_strategy': 'ewc', 'ewc_lambda': 0.0001, 'subgraph_train': False, 'num_hops': 2, 'logname': 'ECL-Informer', 'time': '2023-09-02-20:12:28.705896', 'path': 'exp/ECL-Informer2023-09-02-20:12:28.705896', 'num_workers': 4, 'start_train': 0, 'train_mode': 'pretrain', 'get_score': False, 'use_cm': True, 'logger': <Logger __main__ (INFO)>}
2023-09-02 20:12:28,706 - [*] phase 0 start training
train 33745
val 10801
test 10801
2023-09-02 20:12:28,998 - [*] phase 0 Dataset load!
dropout 0.05
dropout 0.05
2023-09-02 20:12:30,573 - [*] phase 0 Training start
train 33745
2023-09-02 20:19:54,208 - epoch:0, training loss:0.2609 validation loss:0.4460
train 33745
vs, vt 0.44604860598871693 0.475749016689831
Updating learning rate to 6.8959628024441156e-06
Updating learning rate to 6.8959628024441156e-06
train 33745
2023-09-02 20:24:45,199 - logger name:exp/ECL-Informer2023-09-02-20:24:45.198941/ECL-Informer.log
2023-09-02 20:24:45,199 - params : {'loss': 'mse', 'conf': 'ECL-Informer', 'data_name': 'exchange_rate', 'iteration': 1, 'train': 1, 'mainrs': 0, 'abl': 0, 'load': True, 'build_graph': False, 'same_init': True, 'grad_norm': False, 'refiner_residual': 0, 'root_path': '', 'exp_path': 'exp/', 'val_test_mix': False, 'lr': 0.0001, 'lradj': 'TST', 'dropout': 0.05, 'fc_dropout': 0.05, 'head_dropout': 0.0, 'patch_len': 16, 'stride': 8, 'd_ff': 2048, 'd_model': 512, 'n_heads': 8, 'seq_len': 96, 'pred_len': 96, 'noise_rate': 0.5, 'device': device(type='cuda', index=1), 'test_model_path': '/Disk/fhyega/code/BASE/exp/ECL-PatchTST2023-08-26-13:08:31.837686/0/best_model.pkl', 'idx': -1, 'aligner': 0, 'always_align': 1, 'refiner': 0, 'rec_block_num': 1, 'enhance': 0, 'enhance_type': 5, 'seed': 34, 'batch_size': 64, 'share_head': 0, 'add_noise': 1, 'add_norm': 0, 'jitter_sigma': 0.4, 'slope_rate': 0.01, 'slope_range': 0.2, 'alpha': 10.0, 'beta': 1.0, 'gamma': 0.15, 'feature_jittering': 1, 'rec_intra_feature': 0, 'rec_ori': 1, 'mid_dim': 128, 'test_en': 0, 'debugger': 0, 'summary': 0, 'omega': 1.0, 'theta': 1.5, 'mask_border': 1, 'sup_weight': 10.0, 'rec_length_ratio': 0.8, 'ref_dropout': 0.0, 'ref_block_num': 2, 'add_FFN': 0, 'add_residual': 0, 'rec_all': 0, 'e_layers': 2, 'early_break': 0, 'early_stop': 10, '/* model related args*/': '//', 'model_name': 'informer', 'label_len': 48, 'features': 'M', 'target': 'OT', 'graph_input': False, 'individual': False, 'd_layers': 1, 'factor': 3, 'des': 'Exp', 'padding_patch': 'end', 'revin': 1, 'affine': 0, 'subtract_last': 0, 'decomposition': 0, 'kernel_size': 25, 'output_attention': 0, 'embed_type': 0, 'activation': 'gelu', 'distil': 1, 'linear_output': 0, 'pct_start': 0.3, '/*train related args*/': '//', 'epoch': 30, '/*dataset related args*/': '//', 'save_data_path': 'data/ECL/', 'data_process': False, 'embed': 'timeF', 'freq': 'h', 'begin_phase': 0, 'end_phase': 1, 'phase_len': 26304, 'val_ratio': 0.33, 'graph_size': 321, '/*strategy related args*/': '//', 'strategy': 'incremental', 'increase': False, 'detect': False, 'detect_strategy': 'feature', 'replay': False, 'replay_strategy': 'random', 'repaly_num_samples': 100, 'ewc': False, 'ewc_strategy': 'ewc', 'ewc_lambda': 0.0001, 'subgraph_train': False, 'num_hops': 2, 'logname': 'ECL-Informer', 'time': '2023-09-02-20:24:45.198941', 'path': 'exp/ECL-Informer2023-09-02-20:24:45.198941', 'num_workers': 4, 'start_train': 0, 'train_mode': 'pretrain', 'get_score': False, 'use_cm': True, 'logger': <Logger __main__ (INFO)>}
2023-09-02 20:24:45,199 - [*] phase 0 start training
5311 760 1517 0.7 0.2 7588
train 5120
5311 760 1517 0.7 0.2 7588
val 665
5311 760 1517 0.7 0.2 7588
test 1422
2023-09-02 20:24:45,235 - [*] phase 0 Dataset load!
dropout 0.05
dropout 0.05
2023-09-02 20:24:46,768 - [*] phase 0 Training start
5311 760 1517 0.7 0.2 7588
train 5120
2023-09-02 20:25:20,074 - epoch:0, training loss:0.6834 validation loss:2.2193
5311 760 1517 0.7 0.2 7588
train 5120
vs, vt 2.2192557616667314 2.8238452781330454
Updating learning rate to 6.976011711089559e-06
Updating learning rate to 6.976011711089559e-06
5311 760 1517 0.7 0.2 7588
train 5120
vs, vt 1.6097406582398848 2.344974398612976
need align? ->  False 2.344974398612976
2023-09-02 20:26:28,411 - epoch:1, training loss:0.2985 validation loss:1.6097
Updating learning rate to 1.5535019940002333e-05
Updating learning rate to 1.5535019940002333e-05
5311 760 1517 0.7 0.2 7588
train 5120
vs, vt 1.2427106418392875 1.8876768838275562
need align? ->  False 1.8876768838275562
2023-09-02 20:27:19,201 - epoch:2, training loss:0.2127 validation loss:1.2427
Updating learning rate to 2.861570348988177e-05
Updating learning rate to 2.861570348988177e-05
5311 760 1517 0.7 0.2 7588
train 5120
vs, vt 1.1390849947929382 1.3109112950888546
need align? ->  False 1.3109112950888546
2023-09-02 20:28:07,902 - epoch:3, training loss:0.1544 validation loss:1.1391
Updating learning rate to 4.4596051217665496e-05
Updating learning rate to 4.4596051217665496e-05
5311 760 1517 0.7 0.2 7588
train 5120
vs, vt 1.1710209318182685 0.9545051482590762
need align? ->  True 0.9545051482590762
2023-09-02 20:28:52,233 - epoch:4, training loss:0.1223 validation loss:1.1710
Updating learning rate to 6.149449220730483e-05
Updating learning rate to 6.149449220730483e-05
5311 760 1517 0.7 0.2 7588
train 5120
vs, vt 1.0875686258077621 0.9094775061715733
need align? ->  True 0.9094775061715733
2023-09-02 20:29:36,895 - epoch:5, training loss:0.1009 validation loss:1.0876
Updating learning rate to 7.721561153028634e-05
Updating learning rate to 7.721561153028634e-05
5311 760 1517 0.7 0.2 7588
train 5120
vs, vt 1.173756249926307 1.0280954959717663
need align? ->  True 0.9094775061715733
2023-09-02 20:30:21,530 - epoch:6, training loss:0.0876 validation loss:1.1738
Updating learning rate to 8.980998271925046e-05
Updating learning rate to 8.980998271925046e-05
5311 760 1517 0.7 0.2 7588
train 5120
vs, vt 1.0923066775907169 1.2677728560837833
need align? ->  True 0.9094775061715733
2023-09-02 20:31:06,546 - epoch:7, training loss:0.0781 validation loss:1.0923
Updating learning rate to 9.771589760119031e-05
Updating learning rate to 9.771589760119031e-05
5311 760 1517 0.7 0.2 7588
train 5120
vs, vt 1.0858328545635396 1.1068324676968835
need align? ->  True 0.9094775061715733
2023-09-02 20:31:52,546 - epoch:8, training loss:0.0664 validation loss:1.0858
Updating learning rate to 9.99910353721214e-05
Updating learning rate to 9.99910353721214e-05
5311 760 1517 0.7 0.2 7588
train 5120
vs, vt 1.1021634868600152 1.2611364424228668
need align? ->  True 0.9094775061715733
2023-09-02 20:32:36,647 - epoch:9, training loss:0.0595 validation loss:1.1022
Updating learning rate to 9.927559942620054e-05
Updating learning rate to 9.927559942620054e-05
5311 760 1517 0.7 0.2 7588
train 5120
vs, vt 1.0297690210017292 1.275075457312844
need align? ->  True 0.9094775061715733
2023-09-02 20:33:22,017 - epoch:10, training loss:0.0529 validation loss:1.0298
Updating learning rate to 9.743144315548365e-05
Updating learning rate to 9.743144315548365e-05
5311 760 1517 0.7 0.2 7588
train 5120
vs, vt 1.0527439943768762 1.2319619845260272
need align? ->  True 0.9094775061715733
2023-09-02 20:34:11,490 - epoch:11, training loss:0.0498 validation loss:1.0527
Updating learning rate to 9.450080947812248e-05
Updating learning rate to 9.450080947812248e-05
5311 760 1517 0.7 0.2 7588
train 5120
vs, vt 1.0426965139128945 1.3490131443197078
need align? ->  True 0.9094775061715733
2023-09-02 20:34:56,868 - epoch:12, training loss:0.0458 validation loss:1.0427
Updating learning rate to 9.05508285611921e-05
Updating learning rate to 9.05508285611921e-05
5311 760 1517 0.7 0.2 7588
train 5120
vs, vt 1.055880988186056 1.4313258013942025
need align? ->  True 0.9094775061715733
2023-09-02 20:35:42,806 - epoch:13, training loss:0.0424 validation loss:1.0559
Updating learning rate to 8.567198011252667e-05
Updating learning rate to 8.567198011252667e-05
5311 760 1517 0.7 0.2 7588
train 5120
vs, vt 1.0920703505927867 1.4581124647097155
need align? ->  True 0.9094775061715733
2023-09-02 20:36:28,098 - epoch:14, training loss:0.0414 validation loss:1.0921
Updating learning rate to 7.997602081943336e-05
Updating learning rate to 7.997602081943336e-05
5311 760 1517 0.7 0.2 7588
train 5120
vs, vt 1.124873386187987 1.5553799054839395
need align? ->  True 0.9094775061715733
2023-09-02 20:37:11,285 - epoch:15, training loss:0.0375 validation loss:1.1249
Updating learning rate to 7.359342440913083e-05
Updating learning rate to 7.359342440913083e-05
5311 760 1517 0.7 0.2 7588
train 5120
vs, vt 1.1096284795891156 1.5454175011678175
need align? ->  True 0.9094775061715733
2023-09-02 20:38:01,993 - epoch:16, training loss:0.0362 validation loss:1.1096
Updating learning rate to 6.667039296982475e-05
Updating learning rate to 6.667039296982475e-05
5311 760 1517 0.7 0.2 7588
train 5120
vs, vt 1.0853600312363019 1.5191960795359178
need align? ->  True 0.9094775061715733
2023-09-02 20:38:51,656 - epoch:17, training loss:0.0341 validation loss:1.0854
Updating learning rate to 5.936550799219284e-05
Updating learning rate to 5.936550799219284e-05
5311 760 1517 0.7 0.2 7588
train 5120
vs, vt 1.0397756451910192 1.4194602641192349
need align? ->  True 0.9094775061715733
2023-09-02 20:39:36,568 - epoch:18, training loss:0.0332 validation loss:1.0398
Updating learning rate to 5.184609784374835e-05
Updating learning rate to 5.184609784374835e-05
5311 760 1517 0.7 0.2 7588
train 5120
vs, vt 1.068131685256958 1.4686267917806453
need align? ->  True 0.9094775061715733
2023-09-02 20:40:22,387 - epoch:19, training loss:0.0314 validation loss:1.0681
Updating learning rate to 4.428440488404313e-05
Updating learning rate to 4.428440488404313e-05
5311 760 1517 0.7 0.2 7588
train 5120
vs, vt 1.1328472251241857 1.5273624116724187
need align? ->  True 0.9094775061715733
2023-09-02 20:41:14,596 - epoch:20, training loss:0.0304 validation loss:1.1328
Updating learning rate to 3.685364001817127e-05
Updating learning rate to 3.685364001817127e-05
5311 760 1517 0.7 0.2 7588
train 5120
vs, vt 1.0668218339031392 1.4860992377454585
need align? ->  True 0.9094775061715733
2023-09-02 20:42:00,944 - epoch:21, training loss:0.0300 validation loss:1.0668
dropout 0.05
dropout 0.05
check exp/ECL-Informer2023-09-02-20:24:45.198941/0/1.0298_epoch_10.pkl  &  0.9094775061715733
2023-09-02 20:42:05,309 - [*] loss:0.9784
2023-09-02 20:42:05,311 - [*] phase 0, testing
2023-09-02 20:42:05,336 - T:96	MAE	0.789539	RMSE	0.982474	MAPE	174.952424
2023-09-02 20:42:05,336 - 96	mae	0.7895	
2023-09-02 20:42:05,336 - 96	rmse	0.9825	
2023-09-02 20:42:05,336 - 96	mape	174.9524	
2023-09-02 20:42:09,504 - [*] loss:0.9786
2023-09-02 20:42:09,507 - [*] phase 0, testing
2023-09-02 20:42:09,526 - T:96	MAE	0.789688	RMSE	0.982626	MAPE	174.913287
2023-09-02 20:42:11,791 - logger name:exp/ECL-Informer2023-09-02-20:42:11.788442/ECL-Informer.log
2023-09-02 20:42:11,791 - params : {'loss': 'mse', 'conf': 'ECL-Informer', 'data_name': 'exchange_rate', 'iteration': 1, 'train': 1, 'mainrs': 0, 'abl': 0, 'load': True, 'build_graph': False, 'same_init': True, 'grad_norm': False, 'refiner_residual': 0, 'root_path': '', 'exp_path': 'exp/', 'val_test_mix': False, 'lr': 0.0001, 'lradj': 'TST', 'dropout': 0.05, 'fc_dropout': 0.05, 'head_dropout': 0.0, 'patch_len': 16, 'stride': 8, 'd_ff': 2048, 'd_model': 512, 'n_heads': 8, 'seq_len': 96, 'pred_len': 192, 'noise_rate': 0.5, 'device': device(type='cuda', index=1), 'test_model_path': '/Disk/fhyega/code/BASE/exp/ECL-PatchTST2023-08-26-13:08:31.837686/0/best_model.pkl', 'idx': -1, 'aligner': 0, 'always_align': 1, 'refiner': 0, 'rec_block_num': 1, 'enhance': 0, 'enhance_type': 5, 'seed': 34, 'batch_size': 64, 'share_head': 0, 'add_noise': 1, 'add_norm': 0, 'jitter_sigma': 0.4, 'slope_rate': 0.01, 'slope_range': 0.2, 'alpha': 10.0, 'beta': 1.0, 'gamma': 0.15, 'feature_jittering': 1, 'rec_intra_feature': 0, 'rec_ori': 1, 'mid_dim': 128, 'test_en': 0, 'debugger': 0, 'summary': 0, 'omega': 1.0, 'theta': 1.5, 'mask_border': 1, 'sup_weight': 10.0, 'rec_length_ratio': 0.8, 'ref_dropout': 0.0, 'ref_block_num': 2, 'add_FFN': 0, 'add_residual': 0, 'rec_all': 0, 'e_layers': 2, 'early_break': 0, 'early_stop': 10, '/* model related args*/': '//', 'model_name': 'informer', 'label_len': 48, 'features': 'M', 'target': 'OT', 'graph_input': False, 'individual': False, 'd_layers': 1, 'factor': 3, 'des': 'Exp', 'padding_patch': 'end', 'revin': 1, 'affine': 0, 'subtract_last': 0, 'decomposition': 0, 'kernel_size': 25, 'output_attention': 0, 'embed_type': 0, 'activation': 'gelu', 'distil': 1, 'linear_output': 0, 'pct_start': 0.3, '/*train related args*/': '//', 'epoch': 30, '/*dataset related args*/': '//', 'save_data_path': 'data/ECL/', 'data_process': False, 'embed': 'timeF', 'freq': 'h', 'begin_phase': 0, 'end_phase': 1, 'phase_len': 26304, 'val_ratio': 0.33, 'graph_size': 321, '/*strategy related args*/': '//', 'strategy': 'incremental', 'increase': False, 'detect': False, 'detect_strategy': 'feature', 'replay': False, 'replay_strategy': 'random', 'repaly_num_samples': 100, 'ewc': False, 'ewc_strategy': 'ewc', 'ewc_lambda': 0.0001, 'subgraph_train': False, 'num_hops': 2, 'logname': 'ECL-Informer', 'time': '2023-09-02-20:42:11.788442', 'path': 'exp/ECL-Informer2023-09-02-20:42:11.788442', 'num_workers': 4, 'start_train': 0, 'train_mode': 'pretrain', 'get_score': False, 'use_cm': True, 'logger': <Logger __main__ (INFO)>}
2023-09-02 20:42:11,791 - [*] phase 0 start training
5311 760 1517 0.7 0.2 7588
train 5024
5311 760 1517 0.7 0.2 7588
val 569
5311 760 1517 0.7 0.2 7588
test 1326
2023-09-02 20:42:11,824 - [*] phase 0 Dataset load!
dropout 0.05
dropout 0.05
2023-09-02 20:42:13,222 - [*] phase 0 Training start
5311 760 1517 0.7 0.2 7588
train 5024
2023-09-02 20:42:46,361 - epoch:0, training loss:0.7301 validation loss:2.6589
5311 760 1517 0.7 0.2 7588
train 5024
vs, vt 2.658943282233344 3.47548606660631
Updating learning rate to 6.90293469063218e-06
Updating learning rate to 6.90293469063218e-06
5311 760 1517 0.7 0.2 7588
train 5024
vs, vt 1.862679574224684 2.8144856691360474
need align? ->  False 2.8144856691360474
2023-09-02 20:44:01,504 - epoch:1, training loss:0.3498 validation loss:1.8627
Updating learning rate to 1.5260612520108893e-05
Updating learning rate to 1.5260612520108893e-05
5311 760 1517 0.7 0.2 7588
train 5024
vs, vt 2.068204859892527 1.908241371313731
need align? ->  True 1.908241371313731
2023-09-02 20:44:53,740 - epoch:2, training loss:0.2479 validation loss:2.0682
Updating learning rate to 2.8062125450750323e-05
Updating learning rate to 2.8062125450750323e-05
5311 760 1517 0.7 0.2 7588
train 5024
vs, vt 2.0757243699497647 1.9116772280799017
need align? ->  True 1.908241371313731
2023-09-02 20:45:42,665 - epoch:3, training loss:0.1693 validation loss:2.0757
Updating learning rate to 4.375905865010084e-05
Updating learning rate to 4.375905865010084e-05
5311 760 1517 0.7 0.2 7588
train 5024
vs, vt 1.3387712637583415 1.6123074491818745
need align? ->  False 1.6123074491818745
2023-09-02 20:46:32,639 - epoch:4, training loss:0.1296 validation loss:1.3388
Updating learning rate to 6.045277995478833e-05
Updating learning rate to 6.045277995478833e-05
5311 760 1517 0.7 0.2 7588
train 5024
vs, vt 1.2618039151032765 1.2582476370864444
need align? ->  True 1.2582476370864444
2023-09-02 20:47:31,053 - epoch:5, training loss:0.1069 validation loss:1.2618
Updating learning rate to 7.612409008601602e-05
Updating learning rate to 7.612409008601602e-05
5311 760 1517 0.7 0.2 7588
train 5024
vs, vt 1.3803000913725958 1.574973954094781
need align? ->  True 1.2582476370864444
2023-09-02 20:48:23,274 - epoch:6, training loss:0.0909 validation loss:1.3803
Updating learning rate to 8.887745613430072e-05
Updating learning rate to 8.887745613430072e-05
5311 760 1517 0.7 0.2 7588
train 5024
vs, vt 1.2663716077804565 1.447720252805286
need align? ->  True 1.2582476370864444
2023-09-02 20:49:12,096 - epoch:7, training loss:0.0820 validation loss:1.2664
Updating learning rate to 9.717028690281343e-05
Updating learning rate to 9.717028690281343e-05
5311 760 1517 0.7 0.2 7588
train 5024
vs, vt 1.2979149851534102 1.628350489669376
need align? ->  True 1.2582476370864444
2023-09-02 20:50:08,828 - epoch:8, training loss:0.0711 validation loss:1.2979
Updating learning rate to 9.999990803764402e-05
Updating learning rate to 9.999990803764402e-05
5311 760 1517 0.7 0.2 7588
train 5024
vs, vt 1.1563969055811565 1.582034495141771
need align? ->  False 1.2582476370864444
2023-09-02 20:51:00,359 - epoch:9, training loss:0.0624 validation loss:1.1564
Updating learning rate to 9.942715993806832e-05
Updating learning rate to 9.942715993806832e-05
5311 760 1517 0.7 0.2 7588
train 5024
vs, vt 1.3098848793241713 1.7729053762223985
need align? ->  True 1.2582476370864444
2023-09-02 20:51:50,143 - epoch:10, training loss:0.0601 validation loss:1.3099
Updating learning rate to 9.775029522906882e-05
Updating learning rate to 9.775029522906882e-05
5311 760 1517 0.7 0.2 7588
train 5024
vs, vt 1.188786506652832 1.5822183556026883
need align? ->  False 1.2582476370864444
2023-09-02 20:52:42,506 - epoch:11, training loss:0.0507 validation loss:1.1888
Updating learning rate to 9.500677229730908e-05
Updating learning rate to 9.500677229730908e-05
5311 760 1517 0.7 0.2 7588
train 5024
vs, vt 1.3486052221722074 1.6816791163550482
need align? ->  True 1.2582476370864444
2023-09-02 20:53:38,560 - epoch:12, training loss:0.0495 validation loss:1.3486
Updating learning rate to 9.12578769115494e-05
Updating learning rate to 9.12578769115494e-05
5311 760 1517 0.7 0.2 7588
train 5024
vs, vt 1.241507546769248 1.7695795231395297
need align? ->  False 1.2582476370864444
2023-09-02 20:54:29,300 - epoch:13, training loss:0.0450 validation loss:1.2415
Updating learning rate to 8.658735319984452e-05
Updating learning rate to 8.658735319984452e-05
5311 760 1517 0.7 0.2 7588
train 5024
vs, vt 1.182950195338991 1.675553798675537
need align? ->  False 1.2582476370864444
2023-09-02 20:55:17,885 - epoch:14, training loss:0.0438 validation loss:1.1830
Updating learning rate to 8.109953294410583e-05
Updating learning rate to 8.109953294410583e-05
5311 760 1517 0.7 0.2 7588
train 5024
vs, vt 1.2527796063158247 1.744970851474338
need align? ->  False 1.2582476370864444
2023-09-02 20:56:13,393 - epoch:15, training loss:0.0406 validation loss:1.2528
Updating learning rate to 7.491700498049654e-05
Updating learning rate to 7.491700498049654e-05
5311 760 1517 0.7 0.2 7588
train 5024
vs, vt 1.2628149953153398 1.8380171987745497
need align? ->  True 1.2582476370864444
2023-09-02 20:57:04,703 - epoch:16, training loss:0.0389 validation loss:1.2628
Updating learning rate to 6.817787676740376e-05
Updating learning rate to 6.817787676740376e-05
5311 760 1517 0.7 0.2 7588
train 5024
vs, vt 1.2490428586800892 1.8988325794537861
need align? ->  False 1.2582476370864444
2023-09-02 20:57:53,586 - epoch:17, training loss:0.0365 validation loss:1.2490
Updating learning rate to 6.103268929303383e-05
Updating learning rate to 6.103268929303383e-05
5311 760 1517 0.7 0.2 7588
train 5024
vs, vt 1.2760317126909893 1.9822716183132596
need align? ->  True 1.2582476370864444
2023-09-02 20:58:44,140 - epoch:18, training loss:0.0357 validation loss:1.2760
Updating learning rate to 5.364105423849727e-05
Updating learning rate to 5.364105423849727e-05
5311 760 1517 0.7 0.2 7588
train 5024
vs, vt 1.2520588338375092 1.8891546659999423
need align? ->  False 1.2582476370864444
2023-09-02 20:59:40,305 - epoch:19, training loss:0.0355 validation loss:1.2521
Updating learning rate to 4.6168088516603216e-05
Updating learning rate to 4.6168088516603216e-05
5311 760 1517 0.7 0.2 7588
train 5024
vs, vt 1.2655547625488706 1.8905265794859991
need align? ->  True 1.2582476370864444
2023-09-02 21:00:30,564 - epoch:20, training loss:0.0330 validation loss:1.2656
dropout 0.05
dropout 0.05
check exp/ECL-Informer2023-09-02-20:42:11.788442/0/1.1564_epoch_9.pkl  &  1.2582476370864444
2023-09-02 21:00:35,453 - [*] loss:1.1725
2023-09-02 21:00:35,458 - [*] phase 0, testing
2023-09-02 21:00:35,499 - T:192	MAE	0.876623	RMSE	1.176848	MAPE	237.139797
2023-09-02 21:00:35,499 - 192	mae	0.8766	
2023-09-02 21:00:35,499 - 192	rmse	1.1768	
2023-09-02 21:00:35,499 - 192	mape	237.1398	
2023-09-02 21:00:39,605 - [*] loss:1.1725
2023-09-02 21:00:39,611 - [*] phase 0, testing
2023-09-02 21:00:39,657 - T:192	MAE	0.876649	RMSE	1.176917	MAPE	237.300754
2023-09-02 21:00:42,051 - logger name:exp/ECL-Informer2023-09-02-21:00:42.051015/ECL-Informer.log
2023-09-02 21:00:42,051 - params : {'loss': 'mse', 'conf': 'ECL-Informer', 'data_name': 'exchange_rate', 'iteration': 1, 'train': 1, 'mainrs': 0, 'abl': 0, 'load': True, 'build_graph': False, 'same_init': True, 'grad_norm': False, 'refiner_residual': 0, 'root_path': '', 'exp_path': 'exp/', 'val_test_mix': False, 'lr': 0.0001, 'lradj': 'TST', 'dropout': 0.05, 'fc_dropout': 0.05, 'head_dropout': 0.0, 'patch_len': 16, 'stride': 8, 'd_ff': 2048, 'd_model': 512, 'n_heads': 8, 'seq_len': 96, 'pred_len': 336, 'noise_rate': 0.5, 'device': device(type='cuda', index=1), 'test_model_path': '/Disk/fhyega/code/BASE/exp/ECL-PatchTST2023-08-26-13:08:31.837686/0/best_model.pkl', 'idx': -1, 'aligner': 0, 'always_align': 1, 'refiner': 0, 'rec_block_num': 1, 'enhance': 0, 'enhance_type': 5, 'seed': 34, 'batch_size': 64, 'share_head': 0, 'add_noise': 1, 'add_norm': 0, 'jitter_sigma': 0.4, 'slope_rate': 0.01, 'slope_range': 0.2, 'alpha': 10.0, 'beta': 1.0, 'gamma': 0.15, 'feature_jittering': 1, 'rec_intra_feature': 0, 'rec_ori': 1, 'mid_dim': 128, 'test_en': 0, 'debugger': 0, 'summary': 0, 'omega': 1.0, 'theta': 1.5, 'mask_border': 1, 'sup_weight': 10.0, 'rec_length_ratio': 0.8, 'ref_dropout': 0.0, 'ref_block_num': 2, 'add_FFN': 0, 'add_residual': 0, 'rec_all': 0, 'e_layers': 2, 'early_break': 0, 'early_stop': 10, '/* model related args*/': '//', 'model_name': 'informer', 'label_len': 48, 'features': 'M', 'target': 'OT', 'graph_input': False, 'individual': False, 'd_layers': 1, 'factor': 3, 'des': 'Exp', 'padding_patch': 'end', 'revin': 1, 'affine': 0, 'subtract_last': 0, 'decomposition': 0, 'kernel_size': 25, 'output_attention': 0, 'embed_type': 0, 'activation': 'gelu', 'distil': 1, 'linear_output': 0, 'pct_start': 0.3, '/*train related args*/': '//', 'epoch': 30, '/*dataset related args*/': '//', 'save_data_path': 'data/ECL/', 'data_process': False, 'embed': 'timeF', 'freq': 'h', 'begin_phase': 0, 'end_phase': 1, 'phase_len': 26304, 'val_ratio': 0.33, 'graph_size': 321, '/*strategy related args*/': '//', 'strategy': 'incremental', 'increase': False, 'detect': False, 'detect_strategy': 'feature', 'replay': False, 'replay_strategy': 'random', 'repaly_num_samples': 100, 'ewc': False, 'ewc_strategy': 'ewc', 'ewc_lambda': 0.0001, 'subgraph_train': False, 'num_hops': 2, 'logname': 'ECL-Informer', 'time': '2023-09-02-21:00:42.051015', 'path': 'exp/ECL-Informer2023-09-02-21:00:42.051015', 'num_workers': 4, 'start_train': 0, 'train_mode': 'pretrain', 'get_score': False, 'use_cm': True, 'logger': <Logger __main__ (INFO)>}
2023-09-02 21:00:42,051 - [*] phase 0 start training
5311 760 1517 0.7 0.2 7588
train 4880
5311 760 1517 0.7 0.2 7588
val 425
5311 760 1517 0.7 0.2 7588
test 1182
2023-09-02 21:00:42,084 - [*] phase 0 Dataset load!
dropout 0.05
dropout 0.05
2023-09-02 21:00:43,404 - [*] phase 0 Training start
5311 760 1517 0.7 0.2 7588
train 4880
2023-09-02 21:01:19,973 - epoch:0, training loss:0.7634 validation loss:3.3793
5311 760 1517 0.7 0.2 7588
train 4880
vs, vt 3.3792807374681746 4.196068559374128
Updating learning rate to 6.903150433075093e-06
Updating learning rate to 6.903150433075093e-06
5311 760 1517 0.7 0.2 7588
train 4880
vs, vt 2.3414038590022495 3.704326186861311
need align? ->  False 3.704326186861311
2023-09-02 21:02:48,102 - epoch:1, training loss:0.4094 validation loss:2.3414
Updating learning rate to 1.5261423297422723e-05
Updating learning rate to 1.5261423297422723e-05
5311 760 1517 0.7 0.2 7588
train 4880
vs, vt 2.8040544475827898 2.4846932547433034
need align? ->  True 2.4846932547433034
2023-09-02 21:03:45,472 - epoch:2, training loss:0.2833 validation loss:2.8041
Updating learning rate to 2.8063763447797404e-05
Updating learning rate to 2.8063763447797404e-05
5311 760 1517 0.7 0.2 7588
train 4880
vs, vt 3.6161793981279646 2.536978619439261
need align? ->  True 2.4846932547433034
2023-09-02 21:04:46,572 - epoch:3, training loss:0.1919 validation loss:3.6162
Updating learning rate to 4.376154091120189e-05
Updating learning rate to 4.376154091120189e-05
5311 760 1517 0.7 0.2 7588
train 4880
vs, vt 3.0051173993519376 2.714680859020778
need align? ->  True 2.4846932547433034
2023-09-02 21:05:51,891 - epoch:4, training loss:0.1422 validation loss:3.0051
Updating learning rate to 6.045588029425285e-05
Updating learning rate to 6.045588029425285e-05
5311 760 1517 0.7 0.2 7588
train 4880
vs, vt 3.013882500784738 2.632864696638925
need align? ->  True 2.4846932547433034
2023-09-02 21:06:47,998 - epoch:5, training loss:0.1207 validation loss:3.0139
Updating learning rate to 7.612735748820835e-05
Updating learning rate to 7.612735748820835e-05
5311 760 1517 0.7 0.2 7588
train 4880
vs, vt 2.721728410039629 2.774606466293335
need align? ->  True 2.4846932547433034
2023-09-02 21:07:47,696 - epoch:6, training loss:0.1000 validation loss:2.7217
Updating learning rate to 8.888027850129511e-05
Updating learning rate to 8.888027850129511e-05
5311 760 1517 0.7 0.2 7588
train 4880
vs, vt 2.414225629397801 2.9744008779525757
need align? ->  False 2.4846932547433034
2023-09-02 21:08:51,308 - epoch:7, training loss:0.0858 validation loss:2.4142
Updating learning rate to 9.717199132675832e-05
Updating learning rate to 9.717199132675832e-05
5311 760 1517 0.7 0.2 7588
train 4880
vs, vt 2.719155413763864 3.280485595975603
need align? ->  True 2.4846932547433034
2023-09-02 21:09:47,676 - epoch:8, training loss:0.0780 validation loss:2.7192
Updating learning rate to 9.999990313383577e-05
Updating learning rate to 9.999990313383577e-05
5311 760 1517 0.7 0.2 7588
train 4880
vs, vt 2.7154461996895924 3.2883739471435547
need align? ->  True 2.4846932547433034
2023-09-02 21:10:48,494 - epoch:9, training loss:0.0699 validation loss:2.7154
Updating learning rate to 9.942677896656872e-05
Updating learning rate to 9.942677896656872e-05
5311 760 1517 0.7 0.2 7588
train 4880
vs, vt 2.5644683156694685 3.2626142501831055
need align? ->  True 2.4846932547433034
2023-09-02 21:11:48,942 - epoch:10, training loss:0.0655 validation loss:2.5645
Updating learning rate to 9.774954670015166e-05
Updating learning rate to 9.774954670015166e-05
5311 760 1517 0.7 0.2 7588
train 4880
vs, vt 2.4377321345465526 2.9186667033604214
need align? ->  False 2.4846932547433034
2023-09-02 21:12:46,582 - epoch:11, training loss:0.0595 validation loss:2.4377
Updating learning rate to 9.500567293187344e-05
Updating learning rate to 9.500567293187344e-05
5311 760 1517 0.7 0.2 7588
train 4880
vs, vt 2.319578068596976 2.8806042160306657
need align? ->  False 2.4846932547433034
2023-09-02 21:13:48,621 - epoch:12, training loss:0.0551 validation loss:2.3196
Updating learning rate to 9.125645126760246e-05
Updating learning rate to 9.125645126760246e-05
5311 760 1517 0.7 0.2 7588
train 4880
vs, vt 2.321778518812997 2.922460573060172
need align? ->  False 2.4846932547433034
2023-09-02 21:14:51,754 - epoch:13, training loss:0.0535 validation loss:2.3218
Updating learning rate to 8.658563312391629e-05
Updating learning rate to 8.658563312391629e-05
5311 760 1517 0.7 0.2 7588
train 4880
vs, vt 2.5972573246274675 3.172950948987688
need align? ->  True 2.4846932547433034
2023-09-02 21:15:50,111 - epoch:14, training loss:0.0483 validation loss:2.5973
Updating learning rate to 8.109755685985018e-05
Updating learning rate to 8.109755685985018e-05
5311 760 1517 0.7 0.2 7588
train 4880
vs, vt 2.504719070025853 3.0668366636548723
need align? ->  True 2.4846932547433034
2023-09-02 21:16:52,779 - epoch:15, training loss:0.0448 validation loss:2.5047
Updating learning rate to 7.491481703037036e-05
Updating learning rate to 7.491481703037036e-05
5311 760 1517 0.7 0.2 7588
train 4880
vs, vt 2.47701142515455 3.0915546076638356
need align? ->  False 2.4846932547433034
2023-09-02 21:17:51,368 - epoch:16, training loss:0.0442 validation loss:2.4770
Updating learning rate to 6.817552582659738e-05
Updating learning rate to 6.817552582659738e-05
5311 760 1517 0.7 0.2 7588
train 4880
vs, vt 2.362328495298113 2.9898814984730313
need align? ->  False 2.4846932547433034
2023-09-02 21:18:50,661 - epoch:17, training loss:0.0424 validation loss:2.3623
Updating learning rate to 6.103022787768006e-05
Updating learning rate to 6.103022787768006e-05
5311 760 1517 0.7 0.2 7588
train 4880
vs, vt 2.2840881177357266 3.134554215839931
need align? ->  False 2.4846932547433034
2023-09-02 21:19:55,277 - epoch:18, training loss:0.0408 validation loss:2.2841
Updating learning rate to 5.363853733254775e-05
Updating learning rate to 5.363853733254775e-05
5311 760 1517 0.7 0.2 7588
train 4880
vs, vt 2.2873758929116383 3.16608088357108
need align? ->  False 2.4846932547433034
2023-09-02 21:20:56,549 - epoch:19, training loss:0.0402 validation loss:2.2874
Updating learning rate to 4.616557234357781e-05
Updating learning rate to 4.616557234357781e-05
5311 760 1517 0.7 0.2 7588
train 4880
vs, vt 2.2829032966068814 3.3041625704084123
need align? ->  False 2.4846932547433034
2023-09-02 21:21:53,289 - epoch:20, training loss:0.0385 validation loss:2.2829
Updating learning rate to 3.877826659992088e-05
Updating learning rate to 3.877826659992088e-05
5311 760 1517 0.7 0.2 7588
train 4880
vs, vt 2.377415180206299 3.191387959889003
need align? ->  False 2.4846932547433034
2023-09-02 21:23:00,051 - epoch:21, training loss:0.0370 validation loss:2.3774
Updating learning rate to 3.164164030473496e-05
Updating learning rate to 3.164164030473496e-05
5311 760 1517 0.7 0.2 7588
train 4880
vs, vt 2.1980578558785573 3.1672042437962125
need align? ->  False 2.4846932547433034
2023-09-02 21:23:57,564 - epoch:22, training loss:0.0366 validation loss:2.1981
Updating learning rate to 2.49151138965346e-05
Updating learning rate to 2.49151138965346e-05
5311 760 1517 0.7 0.2 7588
train 4880
vs, vt 2.285737548555647 3.2568416595458984
need align? ->  False 2.4846932547433034
2023-09-02 21:24:58,429 - epoch:23, training loss:0.0360 validation loss:2.2857
Updating learning rate to 1.8748946860028664e-05
Updating learning rate to 1.8748946860028664e-05
5311 760 1517 0.7 0.2 7588
train 4880
vs, vt 2.2888361726488387 3.2276643344334195
need align? ->  False 2.4846932547433034
2023-09-02 21:26:01,588 - epoch:24, training loss:0.0352 validation loss:2.2888
Updating learning rate to 1.3280881177528399e-05
Updating learning rate to 1.3280881177528399e-05
5311 760 1517 0.7 0.2 7588
train 4880
vs, vt 2.2729235546929494 3.207776205880301
need align? ->  False 2.4846932547433034
2023-09-02 21:27:01,182 - epoch:25, training loss:0.0348 validation loss:2.2729
Updating learning rate to 8.633064400674335e-06
Updating learning rate to 8.633064400674335e-06
5311 760 1517 0.7 0.2 7588
train 4880
vs, vt 2.280487196786063 3.243403536932809
need align? ->  False 2.4846932547433034
2023-09-02 21:28:08,282 - epoch:26, training loss:0.0347 validation loss:2.2805
Updating learning rate to 4.909321075975339e-06
Updating learning rate to 4.909321075975339e-06
5311 760 1517 0.7 0.2 7588
train 4880
vs, vt 2.2539649520601546 3.2174437046051025
need align? ->  False 2.4846932547433034
2023-09-02 21:29:06,291 - epoch:27, training loss:0.0341 validation loss:2.2540
Updating learning rate to 2.1928334760045798e-06
Updating learning rate to 2.1928334760045798e-06
5311 760 1517 0.7 0.2 7588
train 4880
vs, vt 2.256411910057068 3.2090040275028775
need align? ->  False 2.4846932547433034
2023-09-02 21:30:06,913 - epoch:28, training loss:0.0342 validation loss:2.2564
Updating learning rate to 5.44283444884783e-07
Updating learning rate to 5.44283444884783e-07
5311 760 1517 0.7 0.2 7588
train 4880
vs, vt 2.277112603187561 3.2299835000719344
need align? ->  False 2.4846932547433034
2023-09-02 21:31:12,334 - epoch:29, training loss:0.0342 validation loss:2.2771
Updating learning rate to 4.968661642358393e-10
Updating learning rate to 4.968661642358393e-10
dropout 0.05
dropout 0.05
check exp/ECL-Informer2023-09-02-21:00:42.051015/0/2.1981_epoch_22.pkl  &  2.4846932547433034
2023-09-02 21:31:18,447 - [*] loss:1.6159
2023-09-02 21:31:18,455 - [*] phase 0, testing
2023-09-02 21:31:18,562 - T:336	MAE	1.038779	RMSE	1.615535	MAPE	333.764410
2023-09-02 21:31:18,563 - 336	mae	1.0388	
2023-09-02 21:31:18,563 - 336	rmse	1.6155	
2023-09-02 21:31:18,564 - 336	mape	333.7644	
2023-09-02 21:31:23,743 - [*] loss:1.6165
2023-09-02 21:31:23,750 - [*] phase 0, testing
2023-09-02 21:31:23,816 - T:336	MAE	1.038994	RMSE	1.616173	MAPE	333.635402
2023-09-02 21:31:26,270 - logger name:exp/ECL-Informer2023-09-02-21:31:26.269296/ECL-Informer.log
2023-09-02 21:31:26,270 - params : {'loss': 'mse', 'conf': 'ECL-Informer', 'data_name': 'exchange_rate', 'iteration': 1, 'train': 1, 'mainrs': 0, 'abl': 0, 'load': True, 'build_graph': False, 'same_init': True, 'grad_norm': False, 'refiner_residual': 0, 'root_path': '', 'exp_path': 'exp/', 'val_test_mix': False, 'lr': 0.0001, 'lradj': 'TST', 'dropout': 0.05, 'fc_dropout': 0.05, 'head_dropout': 0.0, 'patch_len': 16, 'stride': 8, 'd_ff': 2048, 'd_model': 512, 'n_heads': 8, 'seq_len': 96, 'pred_len': 720, 'noise_rate': 0.5, 'device': device(type='cuda', index=1), 'test_model_path': '/Disk/fhyega/code/BASE/exp/ECL-PatchTST2023-08-26-13:08:31.837686/0/best_model.pkl', 'idx': -1, 'aligner': 0, 'always_align': 1, 'refiner': 0, 'rec_block_num': 1, 'enhance': 0, 'enhance_type': 5, 'seed': 34, 'batch_size': 64, 'share_head': 0, 'add_noise': 1, 'add_norm': 0, 'jitter_sigma': 0.4, 'slope_rate': 0.01, 'slope_range': 0.2, 'alpha': 10.0, 'beta': 1.0, 'gamma': 0.15, 'feature_jittering': 1, 'rec_intra_feature': 0, 'rec_ori': 1, 'mid_dim': 128, 'test_en': 0, 'debugger': 0, 'summary': 0, 'omega': 1.0, 'theta': 1.5, 'mask_border': 1, 'sup_weight': 10.0, 'rec_length_ratio': 0.8, 'ref_dropout': 0.0, 'ref_block_num': 2, 'add_FFN': 0, 'add_residual': 0, 'rec_all': 0, 'e_layers': 2, 'early_break': 0, 'early_stop': 10, '/* model related args*/': '//', 'model_name': 'informer', 'label_len': 48, 'features': 'M', 'target': 'OT', 'graph_input': False, 'individual': False, 'd_layers': 1, 'factor': 3, 'des': 'Exp', 'padding_patch': 'end', 'revin': 1, 'affine': 0, 'subtract_last': 0, 'decomposition': 0, 'kernel_size': 25, 'output_attention': 0, 'embed_type': 0, 'activation': 'gelu', 'distil': 1, 'linear_output': 0, 'pct_start': 0.3, '/*train related args*/': '//', 'epoch': 30, '/*dataset related args*/': '//', 'save_data_path': 'data/ECL/', 'data_process': False, 'embed': 'timeF', 'freq': 'h', 'begin_phase': 0, 'end_phase': 1, 'phase_len': 26304, 'val_ratio': 0.33, 'graph_size': 321, '/*strategy related args*/': '//', 'strategy': 'incremental', 'increase': False, 'detect': False, 'detect_strategy': 'feature', 'replay': False, 'replay_strategy': 'random', 'repaly_num_samples': 100, 'ewc': False, 'ewc_strategy': 'ewc', 'ewc_lambda': 0.0001, 'subgraph_train': False, 'num_hops': 2, 'logname': 'ECL-Informer', 'time': '2023-09-02-21:31:26.269296', 'path': 'exp/ECL-Informer2023-09-02-21:31:26.269296', 'num_workers': 4, 'start_train': 0, 'train_mode': 'pretrain', 'get_score': False, 'use_cm': True, 'logger': <Logger __main__ (INFO)>}
2023-09-02 21:31:26,271 - [*] phase 0 start training
5311 760 1517 0.7 0.2 7588
train 4496
5311 760 1517 0.7 0.2 7588
val 41
5311 760 1517 0.7 0.2 7588
test 798
2023-09-02 21:31:26,308 - [*] phase 0 Dataset load!
dropout 0.05
dropout 0.05
2023-09-02 21:31:27,933 - [*] phase 0 Training start
5311 760 1517 0.7 0.2 7588
train 4496
2023-09-02 21:32:16,324 - epoch:0, training loss:0.8026 validation loss:4.4459
5311 760 1517 0.7 0.2 7588
train 4496
vs, vt 4.445916652679443 5.540915012359619
Updating learning rate to 6.903871803230679e-06
Updating learning rate to 6.903871803230679e-06
5311 760 1517 0.7 0.2 7588
train 4496
vs, vt 2.8693714141845703 5.0387396812438965
need align? ->  False 5.0387396812438965
2023-09-02 21:34:13,131 - epoch:1, training loss:0.4956 validation loss:2.8694
Updating learning rate to 1.5264134235856163e-05
Updating learning rate to 1.5264134235856163e-05
5311 760 1517 0.7 0.2 7588
train 4496
vs, vt 2.9530439376831055 3.455106019973755
need align? ->  False 3.455106019973755
2023-09-02 21:35:30,466 - epoch:2, training loss:0.3056 validation loss:2.9530
Updating learning rate to 2.8069240200138485e-05
Updating learning rate to 2.8069240200138485e-05
5311 760 1517 0.7 0.2 7588
train 4496
vs, vt 3.529653549194336 3.691760778427124
need align? ->  True 3.455106019973755
2023-09-02 21:36:55,878 - epoch:3, training loss:0.1943 validation loss:3.5297
Updating learning rate to 4.376984027328348e-05
Updating learning rate to 4.376984027328348e-05
5311 760 1517 0.7 0.2 7588
train 4496
vs, vt 4.305858135223389 4.629047870635986
need align? ->  True 3.455106019973755
2023-09-02 21:38:14,374 - epoch:4, training loss:0.1465 validation loss:4.3059
Updating learning rate to 6.046624571169919e-05
Updating learning rate to 6.046624571169919e-05
5311 760 1517 0.7 0.2 7588
train 4496
vs, vt 4.438202857971191 5.398378849029541
need align? ->  True 3.455106019973755
2023-09-02 21:39:39,322 - epoch:5, training loss:0.1233 validation loss:4.4382
Updating learning rate to 7.613828064172216e-05
Updating learning rate to 7.613828064172216e-05
5311 760 1517 0.7 0.2 7588
train 4496
vs, vt 4.545971870422363 5.019510269165039
need align? ->  True 3.455106019973755
2023-09-02 21:40:59,724 - epoch:6, training loss:0.1112 validation loss:4.5460
Updating learning rate to 8.888971254949652e-05
Updating learning rate to 8.888971254949652e-05
5311 760 1517 0.7 0.2 7588
train 4496
vs, vt 4.62108039855957 5.330066680908203
need align? ->  True 3.455106019973755
2023-09-02 21:42:18,776 - epoch:7, training loss:0.0946 validation loss:4.6211
Updating learning rate to 9.71776862863639e-05
Updating learning rate to 9.71776862863639e-05
5311 760 1517 0.7 0.2 7588
train 4496
vs, vt 4.746179103851318 5.472339630126953
need align? ->  True 3.455106019973755
2023-09-02 21:43:41,321 - epoch:8, training loss:0.0866 validation loss:4.7462
Updating learning rate to 9.999988581654443e-05
Updating learning rate to 9.999988581654443e-05
5311 760 1517 0.7 0.2 7588
train 4496
vs, vt 4.863492965698242 5.799935340881348
need align? ->  True 3.455106019973755
2023-09-02 21:45:00,801 - epoch:9, training loss:0.0773 validation loss:4.8635
Updating learning rate to 9.942550451931245e-05
Updating learning rate to 9.942550451931245e-05
5311 760 1517 0.7 0.2 7588
train 4496
vs, vt 4.978951930999756 5.163562297821045
need align? ->  True 3.455106019973755
2023-09-02 21:46:24,084 - epoch:10, training loss:0.0747 validation loss:4.9790
Updating learning rate to 9.77470435919762e-05
Updating learning rate to 9.77470435919762e-05
5311 760 1517 0.7 0.2 7588
train 4496
vs, vt 4.949728965759277 5.795172214508057
need align? ->  True 3.455106019973755
2023-09-02 21:47:46,877 - epoch:11, training loss:0.0692 validation loss:4.9497
Updating learning rate to 9.500199707807918e-05
Updating learning rate to 9.500199707807918e-05
5311 760 1517 0.7 0.2 7588
train 4496
vs, vt 5.164116859436035 6.01384162902832
need align? ->  True 3.455106019973755
2023-09-02 21:49:05,962 - epoch:12, training loss:0.0646 validation loss:5.1641
dropout 0.05
dropout 0.05
check exp/ECL-Informer2023-09-02-21:31:26.269296/0/2.8694_epoch_1.pkl  &  3.455106019973755
2023-09-02 21:49:10,370 - [*] loss:1.3415
2023-09-02 21:49:10,378 - [*] phase 0, testing
2023-09-02 21:49:10,485 - T:720	MAE	0.959111	RMSE	1.348350	MAPE	262.182736
2023-09-02 21:49:10,486 - 720	mae	0.9591	
2023-09-02 21:49:10,486 - 720	rmse	1.3484	
2023-09-02 21:49:10,487 - 720	mape	262.1827	
2023-09-02 21:49:14,122 - [*] loss:1.3404
2023-09-02 21:49:14,129 - [*] phase 0, testing
2023-09-02 21:49:14,225 - T:720	MAE	0.958852	RMSE	1.347420	MAPE	262.185407
2023-09-02 21:49:16,546 - logger name:exp/ECL-Informer2023-09-02-21:49:16.546059/ECL-Informer.log
2023-09-02 21:49:16,546 - params : {'loss': 'huber', 'conf': 'ECL-Informer', 'data_name': 'exchange_rate', 'iteration': 1, 'train': 1, 'mainrs': 0, 'abl': 0, 'load': True, 'build_graph': False, 'same_init': True, 'grad_norm': False, 'refiner_residual': 0, 'root_path': '', 'exp_path': 'exp/', 'val_test_mix': False, 'lr': 0.0001, 'lradj': 'TST', 'dropout': 0.05, 'fc_dropout': 0.05, 'head_dropout': 0.0, 'patch_len': 16, 'stride': 8, 'd_ff': 2048, 'd_model': 512, 'n_heads': 8, 'seq_len': 96, 'pred_len': 96, 'noise_rate': 0.5, 'device': device(type='cuda', index=1), 'test_model_path': '/Disk/fhyega/code/BASE/exp/ECL-PatchTST2023-08-26-13:08:31.837686/0/best_model.pkl', 'idx': -1, 'aligner': 1, 'always_align': 1, 'refiner': 1, 'rec_block_num': 1, 'enhance': 1, 'enhance_type': 5, 'seed': 34, 'batch_size': 64, 'share_head': 0, 'add_noise': 1, 'add_norm': 0, 'jitter_sigma': 0.4, 'slope_rate': 0.01, 'slope_range': 0.2, 'alpha': 10.0, 'beta': 1.0, 'gamma': 0.15, 'feature_jittering': 1, 'rec_intra_feature': 0, 'rec_ori': 1, 'mid_dim': 128, 'test_en': 0, 'debugger': 0, 'summary': 0, 'omega': 1.0, 'theta': 1.5, 'mask_border': 1, 'sup_weight': 10.0, 'rec_length_ratio': 0.8, 'ref_dropout': 0.0, 'ref_block_num': 2, 'add_FFN': 0, 'add_residual': 0, 'rec_all': 0, 'e_layers': 2, 'early_break': 0, 'early_stop': 10, '/* model related args*/': '//', 'model_name': 'informer', 'label_len': 48, 'features': 'M', 'target': 'OT', 'graph_input': False, 'individual': False, 'd_layers': 1, 'factor': 3, 'des': 'Exp', 'padding_patch': 'end', 'revin': 1, 'affine': 0, 'subtract_last': 0, 'decomposition': 0, 'kernel_size': 25, 'output_attention': 0, 'embed_type': 0, 'activation': 'gelu', 'distil': 1, 'linear_output': 0, 'pct_start': 0.3, '/*train related args*/': '//', 'epoch': 30, '/*dataset related args*/': '//', 'save_data_path': 'data/ECL/', 'data_process': False, 'embed': 'timeF', 'freq': 'h', 'begin_phase': 0, 'end_phase': 1, 'phase_len': 26304, 'val_ratio': 0.33, 'graph_size': 321, '/*strategy related args*/': '//', 'strategy': 'incremental', 'increase': False, 'detect': False, 'detect_strategy': 'feature', 'replay': False, 'replay_strategy': 'random', 'repaly_num_samples': 100, 'ewc': False, 'ewc_strategy': 'ewc', 'ewc_lambda': 0.0001, 'subgraph_train': False, 'num_hops': 2, 'logname': 'ECL-Informer', 'time': '2023-09-02-21:49:16.546059', 'path': 'exp/ECL-Informer2023-09-02-21:49:16.546059', 'num_workers': 4, 'start_train': 0, 'train_mode': 'pretrain', 'get_score': False, 'use_cm': True, 'logger': <Logger __main__ (INFO)>}
2023-09-02 21:49:16,546 - [*] phase 0 start training
5311 760 1517 0.7 0.2 7588
train 5120
5311 760 1517 0.7 0.2 7588
val 665
5311 760 1517 0.7 0.2 7588
test 1422
2023-09-02 21:49:16,579 - [*] phase 0 Dataset load!
dropout 0.05
dropout 0.05
2023-09-02 21:49:18,002 - [*] phase 0 Training start
5311 760 1517 0.7 0.2 7588
train 5120
2023-09-02 21:49:51,841 - epoch:0, training loss:0.3005 validation loss:0.8232
5311 760 1517 0.7 0.2 7588
train 5120
vs, vt 0.8231750374490564 0.9700897281820123
Updating learning rate to 6.976011711089559e-06
Updating learning rate to 6.976011711089559e-06
5311 760 1517 0.7 0.2 7588
train 5120
2023-09-02 21:50:14,473 - logger name:exp/ECL-Informer2023-09-02-21:50:14.466530/ECL-Informer.log
2023-09-02 21:50:14,474 - params : {'loss': 'huber', 'conf': 'ECL-Informer', 'data_name': 'exchange_rate', 'iteration': 1, 'train': 1, 'mainrs': 0, 'abl': 0, 'load': True, 'build_graph': False, 'same_init': True, 'grad_norm': False, 'refiner_residual': 0, 'root_path': '', 'exp_path': 'exp/', 'val_test_mix': False, 'lr': 0.0001, 'lradj': 'TST', 'dropout': 0.05, 'fc_dropout': 0.05, 'head_dropout': 0.0, 'patch_len': 16, 'stride': 8, 'd_ff': 2048, 'd_model': 512, 'n_heads': 8, 'seq_len': 96, 'pred_len': 192, 'noise_rate': 0.5, 'device': device(type='cuda', index=1), 'test_model_path': '/Disk/fhyega/code/BASE/exp/ECL-PatchTST2023-08-26-13:08:31.837686/0/best_model.pkl', 'idx': -1, 'aligner': 1, 'always_align': 1, 'refiner': 1, 'rec_block_num': 1, 'enhance': 1, 'enhance_type': 5, 'seed': 34, 'batch_size': 64, 'share_head': 0, 'add_noise': 1, 'add_norm': 0, 'jitter_sigma': 0.4, 'slope_rate': 0.01, 'slope_range': 0.2, 'alpha': 10.0, 'beta': 1.0, 'gamma': 0.15, 'feature_jittering': 1, 'rec_intra_feature': 0, 'rec_ori': 1, 'mid_dim': 128, 'test_en': 0, 'debugger': 0, 'summary': 0, 'omega': 1.0, 'theta': 1.5, 'mask_border': 1, 'sup_weight': 10.0, 'rec_length_ratio': 0.8, 'ref_dropout': 0.0, 'ref_block_num': 2, 'add_FFN': 0, 'add_residual': 0, 'rec_all': 0, 'e_layers': 2, 'early_break': 0, 'early_stop': 10, '/* model related args*/': '//', 'model_name': 'informer', 'label_len': 48, 'features': 'M', 'target': 'OT', 'graph_input': False, 'individual': False, 'd_layers': 1, 'factor': 3, 'des': 'Exp', 'padding_patch': 'end', 'revin': 1, 'affine': 0, 'subtract_last': 0, 'decomposition': 0, 'kernel_size': 25, 'output_attention': 0, 'embed_type': 0, 'activation': 'gelu', 'distil': 1, 'linear_output': 0, 'pct_start': 0.3, '/*train related args*/': '//', 'epoch': 30, '/*dataset related args*/': '//', 'save_data_path': 'data/ECL/', 'data_process': False, 'embed': 'timeF', 'freq': 'h', 'begin_phase': 0, 'end_phase': 1, 'phase_len': 26304, 'val_ratio': 0.33, 'graph_size': 321, '/*strategy related args*/': '//', 'strategy': 'incremental', 'increase': False, 'detect': False, 'detect_strategy': 'feature', 'replay': False, 'replay_strategy': 'random', 'repaly_num_samples': 100, 'ewc': False, 'ewc_strategy': 'ewc', 'ewc_lambda': 0.0001, 'subgraph_train': False, 'num_hops': 2, 'logname': 'ECL-Informer', 'time': '2023-09-02-21:50:14.466530', 'path': 'exp/ECL-Informer2023-09-02-21:50:14.466530', 'num_workers': 4, 'start_train': 0, 'train_mode': 'pretrain', 'get_score': False, 'use_cm': True, 'logger': <Logger __main__ (INFO)>}
2023-09-02 21:50:14,474 - [*] phase 0 start training
5311 760 1517 0.7 0.2 7588
train 5024
5311 760 1517 0.7 0.2 7588
val 569
5311 760 1517 0.7 0.2 7588
test 1326
2023-09-02 21:50:14,511 - [*] phase 0 Dataset load!
dropout 0.05
dropout 0.05
2023-09-02 21:50:16,137 - [*] phase 0 Training start
5311 760 1517 0.7 0.2 7588
train 5024
2023-09-02 21:50:56,454 - epoch:0, training loss:0.3209 validation loss:0.9557
5311 760 1517 0.7 0.2 7588
train 5024
vs, vt 0.9557176099883186 1.1265182826254103
Updating learning rate to 6.90293469063218e-06
Updating learning rate to 6.90293469063218e-06
5311 760 1517 0.7 0.2 7588
train 5024
2023-09-02 21:51:18,675 - logger name:exp/ECL-Informer2023-09-02-21:51:18.674316/ECL-Informer.log
2023-09-02 21:51:18,675 - params : {'loss': 'huber', 'conf': 'ECL-Informer', 'data_name': 'exchange_rate', 'iteration': 1, 'train': 1, 'mainrs': 0, 'abl': 0, 'load': True, 'build_graph': False, 'same_init': True, 'grad_norm': False, 'refiner_residual': 0, 'root_path': '', 'exp_path': 'exp/', 'val_test_mix': False, 'lr': 0.0001, 'lradj': 'TST', 'dropout': 0.05, 'fc_dropout': 0.05, 'head_dropout': 0.0, 'patch_len': 16, 'stride': 8, 'd_ff': 2048, 'd_model': 512, 'n_heads': 8, 'seq_len': 96, 'pred_len': 336, 'noise_rate': 0.5, 'device': device(type='cuda', index=1), 'test_model_path': '/Disk/fhyega/code/BASE/exp/ECL-PatchTST2023-08-26-13:08:31.837686/0/best_model.pkl', 'idx': -1, 'aligner': 1, 'always_align': 1, 'refiner': 1, 'rec_block_num': 1, 'enhance': 1, 'enhance_type': 5, 'seed': 34, 'batch_size': 64, 'share_head': 0, 'add_noise': 1, 'add_norm': 0, 'jitter_sigma': 0.4, 'slope_rate': 0.01, 'slope_range': 0.2, 'alpha': 10.0, 'beta': 1.0, 'gamma': 0.15, 'feature_jittering': 1, 'rec_intra_feature': 0, 'rec_ori': 1, 'mid_dim': 128, 'test_en': 0, 'debugger': 0, 'summary': 0, 'omega': 1.0, 'theta': 1.5, 'mask_border': 1, 'sup_weight': 10.0, 'rec_length_ratio': 0.8, 'ref_dropout': 0.0, 'ref_block_num': 2, 'add_FFN': 0, 'add_residual': 0, 'rec_all': 0, 'e_layers': 2, 'early_break': 0, 'early_stop': 10, '/* model related args*/': '//', 'model_name': 'informer', 'label_len': 48, 'features': 'M', 'target': 'OT', 'graph_input': False, 'individual': False, 'd_layers': 1, 'factor': 3, 'des': 'Exp', 'padding_patch': 'end', 'revin': 1, 'affine': 0, 'subtract_last': 0, 'decomposition': 0, 'kernel_size': 25, 'output_attention': 0, 'embed_type': 0, 'activation': 'gelu', 'distil': 1, 'linear_output': 0, 'pct_start': 0.3, '/*train related args*/': '//', 'epoch': 30, '/*dataset related args*/': '//', 'save_data_path': 'data/ECL/', 'data_process': False, 'embed': 'timeF', 'freq': 'h', 'begin_phase': 0, 'end_phase': 1, 'phase_len': 26304, 'val_ratio': 0.33, 'graph_size': 321, '/*strategy related args*/': '//', 'strategy': 'incremental', 'increase': False, 'detect': False, 'detect_strategy': 'feature', 'replay': False, 'replay_strategy': 'random', 'repaly_num_samples': 100, 'ewc': False, 'ewc_strategy': 'ewc', 'ewc_lambda': 0.0001, 'subgraph_train': False, 'num_hops': 2, 'logname': 'ECL-Informer', 'time': '2023-09-02-21:51:18.674316', 'path': 'exp/ECL-Informer2023-09-02-21:51:18.674316', 'num_workers': 4, 'start_train': 0, 'train_mode': 'pretrain', 'get_score': False, 'use_cm': True, 'logger': <Logger __main__ (INFO)>}
2023-09-02 21:51:18,675 - [*] phase 0 start training
5311 760 1517 0.7 0.2 7588
train 4880
5311 760 1517 0.7 0.2 7588
val 425
5311 760 1517 0.7 0.2 7588
test 1182
2023-09-02 21:51:18,708 - [*] phase 0 Dataset load!
dropout 0.05
dropout 0.05
2023-09-02 21:51:20,212 - [*] phase 0 Training start
5311 760 1517 0.7 0.2 7588
train 4880
2023-09-02 21:51:59,609 - epoch:0, training loss:0.3354 validation loss:1.1410
5311 760 1517 0.7 0.2 7588
train 4880
vs, vt 1.1410011478832789 1.3004916736057825
Updating learning rate to 6.903150433075093e-06
Updating learning rate to 6.903150433075093e-06
5311 760 1517 0.7 0.2 7588
train 4880
2023-09-02 21:52:26,282 - logger name:exp/ECL-Informer2023-09-02-21:52:26.281993/ECL-Informer.log
2023-09-02 21:52:26,282 - params : {'loss': 'huber', 'conf': 'ECL-Informer', 'data_name': 'exchange_rate', 'iteration': 1, 'train': 1, 'mainrs': 0, 'abl': 0, 'load': True, 'build_graph': False, 'same_init': True, 'grad_norm': False, 'refiner_residual': 0, 'root_path': '', 'exp_path': 'exp/', 'val_test_mix': False, 'lr': 0.0001, 'lradj': 'TST', 'dropout': 0.05, 'fc_dropout': 0.05, 'head_dropout': 0.0, 'patch_len': 16, 'stride': 8, 'd_ff': 2048, 'd_model': 512, 'n_heads': 8, 'seq_len': 96, 'pred_len': 720, 'noise_rate': 0.5, 'device': device(type='cuda', index=1), 'test_model_path': '/Disk/fhyega/code/BASE/exp/ECL-PatchTST2023-08-26-13:08:31.837686/0/best_model.pkl', 'idx': -1, 'aligner': 1, 'always_align': 1, 'refiner': 1, 'rec_block_num': 1, 'enhance': 1, 'enhance_type': 5, 'seed': 34, 'batch_size': 64, 'share_head': 0, 'add_noise': 1, 'add_norm': 0, 'jitter_sigma': 0.4, 'slope_rate': 0.01, 'slope_range': 0.2, 'alpha': 10.0, 'beta': 1.0, 'gamma': 0.15, 'feature_jittering': 1, 'rec_intra_feature': 0, 'rec_ori': 1, 'mid_dim': 128, 'test_en': 0, 'debugger': 0, 'summary': 0, 'omega': 1.0, 'theta': 1.5, 'mask_border': 1, 'sup_weight': 10.0, 'rec_length_ratio': 0.8, 'ref_dropout': 0.0, 'ref_block_num': 2, 'add_FFN': 0, 'add_residual': 0, 'rec_all': 0, 'e_layers': 2, 'early_break': 0, 'early_stop': 10, '/* model related args*/': '//', 'model_name': 'informer', 'label_len': 48, 'features': 'M', 'target': 'OT', 'graph_input': False, 'individual': False, 'd_layers': 1, 'factor': 3, 'des': 'Exp', 'padding_patch': 'end', 'revin': 1, 'affine': 0, 'subtract_last': 0, 'decomposition': 0, 'kernel_size': 25, 'output_attention': 0, 'embed_type': 0, 'activation': 'gelu', 'distil': 1, 'linear_output': 0, 'pct_start': 0.3, '/*train related args*/': '//', 'epoch': 30, '/*dataset related args*/': '//', 'save_data_path': 'data/ECL/', 'data_process': False, 'embed': 'timeF', 'freq': 'h', 'begin_phase': 0, 'end_phase': 1, 'phase_len': 26304, 'val_ratio': 0.33, 'graph_size': 321, '/*strategy related args*/': '//', 'strategy': 'incremental', 'increase': False, 'detect': False, 'detect_strategy': 'feature', 'replay': False, 'replay_strategy': 'random', 'repaly_num_samples': 100, 'ewc': False, 'ewc_strategy': 'ewc', 'ewc_lambda': 0.0001, 'subgraph_train': False, 'num_hops': 2, 'logname': 'ECL-Informer', 'time': '2023-09-02-21:52:26.281993', 'path': 'exp/ECL-Informer2023-09-02-21:52:26.281993', 'num_workers': 4, 'start_train': 0, 'train_mode': 'pretrain', 'get_score': False, 'use_cm': True, 'logger': <Logger __main__ (INFO)>}
2023-09-02 21:52:26,282 - [*] phase 0 start training
5311 760 1517 0.7 0.2 7588
train 4496
5311 760 1517 0.7 0.2 7588
val 41
5311 760 1517 0.7 0.2 7588
test 798
2023-09-02 21:52:26,318 - [*] phase 0 Dataset load!
dropout 0.05
dropout 0.05
2023-09-02 21:52:27,750 - [*] phase 0 Training start
5311 760 1517 0.7 0.2 7588
train 4496
2023-09-02 21:53:22,165 - epoch:0, training loss:0.3525 validation loss:1.4115
5311 760 1517 0.7 0.2 7588
train 4496
vs, vt 1.4114726781845093 1.636053204536438
Updating learning rate to 6.903871803230679e-06
Updating learning rate to 6.903871803230679e-06
5311 760 1517 0.7 0.2 7588
train 4496
